{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/examples/timeseries/timeseries_transformer_classification/\n",
    "logger_name = \"lstnet\"\n",
    "\n",
    "# Path appended in order to import from util\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from util.model_util import LoadModel, SaveModel, SaveResults, SaveHistory\n",
    "from util.Msglog import LogInit\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "#from lstnet_util import GetArguments, LSTNetInit\n",
    "from pandas_util import DataUtil\n",
    "#from lstnet_model import PreSkipTrans, PostSkipTrans, PreARTrans, PostARTrans, LSTNetModel, ModelCompile\n",
    "#from lstnet_plot import AutoCorrelationPlot, PlotHistory, PlotPrediction\n",
    "\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/dphanekham/.conda/envs/myenv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,14,20,77,78,79,80,81,82) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9726.925995055048\n",
      "6670.752950995383\n"
     ]
    }
   ],
   "source": [
    "# Reading data\n",
    "filename = 'bq_results_8_12_2020.csv'\n",
    "trainpercent = 0.6\n",
    "validpercent = 0.2\n",
    "horizon=0\n",
    "window=10\n",
    "normalize=0\n",
    "Data = DataUtil(filename,\n",
    "                trainpercent,\n",
    "                validpercent,\n",
    "                horizon,\n",
    "                window,\n",
    "                normalise=normalize,\n",
    "                dependent_variable=\"iperf_throughput_1_thread\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.43849233 -0.5917273  -0.6500752 ]\n",
      "  [ 0.14812031 -0.5917407  -0.6500752 ]\n",
      "  [ 0.04063619 -0.5921704  -0.6500752 ]\n",
      "  ...\n",
      "  [ 0.16401057 -0.59190184 -0.6500752 ]\n",
      "  [ 0.13357922 -0.5921704  -0.6500752 ]\n",
      "  [ 0.26369947 -0.5920361  -0.6500752 ]]\n",
      "\n",
      " [[ 0.14812031 -0.5917407  -0.6500752 ]\n",
      "  [ 0.04063619 -0.5921704  -0.6500752 ]\n",
      "  [ 0.19519146 -0.5918884  -0.6500752 ]\n",
      "  ...\n",
      "  [ 0.13357922 -0.5921704  -0.6500752 ]\n",
      "  [ 0.26369947 -0.5920361  -0.6500752 ]\n",
      "  [-0.33908105 -0.5916736  -0.6500752 ]]\n",
      "\n",
      " [[ 0.04063619 -0.5921704  -0.6500752 ]\n",
      "  [ 0.19519146 -0.5918884  -0.6500752 ]\n",
      "  [-0.1513961  -0.59145874 -0.6500752 ]\n",
      "  ...\n",
      "  [ 0.26369947 -0.5920361  -0.6500752 ]\n",
      "  [-0.33908105 -0.5916736  -0.6500752 ]\n",
      "  [ 0.31586748 -0.59214354 -0.6500752 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.778334   -0.5929089  -0.6500752 ]\n",
      "  [ 1.2208627  -0.5928015  -0.6500752 ]\n",
      "  [ 2.67722    -0.59336543 -0.6500752 ]\n",
      "  ...\n",
      "  [ 1.408098   -0.59284174 -0.6500752 ]\n",
      "  [ 1.3292464  -0.593164   -0.6500752 ]\n",
      "  [ 1.0869949  -0.5931909  -0.6500752 ]]\n",
      "\n",
      " [[ 1.2208627  -0.5928015  -0.6500752 ]\n",
      "  [ 2.67722    -0.59336543 -0.6500752 ]\n",
      "  [ 2.2388887  -0.59302974 -0.6500752 ]\n",
      "  ...\n",
      "  [ 1.3292464  -0.593164   -0.6500752 ]\n",
      "  [ 1.0869949  -0.5931909  -0.6500752 ]\n",
      "  [ 1.9377234  -0.5932446  -0.6500752 ]]\n",
      "\n",
      " [[ 2.67722    -0.59336543 -0.6500752 ]\n",
      "  [ 2.2388887  -0.59302974 -0.6500752 ]\n",
      "  [ 1.7224554  -0.59328485 -0.6500752 ]\n",
      "  ...\n",
      "  [ 1.0869949  -0.5931909  -0.6500752 ]\n",
      "  [ 1.9377234  -0.5932446  -0.6500752 ]\n",
      "  [ 1.4257872  -0.5931909  -0.6500752 ]]]\n"
     ]
    }
   ],
   "source": [
    "#Data.train[0].shape\n",
    "print(Data.train[0])\n",
    "#type(Data.train)\n",
    "#print(len(Data.train[0]))\n",
    "#Data.train\n",
    "#n_classes = len(np.unique(Data.train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Root relative squared error\n",
    "def tf_rse(y_true, y_pred):\n",
    "    #\n",
    "    # The formula is:\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred)))     \n",
    "    #    RSE = -----------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)))       \n",
    "    #\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred))/(N-1))\n",
    "    #        = ----------------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)/(N-1)))\n",
    "    #\n",
    "    #\n",
    "    #           K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    #        = ------------------------------------------\n",
    "    #           K.std(y_true)\n",
    "    #\n",
    "    num = K.sqrt(K.mean(K.square(y_true - y_pred), axis=None))\n",
    "    den = K.std(y_true, axis=None)\n",
    "    \n",
    "    return num / den\n",
    "\n",
    "def rse_test1(y_true, y_pred):\n",
    "    return K.square(y_true - y_pred)\n",
    "\n",
    "def rse_test2(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred), axis=None))\n",
    "\n",
    "def rse_test3(y_true, y_pred):\n",
    "    return K.std(y_true, axis=None)\n",
    "\n",
    "def rse(y_true, y_pred):\n",
    "    #\n",
    "    # The formula is:\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred)))     \n",
    "    #    RSE = -----------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)))       \n",
    "    #\n",
    "    #           K.sqrt(K.sum(K.square( y_true - y_pred))/(N-1))\n",
    "    #        = ----------------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)/(N-1)))\n",
    "    #\n",
    "    #\n",
    "    #           K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    #        = ------------------------------------------\n",
    "    #           K.std(y_true)\n",
    "    #\n",
    "    num = np.sqrt(np.mean(np.square(y_true - y_pred), axis=None))\n",
    "    den = np.std(y_true, axis=None)\n",
    "    \n",
    "    return num / den\n",
    "\n",
    "def tf_corr(y_true, y_pred):\n",
    "    #\n",
    "    # This function calculates the correlation between the true and the predicted outputs\n",
    "    #\n",
    "    num1 = y_true - K.mean(y_true, axis=0)\n",
    "    num2 = y_pred - K.mean(y_pred, axis=0)\n",
    "    \n",
    "    num  = K.mean(num1 * num2, axis=0)\n",
    "    den  = K.std(y_true, axis=0) * K.std(y_pred, axis=0)\n",
    "    \n",
    "    return K.mean(num / den)\n",
    "\n",
    "def corr(y_true, y_pred):\n",
    "    #\n",
    "    # This function calculates the correlation between the true and the predicted outputs\n",
    "    #\n",
    "    num1 = y_true - np.mean(y_true, axis=0)\n",
    "    num2 = y_pred - np.mean(y_pred, axis=0)\n",
    "    \n",
    "    num  = np.mean(num1 * num2, axis=0)\n",
    "    den  = np.std(y_true, axis=0) * np.std(y_pred, axis=0)\n",
    "    \n",
    "    return np.mean(num / den)\n",
    "\n",
    "def single_rse(y_true, y_pred):\n",
    "    #\n",
    "    # The formula is:\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred)))     \n",
    "    #    RSE = -----------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)))       \n",
    "    #\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred))/(N-1))\n",
    "    #        = ----------------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)/(N-1)))\n",
    "    #\n",
    "    #\n",
    "    #           K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    #        = ------------------------------------------\n",
    "    #           K.std(y_true)\n",
    "    #\n",
    "    num = K.sqrt(K.mean(K.square(y_true[:,0] - y_pred[:,0]), axis=None))\n",
    "    den = K.std(y_true, axis=None)\n",
    "    \n",
    "    return num / den\n",
    "\n",
    "\n",
    "def single_corr(y_true, y_pred):\n",
    "    #\n",
    "    # This function calculates the correlation between the true and the predicted outputs\n",
    "    #\n",
    "    num1 = y_true[:,0] - K.mean(y_true[:,0], axis=0)\n",
    "    num2 = y_pred[:,0] - K.mean(y_pred[:,0], axis=0)\n",
    "    \n",
    "    num  = K.mean(num1 * num2, axis=0)\n",
    "    den  = K.std(y_true[:,0], axis=0) * K.std(y_pred[:,0], axis=0)\n",
    "    \n",
    "    return K.mean(num / den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "        )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = tf.keras.Input(shape=(10,3))\n",
    "#     x = tf.keras.layers.Flatten()(inputs)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(1,activation='linear')(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(f\"data.train: {Data.train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 10, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_105 (LayerN (None, 10, 3)        6           input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_53 (MultiH (None, 10, 3)        243         layer_normalization_105[0][0]    \n",
      "                                                                 layer_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)           (None, 10, 3)        0           multi_head_attention_53[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_104 (TFOpL (None, 10, 3)        0           dropout_116[0][0]                \n",
      "                                                                 input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_106 (LayerN (None, 10, 3)        6           tf.__operators__.add_104[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_104 (Conv1D)             (None, 10, 4)        16          layer_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)           (None, 10, 4)        0           conv1d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_105 (Conv1D)             (None, 10, 3)        15          dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_105 (TFOpL (None, 10, 3)        0           conv1d_105[0][0]                 \n",
      "                                                                 tf.__operators__.add_104[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_107 (LayerN (None, 10, 3)        6           tf.__operators__.add_105[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_54 (MultiH (None, 10, 3)        243         layer_normalization_107[0][0]    \n",
      "                                                                 layer_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)           (None, 10, 3)        0           multi_head_attention_54[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_106 (TFOpL (None, 10, 3)        0           dropout_118[0][0]                \n",
      "                                                                 tf.__operators__.add_105[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_108 (LayerN (None, 10, 3)        6           tf.__operators__.add_106[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_106 (Conv1D)             (None, 10, 4)        16          layer_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)           (None, 10, 4)        0           conv1d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_107 (Conv1D)             (None, 10, 3)        15          dropout_119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_107 (TFOpL (None, 10, 3)        0           conv1d_107[0][0]                 \n",
      "                                                                 tf.__operators__.add_106[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_109 (LayerN (None, 10, 3)        6           tf.__operators__.add_107[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_55 (MultiH (None, 10, 3)        243         layer_normalization_109[0][0]    \n",
      "                                                                 layer_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 10, 3)        0           multi_head_attention_55[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_108 (TFOpL (None, 10, 3)        0           dropout_120[0][0]                \n",
      "                                                                 tf.__operators__.add_107[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_110 (LayerN (None, 10, 3)        6           tf.__operators__.add_108[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_108 (Conv1D)             (None, 10, 4)        16          layer_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 10, 4)        0           conv1d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_109 (Conv1D)             (None, 10, 3)        15          dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_109 (TFOpL (None, 10, 3)        0           conv1d_109[0][0]                 \n",
      "                                                                 tf.__operators__.add_108[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_111 (LayerN (None, 10, 3)        6           tf.__operators__.add_109[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_56 (MultiH (None, 10, 3)        243         layer_normalization_111[0][0]    \n",
      "                                                                 layer_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)           (None, 10, 3)        0           multi_head_attention_56[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_110 (TFOpL (None, 10, 3)        0           dropout_122[0][0]                \n",
      "                                                                 tf.__operators__.add_109[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_112 (LayerN (None, 10, 3)        6           tf.__operators__.add_110[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_110 (Conv1D)             (None, 10, 4)        16          layer_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)           (None, 10, 4)        0           conv1d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_111 (Conv1D)             (None, 10, 3)        15          dropout_123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_111 (TFOpL (None, 10, 3)        0           conv1d_111[0][0]                 \n",
      "                                                                 tf.__operators__.add_110[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 10)           0           tf.__operators__.add_111[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 128)          1408        global_average_pooling1d_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)           (None, 128)          0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1)            129         dropout_124[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 2,681\n",
      "Trainable params: 2,681\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n",
      "182/182 [==============================] - 8s 17ms/step - loss: 1.2278 - tf_rse: 1.1483 - tf_corr: 0.0559 - mean_absolute_error: 0.9039 - mean_squared_error: 1.2278 - root_mean_squared_error: 1.1080 - val_loss: 0.9479 - val_tf_rse: 1.4719 - val_tf_corr: -0.2555 - val_mean_absolute_error: 0.8147 - val_mean_squared_error: 0.9479 - val_root_mean_squared_error: 0.9736\n",
      "Epoch 2/2\n",
      "182/182 [==============================] - 2s 13ms/step - loss: 1.0822 - tf_rse: 1.0651 - tf_corr: 0.1192 - mean_absolute_error: 0.8403 - mean_squared_error: 1.0822 - root_mean_squared_error: 1.0402 - val_loss: 0.7449 - val_tf_rse: 1.2719 - val_tf_corr: -0.1212 - val_mean_absolute_error: 0.7172 - val_mean_squared_error: 0.7449 - val_root_mean_squared_error: 0.8631\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 0.9504 - tf_rse: 2.1630 - tf_corr: -0.1205 - mean_absolute_error: 0.8687 - mean_squared_error: 0.9504 - root_mean_squared_error: 0.9749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9503584504127502,\n",
       " 2.163001775741577,\n",
       " -0.12051258981227875,\n",
       " 0.868747889995575,\n",
       " 0.9503584504127502,\n",
       " 0.9748632907867432]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (10,3)\n",
    "#print(f\"data.train: {type(Data.train)}\")\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=4,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "model.fit(\n",
    "    Data.train[0][:,:,:], Data.train[1][:,0],\n",
    "    validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]),\n",
    "    epochs=2,\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "model.evaluate(Data.test[0][:,:,:], Data.test[1][:,0], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11587, 10, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.train[0][:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33908105,  0.31586748,  0.419454  , ...,  1.9377234 ,\n",
       "        1.4257872 ,  0.66395414], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.train[1][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training = np.array([np.array(xi) for xi in Data.train])\n",
    "latency = []\n",
    "throughput = []\n",
    "tcp_buffer_size = []\n",
    "counter = 0\n",
    "for x in range(1):\n",
    "    \n",
    "    for y in range(10):\n",
    "        latency_list = []\n",
    "        throughput_list = []\n",
    "        tcp_buffer_size_list = []\n",
    "        for z in Data.train[x][y]:\n",
    "            #print(f\"y is: {z}\")\n",
    "            latency_list.append(z[0])\n",
    "            throughput_list.append(z[1])\n",
    "            tcp_buffer_size_list.append(z[2])\n",
    "        latency.append(latency_list)\n",
    "        throughput.append(throughput_list)\n",
    "        tcp_buffer_size.append(tcp_buffer_size_list)\n",
    "    break\n",
    "#print(f\"latency: {latency[0]}\")\n",
    "training = np.array([np.array(xi) for xi in latency])\n",
    "training = Data.train.reshape((Data.train[0].shape[0], data.train[0].shape[1], 1))\n",
    "#x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "#print(f\"data train is: {training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance = {}\n",
    "performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Root relative squared error\n",
    "def tf_rse(y_true, y_pred):\n",
    "    #\n",
    "    # The formula is:\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred)))     \n",
    "    #    RSE = -----------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)))       \n",
    "    #\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred))/(N-1))\n",
    "    #        = ----------------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)/(N-1)))\n",
    "    #\n",
    "    #\n",
    "    #           K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    #        = ------------------------------------------\n",
    "    #           K.std(y_true)\n",
    "    #\n",
    "    num = K.sqrt(K.mean(K.square(y_true - y_pred), axis=None))\n",
    "    den = K.std(y_true, axis=None)\n",
    "    \n",
    "    return num / den\n",
    "\n",
    "def rse_test1(y_true, y_pred):\n",
    "    return K.square(y_true - y_pred)\n",
    "\n",
    "def rse_test2(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred), axis=None))\n",
    "\n",
    "def rse_test3(y_true, y_pred):\n",
    "    return K.std(y_true, axis=None)\n",
    "\n",
    "def rse(y_true, y_pred):\n",
    "    #\n",
    "    # The formula is:\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred)))     \n",
    "    #    RSE = -----------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)))       \n",
    "    #\n",
    "    #           K.sqrt(K.sum(K.square( y_true - y_pred))/(N-1))\n",
    "    #        = ----------------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)/(N-1)))\n",
    "    #\n",
    "    #\n",
    "    #           K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    #        = ------------------------------------------\n",
    "    #           K.std(y_true)\n",
    "    #\n",
    "    num = np.sqrt(np.mean(np.square(y_true - y_pred), axis=None))\n",
    "    den = np.std(y_true, axis=None)\n",
    "    \n",
    "    return num / den\n",
    "\n",
    "def tf_corr(y_true, y_pred):\n",
    "    #\n",
    "    # This function calculates the correlation between the true and the predicted outputs\n",
    "    #\n",
    "    num1 = y_true - K.mean(y_true, axis=0)\n",
    "    num2 = y_pred - K.mean(y_pred, axis=0)\n",
    "    \n",
    "    num  = K.mean(num1 * num2, axis=0)\n",
    "    den  = K.std(y_true, axis=0) * K.std(y_pred, axis=0)\n",
    "    \n",
    "    return K.mean(num / den)\n",
    "\n",
    "def corr(y_true, y_pred):\n",
    "    #\n",
    "    # This function calculates the correlation between the true and the predicted outputs\n",
    "    #\n",
    "    num1 = y_true - np.mean(y_true, axis=0)\n",
    "    num2 = y_pred - np.mean(y_pred, axis=0)\n",
    "    \n",
    "    num  = np.mean(num1 * num2, axis=0)\n",
    "    den  = np.std(y_true, axis=0) * np.std(y_pred, axis=0)\n",
    "    \n",
    "    return np.mean(num / den)\n",
    "\n",
    "def single_rse(y_true, y_pred):\n",
    "    #\n",
    "    # The formula is:\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred)))     \n",
    "    #    RSE = -----------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)))       \n",
    "    #\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred))/(N-1))\n",
    "    #        = ----------------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)/(N-1)))\n",
    "    #\n",
    "    #\n",
    "    #           K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    #        = ------------------------------------------\n",
    "    #           K.std(y_true)\n",
    "    #\n",
    "    num = K.sqrt(K.mean(K.square(y_true[:,0] - y_pred[:,0]), axis=None))\n",
    "    den = K.std(y_true, axis=None)\n",
    "    \n",
    "    return num / den\n",
    "\n",
    "\n",
    "def single_corr(y_true, y_pred):\n",
    "    #\n",
    "    # This function calculates the correlation between the true and the predicted outputs\n",
    "    #\n",
    "    num1 = y_true[:,0] - K.mean(y_true[:,0], axis=0)\n",
    "    num2 = y_pred[:,0] - K.mean(y_pred[:,0], axis=0)\n",
    "    \n",
    "    num  = K.mean(num1 * num2, axis=0)\n",
    "    den  = K.std(y_true[:,0], axis=0) * K.std(y_pred[:,0], axis=0)\n",
    "    \n",
    "    return K.mean(num / den)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=10,\n",
    "                                                mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.train[0][:,:,0:3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.train[1][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = {}\n",
    "accuracy_stats['rmse'] = {}\n",
    "accuracy_stats['rse'] = {}\n",
    "accuracy_stats['corr'] = {}\n",
    "accuracy_stats['accuracy'] = {}\n",
    "accuracy_stats['mae'] = {}\n",
    "accuracy_stats['predicted'] = {}\n",
    "accuracy_stats['mse'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MLP\n",
    "\n",
    "Here we are testing the effectiveness of a simple ANN (MLP) on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(10,3)),\n",
    "    tf.keras.layers.Dense(units=15),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=15),\n",
    "    tf.keras.layers.Dense(units=1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.train[1][:,0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.fit(Data.train[0][:,:,:], Data.train[1][:,0].reshape(Data.train[1][:,0].shape[0],1), epochs=100, validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0].reshape(Data.valid[1][:,0].shape[0],1)), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_stats = linear.evaluate(Data.test[0], Data.test[1][:,0].reshape(2933,1))\n",
    "linear_stats = linear.evaluate(Data.test[0], Data.test[1][:,0].reshape(25230,1))\n",
    "\n",
    "linear_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predicted = linear.predict(Data.test[0][:,:,:])\n",
    "\n",
    "np.save('predicted_results/mlp_predicted.npy', linear_predicted)\n",
    "np.savetxt('predicted_results/mlp_predicted.txt', linear_predicted)\n",
    "linear.save_weights('./checkpoints/linear_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import iqr\n",
    "import matplotlib.cm as cm\n",
    "Data.test[1][0:25230,0]\n",
    "linear_predicted[0:25230]\n",
    "inquartileRange = iqr(Data.test[1][0:25230,0],interpolation = 'midpoint')\n",
    "print(inquartileRange)\n",
    "higherRange = inquartileRange * 1.5\n",
    "\n",
    "import numpy as np\n",
    "# First quartile (Q1)\n",
    "#print(Data.test[])\n",
    "Q1 = np.median(Data.test[1][:12615,0])\n",
    "  \n",
    "# Third quartile (Q3)\n",
    "Q3 = np.median(Data.test[1][12615:,0])\n",
    "  \n",
    "# Interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "print(f\"IQR: {IQR}\")\n",
    "# Quartile Deviation\n",
    "qd = IQR / 2\n",
    "  \n",
    "print(f\"Quartile Deviation: {qd}\")\n",
    "highRange = IQR + qd\n",
    "lowRange = IQR - qd\n",
    "print(f\"High Range: {highRange}\")\n",
    "print(f\"Low Range: {lowRange}\")\n",
    "# plt.plot(Data.test[1][0:25230,0])\n",
    "# print(linear_predicted[0:25230])\n",
    "# anomolyList =[]\n",
    "# anomolyListXCoords =[]\n",
    "# count = 0\n",
    "# for x in Data.test[1][0:25230,0]:\n",
    "#     if x > 2 or x <-1:\n",
    "#         anomolyList.append([x])\n",
    "#         anomolyListXCoords.append(count)\n",
    "#     count = count + 1\n",
    "# colors = cm.rainbow(np.linspace(1, 1, 2119))\n",
    "# #print(anomolyList)\n",
    "# #plt.scatter(linear_predicted[0:25230])\n",
    "# plt.scatter(anomolyListXCoords, anomolyList, c=colors)\n",
    "# plt.legend([\"Actual\", \"Anomoly Points\"])\n",
    "# plt.show()\n",
    "print(Data.test[0][1,:])\n",
    "#Data.test[x] shows data in the format [throughput, latency, bufferSize] . Focus Anomoly detection on both Throughput and Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import matplotlib.cm as cm\n",
    "dataRange = 500\n",
    "Data.test[1][0:25230,0]\n",
    "linear_predicted[0:25230]\n",
    "plt.plot(Data.test[1][0:dataRange,0])\n",
    "#print(linear_predicted[0:25230])\n",
    "anomalyList =[]\n",
    "anomalyListXCoords =[]\n",
    "count = 0\n",
    "total=0\n",
    "for x in range(dataRange):\n",
    "    difference = abs(Data.test[1][x,0]-linear_predicted[x])\n",
    "    total = difference + total\n",
    "    count += 1\n",
    "total = total / count\n",
    "print(f\"The Average is: {total}\")\n",
    "count = 0\n",
    "for x in range(dataRange):\n",
    "    difference = abs(Data.test[1][x,0]-linear_predicted[x])\n",
    "    if difference > 3*total:\n",
    "        anomalyList.append(Data.test[1][x,0])\n",
    "        anomalyListXCoords.append(count)\n",
    "    count += 1\n",
    "percentageAnomalous =  round(len(anomalyList)/dataRange *100)\n",
    "print(f\"The percentage of total anomalous points was: {percentageAnomalous}%\")\n",
    "colors = cm.rainbow(np.linspace(1, 1, len(anomalyList)))\n",
    "print(f\"The len of anomalyList: {len(anomalyList)}\")\n",
    "#print(anomolyList)\n",
    "#plt.scatter(linear_predicted[0:25230])\n",
    "#print(f\"The anomalyList: {anomalyList}\\nThe anomalyListXCoords: {anomalyListXCoords}\")\n",
    "\n",
    "plt.scatter(anomalyListXCoords, anomalyList, c=colors)\n",
    "#plt.scatter([1762, 4443, 19902, 23501, 25112], [3.7193446, 4.0872087, 4.4067316, 3.9032767, 4.3992643])#, c=colors)\n",
    "\n",
    "plt.legend([\"Actual\", \"Anomoly Points\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Data.test[1][0:25230,0])\n",
    "plt.plot(linear_predicted[0:25230])\n",
    "plt.legend([\"Actual\", \"Predicted\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(Data.test[1][:,0], linear_predicted.flatten())\n",
    "rmse = sqrt(mean_squared_error(Data.test[1][:,0], linear_predicted.flatten()))\n",
    "mae = mean_absolute_error(Data.test[1][:,0], linear_predicted.flatten())\n",
    "rse_val = rse(Data.test[1][:,0], linear_predicted.flatten())\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "\n",
    "accuracy_stats['rmse']['mlp'] = rmse\n",
    "accuracy_stats['rse']['mlp'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['mlp'] = mae\n",
    "accuracy_stats['predicted']['mlp'] = linear_predicted\n",
    "accuracy_stats['mse']['mlp'] = mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMPLE LSTM\n",
    "\n",
    "Here we run our data through a simple lstm for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.train[0][:,:,0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.train[0][:,:,0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lstm network\n",
    "\n",
    "# lstm_model = tf.keras.models.Sequential([\n",
    "#     # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "#     tf.keras.layers.GRU(32, input_shape=(10), return_sequences=False),\n",
    "#     # Shape => [batch, time, features]\n",
    "#     tf.keras.layers.Dense(units=1)\n",
    "# ])\n",
    "\n",
    "ts_inputs = tf.keras.Input(shape=(10,3))\n",
    "x = tf.keras.layers.LSTM(units=250, dropout=0.1, recurrent_dropout=0.1)(ts_inputs)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(1,activation='linear')(x)\n",
    "lstm_model = tf.keras.Model(inputs=ts_inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lstm_model.fit(Data.train[0][:,:,:], Data.train[1][:,0], \n",
    "               epochs=100, \n",
    "               validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]), \n",
    "               callbacks=[early_stopping],\n",
    "               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_stats = lstm_model.evaluate(Data.test[0][:,:,:], Data.test[1][:,0])\n",
    "lstm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted = lstm_model.predict(Data.test[0][:,:,:]).flatten()\n",
    "\n",
    "np.save('predicted_results/lstm_predicted.npy', lstm_predicted)\n",
    "np.savetxt('predicted_results/lstm_predicted.txt', lstm_predicted)\n",
    "lstm_model.save_weights('./checkpoints/lstm_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted = np.load('predicted_results/lstm_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "data_true = Data.test[1][:,0]*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100\n",
    "lstm_mape = mean_absolute_percentage_error(data_true, lstm_predicted)\n",
    "lstm_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Data.test[1][0:50,0])\n",
    "plt.plot(lstm_predicted[0:50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 10))\n",
    "plt.plot(Data.test[1][:,0],label=\"actual\")\n",
    "plt.plot(lstm_predicted, color='r',label=\"predicted\")\n",
    "plt.legend(loc='best', fontsize='xx-large')\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(Data.test[1][:,0], lstm_predicted)\n",
    "rmse = sqrt(mean_squared_error(Data.test[1][:,0], lstm_predicted))\n",
    "mae = mean_absolute_error(Data.test[1][:,0], lstm_predicted)\n",
    "rse_val = rse(Data.test[1][:,0], lstm_predicted)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "\n",
    "accuracy_stats['rmse']['lstm'] = rmse\n",
    "accuracy_stats['rse']['lstm'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['lstm'] = mae\n",
    "accuracy_stats['predicted']['lstm'] = lstm_predicted\n",
    "accuracy_stats['mse']['lstm'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.test[1][:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GRU\n",
    "\n",
    "Do the same thing but with a GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_inputs = tf.keras.Input(shape=(10,3))\n",
    "x = tf.keras.layers.GRU(units=250, dropout=0.1)(ts_inputs)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(1,activation='linear')(x)\n",
    "gru_model = tf.keras.Model(inputs=ts_inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                  optimizer=tf.optimizers.Adam(),\n",
    "                  metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.fit(Data.train[0][:,:,:], Data.train[1][:,0], \n",
    "               epochs=100, \n",
    "               validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]), \n",
    "               callbacks=[early_stopping],\n",
    "               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.evaluate(Data.test[0][:,:,:], Data.test[1][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_predicted = gru_model.predict(Data.test[0][:,:,:]).flatten()\n",
    "\n",
    "np.save('predicted_results/gru_predicted.npy', gru_predicted)\n",
    "np.savetxt('predicted_results/gru_predicted.txt', gru_predicted)\n",
    "gru_model.save_weights('./checkpoints/gru_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_predicted = np.load('predicted_results/gru_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "data_true = Data.test[1][:,0]*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100\n",
    "gru_mape = mean_absolute_percentage_error(data_true, gru_predicted)\n",
    "gru_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Data.test[1][0:100,0], label='actual')\n",
    "plt.plot(gru_predicted[0:100], label=\"predicted\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(Data.test[1][:,0], gru_predicted)\n",
    "rmse = sqrt(mean_squared_error(Data.test[1][:,0], gru_predicted))\n",
    "mae = mean_absolute_error(Data.test[1][:,0], gru_predicted)\n",
    "rse_val = rse(Data.test[1][:,0], gru_predicted)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "\n",
    "accuracy_stats['rmse']['gru'] = rmse\n",
    "accuracy_stats['rse']['gru'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['gru'] = mae\n",
    "accuracy_stats['predicted']['gru'] = gru_predicted\n",
    "accuracy_stats['mse']['gru'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "\n",
    "\n",
    "# cnn_model = Sequential()\n",
    "# cnn_model.add(Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=(10, 3)))\n",
    "# cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "# cnn_model.add(Flatten())\n",
    "# cnn_model.add(Dense(50, activation='relu'))\n",
    "# cnn_model.add(Dense(1))\n",
    "# cnn_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=30, kernel_size=5, activation='relu', padding='SAME', strides=1, input_shape=(10, 3)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "cnn_model.add(Conv1D(filters=45, kernel_size=5, activation='relu', padding='SAME', strides=1))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "cnn_model.add(Conv1D(filters=60, kernel_size=5, activation='relu', padding='SAME', strides=1))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(120, activation='relu'))\n",
    "cnn_model.add(Dense(1))\n",
    "# cnn_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "              optimizer=tf.optimizers.Adam(),\n",
    "              metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.fit(Data.train[0][:,:,:], Data.train[1][:,0], \n",
    "               epochs=100, \n",
    "               validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]), \n",
    "               callbacks=[early_stopping],\n",
    "               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_stats = cnn_model.evaluate(Data.test[0][:,:,:], Data.test[1][:,0])\n",
    "cnn_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_predicted = cnn_model.predict(Data.test[0][:,:,:]).flatten()\n",
    "\n",
    "np.save('predicted_results/cnn_predicted.npy', cnn_predicted)\n",
    "np.savetxt('predicted_results/cnn_predicted.txt', cnn_predicted)\n",
    "cnn_model.save_weights('./checkpoints/cnn_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Data.test[1][0:100,0], label='actual')\n",
    "plt.plot(cnn_predicted[0:100], label=\"predicted\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(Data.test[1][:,0], cnn_predicted)\n",
    "rmse = sqrt(mean_squared_error(Data.test[1][:,0], cnn_predicted))\n",
    "mae = mean_absolute_error(Data.test[1][:,0], cnn_predicted)\n",
    "rse_val = rse(Data.test[1][:,0], cnn_predicted)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "\n",
    "accuracy_stats['rmse']['cnn'] = rmse\n",
    "accuracy_stats['rse']['cnn'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['cnn'] = mae\n",
    "accuracy_stats['predicted']['cnn'] = cnn_predicted\n",
    "accuracy_stats['mse']['cnn'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_predicted = np.load('predicted_results/cnn_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "data_true = Data.test[1][:,0]*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "\n",
    "cnn_mape = mean_absolute_percentage_error(data_true, cnn_predicted)\n",
    "cnn_mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-LSTM HYBRID MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, Conv2D, LSTM, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model = Sequential()\n",
    "cnn_lstm_model.add(Conv1D(filters=64, kernel_size=5, activation='relu', padding='SAME', strides=1, input_shape=(10, 3)))\n",
    "cnn_lstm_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "cnn_lstm_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='SAME', strides=1))\n",
    "cnn_lstm_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "# cnn_lstm_model.add(Conv1D(filters=10, kernel_size=3, activation='relu', padding='SAME', strides=1))\n",
    "# cnn_lstm_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "# cnn_model.add(Flatten())\n",
    "cnn_lstm_model.add(LSTM(32, dropout=0.1, recurrent_dropout=0.1, return_sequences=False))\n",
    "cnn_lstm_model.add(Dense(100, activation='relu'))\n",
    "cnn_lstm_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                       optimizer=tf.optimizers.Adam(),\n",
    "                       metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model.fit(Data.train[0][:,:,:], Data.train[1][:,0], \n",
    "                   epochs=100, \n",
    "                   validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]), \n",
    "                   callbacks=[early_stopping],\n",
    "                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm1_stats = cnn_lstm_model.evaluate(Data.test[0][:,:,:], Data.test[1][:,0])\n",
    "cnn_lstm1_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_predicted = cnn_lstm_model.predict(Data.test[0][:,:,:]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Data.test[1][0:100,0], label='actual')\n",
    "plt.plot(cnn_lstm_predicted[0:100], label=\"predicted\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(Data.test[1][:,0], cnn_lstm_predicted)\n",
    "rmse = sqrt(mean_squared_error(Data.test[1][:,0], cnn_lstm_predicted))\n",
    "mae = mean_absolute_error(Data.test[1][:,0], cnn_lstm_predicted)\n",
    "rse_val = rse(Data.test[1][:,0], cnn_lstm_predicted)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "\n",
    "accuracy_stats['rmse']['cnn_lstm'] = rmse\n",
    "accuracy_stats['rse']['cnn_lstm'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['cnn_lstm'] = mae\n",
    "accuracy_stats['predicted']['cnn_lstm'] = cnn_lstm_predicted\n",
    "accuracy_stats['mse']['cnn_lstm'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=10,\n",
    "                                                mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, LSTM, MaxPooling2D, Reshape, TimeDistributed, Input, Dropout, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Input(shape = (10,3))\n",
    "\n",
    "\n",
    "#CNN\n",
    "C = Reshape((10, 3, 1))(X)\n",
    "\n",
    "# Apply a Conv2D that will transform it into data of dimensions (batchsize, time, 1, NumofFilters)\n",
    "C = Conv2D(filters=200, kernel_size=(1, 3), kernel_initializer='glorot_uniform')(C)\n",
    "C = Dropout(0.2)(C)\n",
    "\n",
    "# Adjust data dimensions by removing axis=2 which is always equal to 1\n",
    "c_shape = K.int_shape(C)\n",
    "C = Reshape((c_shape[1], c_shape[3]))(C)\n",
    "\n",
    "# Apply a GRU layer (with activation set to 'relu' as per the paper) and take the returned states as result\n",
    "_, R = GRU(200, activation=\"relu\", return_sequences = False, return_state = True)(C)\n",
    "R    = Dropout(0.2)(R)\n",
    "Y = Flatten()(R)\n",
    "Y = Dense(3)(Y)\n",
    "cnn_lstm_model2 = Model(inputs = X, outputs = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model2.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                       optimizer=tf.optimizers.Adam(),\n",
    "                       metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.set_seed(123456)\n",
    "cnn_lstm_model2.fit(Data.train[0][:,:,:], Data.train[1][:,0], \n",
    "                   epochs=10, \n",
    "                   validation_data=(Data.valid[0][:,:,:], Data.valid[1]), \n",
    "                   callbacks=[early_stopping],\n",
    "                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model2.evaluate(Data.test[0][:,:,:], Data.test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model2_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model2_predicted = cnn_lstm_model2.predict(Data.test[0][:,:,:])\n",
    "\n",
    "np.save('predicted_results/cnn_lstm_predicted.npy', cnn_lstm_model2_predicted)\n",
    "np.savetxt('predicted_results/cnn_lstm_predicted.txt', cnn_lstm_model2_predicted)\n",
    "cnn_lstm_model.save_weights('./checkpoints/cnn_lstm_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Data.test[1][0:100,0], label='actual')\n",
    "plt.plot(cnn_lstm_model2_predicted[0:100,0], label=\"predicted\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(Data.test[1][:,0], cnn_lstm_model2_predicted.flatten())\n",
    "rmse = sqrt(mean_squared_error(Data.test[1][:,0], cnn_lstm_model2_predicted.flatten()))\n",
    "mae = mean_absolute_error(Data.test[1][:,0], cnn_lstm_model2_predicted.flatten())\n",
    "rse_val = rse(Data.test[1][:,0], cnn_lstm_model2_predicted[:,0].flatten())\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "\n",
    "accuracy_stats['rmse']['cnn_lstm2'] = rmse\n",
    "accuracy_stats['rse']['cnn_lstm2'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['cnn_lstm2'] = mae\n",
    "accuracy_stats['predicted']['cnn_lstm2'] = cnn_lstm_model2_predicted\n",
    "accuracy_stats['mse']['cnn_lstm2'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTNET MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, model_from_json\n",
    "\n",
    "custom_objects = {\n",
    "        'PreSkipTrans': PreSkipTrans,\n",
    "        'PostSkipTrans': PostSkipTrans,\n",
    "        'PreARTrans': PreARTrans,\n",
    "        'PostARTrans': PostARTrans\n",
    "        }\n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # print(\"CUSTOM LOSS BABBBY\")\n",
    "    # print(type(y_true))\n",
    "    # print(type(y_pred))\n",
    "    # print(y_true)\n",
    "    # print(y_true.shape)\n",
    "    # tf.print(y_true[:,0, sys.stdout)\n",
    "    return tf.keras.losses.mean_absolute_error(y_true[:,0], y_pred[:,0])\n",
    "\n",
    "file = 'models/model2.json'\n",
    "lstnet_model = None\n",
    "with open(file, \"r\") as json_file:\n",
    "  lstnet_model = model_from_json(json_file.read(), custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_model.compile(loss=custom_loss,\n",
    "                       optimizer=tf.optimizers.Adam(),\n",
    "                       metrics=[single_rse, single_corr, tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_model.fit(Data.train[0][:,:,:], Data.train[1][:,0], \n",
    "                   epochs=20, \n",
    "                   validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]), \n",
    "                   callbacks=[early_stopping],\n",
    "                   shuffle=True,\n",
    "                   batch_size=91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_model.evaluate(Data.test[0], Data.test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_predicted = lstnet_model.predict(Data.test[0])\n",
    "\n",
    "np.save('predicted_results/lstnet_predicted.npy', lstnet_predicted)\n",
    "np.savetxt('predicted_results/lstnet_predicted.txt', lstnet_predicted)\n",
    "lstnet_model.save_weights('./checkpoints/lstnet_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Data.test[1][0:100,0], label='actual')\n",
    "plt.plot(lstnet_predicted[0:100, 0], label=\"predicted\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "print(f'MSE: {mean_squared_error(Data.test[1][:,0], lstnet_predicted[:,0])}')\n",
    "print(f'RMSE: {sqrt(mean_squared_error(Data.test[1][:,0], lstnet_predicted[:,0]))}')\n",
    "print(f'MAE: {mean_absolute_error(Data.test[1][:,0], lstnet_predicted[:,0])}')\n",
    "print(f'RSE: {rse(Data.test[1][:,0], lstnet_predicted[:,0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.test[1][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_predicted[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(Data.test[1][:,0]*Data.normalize_std[0] + Data.normalize_mean[0], lstnet_predicted[:,0]*Data.normalize_std[0] + Data.normalize_mean[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between Different Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_predicted = np.load('predicted_results/mlp_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "lstm_predicted = np.load('predicted_results/lstm_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "gru_predicted = np.load('predicted_results/gru_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "cnn_predicted = np.load('predicted_results/cnn_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "cnn_lstm_predicted = np.load('predicted_results/cnn_lstm_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "lstnet_predicted = np.load('predicted_results/lstnet_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "\n",
    "data_true = Data.test[1][:,0]*Data.normalize_std[0] + Data.normalize_mean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "\n",
    "# Create cycler object. Use any styling from above you please\n",
    "monochrome = (cycler('color', ['k']) * cycler('linestyle', ['-', '--', ':']) * cycler('marker', ['^',',', '.']))\n",
    "\n",
    "# Print examples of output from cycler object. \n",
    "# A cycler object, when called, returns a `iter.cycle` object that iterates over items indefinitely\n",
    "\n",
    "default_cycler = (cycler(color=['black', 'r', 'b', 'y', 'teal', 'green', 'purple']) +\n",
    "                  cycler(linestyle=['-', '--', ':', '-.', '-.', '-', '--']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "cmap_1 = ListedColormap([\"darkorange\", \"gold\", \"lawngreen\", \"lightseagreen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 150\n",
    "end_time = 200\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "# plt.rc('axes', prop_cycle=default_cycler)\n",
    "# plt.style.use('grayscale')\n",
    "plt.plot(data_true[start_time:end_time], label='actual')\n",
    "plt.plot(mlp_predicted[start_time:end_time, 0], label=\"mlp\")\n",
    "plt.plot(lstm_predicted[start_time:end_time], label=\"lstm\")\n",
    "plt.plot(gru_predicted[start_time:end_time], label=\"gru\")\n",
    "plt.plot(cnn_predicted[start_time:end_time], label=\"cnn\")\n",
    "plt.plot(cnn_lstm_predicted[start_time:end_time, 0], label=\"cnn+gru\")\n",
    "plt.plot(lstnet_predicted[start_time:end_time, 0], label=\"lstnet\")\n",
    "plt.ylabel('Throughput (Mbits/sec)')\n",
    "plt.xlabel('Day')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_rmse = sqrt(mean_squared_error(data_true, mlp_predicted[:, 0]))\n",
    "mlp_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_rmse = sqrt(mean_squared_error(data_true, lstm_predicted))\n",
    "lstm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_rmse = sqrt(mean_squared_error(data_true, gru_predicted))\n",
    "gru_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_rmse = sqrt(mean_squared_error(data_true, cnn_predicted))\n",
    "cnn_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_rmse = sqrt(mean_squared_error(data_true, cnn_lstm_predicted[:, 0]))\n",
    "cnn_lstm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_rmse = sqrt(mean_squared_error(data_true, lstnet_predicted[:, 0]))\n",
    "lstnet_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[0.45, mlp_rmse, lstm_rmse, gru_rmse, cnn_rmse, cnn_lstm_rmse, lstnet_rmse])\n",
    "ax.set_xlabel('Model')\n",
    "\n",
    "ax.set_ylabel('Root Mean Squared Error (RMSE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mape = mean_absolute_percentage_error(data_true, mlp_predicted[:, 0])\n",
    "mlp_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mape = mean_absolute_percentage_error(data_true, lstm_predicted)\n",
    "lstm_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_mape = mean_absolute_percentage_error(data_true, gru_predicted)\n",
    "gru_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mape = mean_absolute_percentage_error(data_true, cnn_predicted)\n",
    "cnn_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_mape = mean_absolute_percentage_error(data_true, cnn_lstm_predicted[:, 0])\n",
    "cnn_lstm_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_mape = mean_absolute_percentage_error(data_true, lstnet_predicted[:, 0])\n",
    "lstnet_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[79, mlp_mape, lstm_mape, gru_mape, cnn_mape, cnn_lstm_mape, lstnet_mape])\n",
    "ax.set_xlabel('Model')\n",
    "# ax.set_ylim(0.0, 0.9)\n",
    "ax.set_ylabel('Mean Absolute Percentage Error (MAPE) %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_corr = corr(data_true, mlp_predicted[:, 0])\n",
    "mlp_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_corr = corr(data_true, lstm_predicted)\n",
    "lstm_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_corr = corr(data_true, gru_predicted)\n",
    "gru_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_corr = corr(data_true, cnn_predicted)\n",
    "cnn_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_corr = corr(data_true, cnn_lstm_predicted[:, 0])\n",
    "cnn_lstm_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_corr = corr(data_true, lstnet_predicted[:, 0])\n",
    "lstnet_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "scipy.stats.pearsonr(data_true, lstnet_predicted[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[0.88, mlp_corr, lstm_corr, gru_corr, cnn_corr, cnn_lstm_corr, lstnet_corr])\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylim(0.85, 0.95)\n",
    "ax.set_ylabel('Mean Absolute Percentage Error (MAPE) %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_r2 = r2_score(data_true, mlp_predicted[:, 0])\n",
    "lstm_r2 = r2_score(data_true, lstm_predicted)\n",
    "gru_r2 = r2_score(data_true, gru_predicted)\n",
    "cnn_r2 = r2_score(data_true, cnn_predicted)\n",
    "cnn_lstm_r2 = r2_score(data_true, cnn_lstm_predicted[:, 0])\n",
    "lstnet_r2 = r2_score(data_true, lstnet_predicted[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'mlp r2:     {mlp_r2}')\n",
    "print(f'lstm r2:    {lstm_r2}')\n",
    "print(f'gru r2:     {gru_r2}')\n",
    "print(f'cnn r2:     {cnn_r2}')\n",
    "print(f'cnn+gru r2: {cnn_lstm_r2}')\n",
    "print(f'lstnet r2:  {lstnet_r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RRSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_rrse = rse(data_true, mlp_predicted[:, 0])\n",
    "mlp_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_rrse = rse(data_true, lstm_predicted)\n",
    "lstm_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_rrse = rse(data_true, gru_predicted)\n",
    "gru_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_rrse = rse(data_true, cnn_predicted)\n",
    "cnn_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_rrse = rse(data_true, cnn_lstm_predicted[:, 0].flatten())\n",
    "cnn_lstm_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_rrse = rse(data_true, lstnet_predicted[:, 0].flatten())\n",
    "lstnet_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[0.79, mlp_rrse,lstm_rrse,gru_rrse,cnn_rrse,cnn_lstm_rrse,lstnet_rrse])\n",
    "ax.set_xlabel('Model')\n",
    "# ax.set_ylim(0.0, 0.9)\n",
    "ax.set_ylabel('Root Relative Squared Error (RRSE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mae = mean_absolute_error(data_true, mlp_predicted[:, 0])\n",
    "mlp_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mae = mean_absolute_error(data_true, lstm_predicted)\n",
    "lstm_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_mae = mean_absolute_error(data_true, gru_predicted)\n",
    "gru_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mae = mean_absolute_error(data_true, cnn_predicted)\n",
    "cnn_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_mae = mean_absolute_error(data_true, cnn_lstm_predicted[:, 0])\n",
    "cnn_lstm_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_mae = mean_absolute_error(data_true, lstnet_predicted[:, 0])\n",
    "lstnet_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[79, mlp_mae, lstm_mae, gru_mae, cnn_mae, cnn_lstm_mae, lstnet_mae])\n",
    "ax.set_xlabel('Model')\n",
    "# ax.set_ylim(0.0, 0.9)\n",
    "ax.set_ylabel('Mean Absolute Percentage Error (MAPE) %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSRE (root mean square relative error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mae = mean_absolute_error(data_true, mlp_predicted[:, 0])\n",
    "mlp_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mae = mean_absolute_error(data_true, lstm_predicted)\n",
    "lstm_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_mae = mean_absolute_error(data_true, gru_predicted)\n",
    "gru_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mae = mean_absolute_error(data_true, cnn_predicted)\n",
    "cnn_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_mae = mean_absolute_error(data_true, cnn_lstm_predicted[:, 0])\n",
    "cnn_lstm_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_mae = mean_absolute_error(data_true, lstnet_predicted[:, 0])\n",
    "lstnet_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[79, mlp_mae, lstm_mae, gru_mae, cnn_mae, cnn_lstm_mae, lstnet_mae])\n",
    "ax.set_xlabel('Model')\n",
    "# ax.set_ylim(0.0, 0.9)\n",
    "ax.set_ylabel('Mean Absolute Percentage Error (MAPE) %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDF of Relative Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_relative_error = (data_true - mlp_predicted[:, 0]) / data_true\n",
    "lstm_relative_error = (data_true - lstm_predicted) / data_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_residual_error = (data_true - mlp_predicted[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_relative_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mlp_relative_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 40\n",
    "counts, bin_edges = np.histogram (abs(mlp_relative_error), bins=num_bins, normed=True)\n",
    "cdf = np.cumsum (counts)\n",
    "plt.plot (bin_edges[1:], cdf/cdf[-1])\n",
    "counts, bin_edges = np.histogram (abs(lstm_relative_error), bins=num_bins, normed=True)\n",
    "cdf = np.cumsum (counts)\n",
    "plt.plot (bin_edges[1:], cdf/cdf[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_actual = np.load('predicted_results/arima_data_actual_multivar_1.npy')\n",
    "arima_predicted = np.load('predicted_results/arima_data_predictions_multivar_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(arima_actual[0:300])\n",
    "plt.plot(arima_predicted[0:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rrse = rse(arima_actual, arima_predicted)\n",
    "arima_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "arima_mae = mean_absolute_error(arima_actual, arima_predicted)\n",
    "arima_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100\n",
    "\n",
    "arima_mape = mean_absolute_percentage_error(arima_actual, arima_predicted)\n",
    "arima_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "arima_rmse = sqrt(mean_squared_error(arima_actual, arima_predicted))\n",
    "arima_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_corr = corr(arima_actual, arima_predicted)\n",
    "arima_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for all models on a single route (from test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = np.load('numpy_group_test_data/1_stream_test_sample_group_95.npy')\n",
    "test_target = np.load('numpy_group_test_data/1_stream_test_target_group_95.npy')\n",
    "\n",
    "normalize_mean = 9726.925995055048\n",
    "normalize_std  = 6670.752950995383\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm \n",
    "\n",
    "arma_mod = sm.tsa.ARIMA(test_target[:,0], order=(8,0,8))\n",
    "arma_res = arma_mod.fit(trend='nc', disp=-1)\n",
    "arma_predictions = arma_res.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model instance\n",
    "\n",
    "# Restore the weights\n",
    "linear.load_weights('./checkpoints/linear_weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_test_predict = linear.predict(test_sample)\n",
    "lstm_test_predict = lstm_model.predict(test_sample)\n",
    "gru_test_predict = gru_model.predict(test_sample)\n",
    "cnn_test_predict = cnn_model.predict(test_sample)\n",
    "cnn_lstm_test_predict = cnn_lstm_model.predict(test_sample)\n",
    "lstnet_test_predict = lstnet_model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "plt.plot(test_target[1:,0] * normalize_std + normalize_mean, label='actual')\n",
    "plt.plot(arma_predictions[1:] * normalize_std + normalize_mean, label='arima')\n",
    "plt.plot(linear_test_predict[1:] * normalize_std + normalize_mean, label='mlp')\n",
    "plt.plot(lstm_test_predict[1:] * normalize_std + normalize_mean, label='lstm')\n",
    "plt.plot(gru_test_predict[1:] * normalize_std + normalize_mean, label='gru')\n",
    "plt.plot(cnn_test_predict[1:] * normalize_std + normalize_mean, label='cnn')\n",
    "plt.plot(cnn_lstm_test_predict[1:,0] * normalize_std + normalize_mean, label='cnn+gru')\n",
    "plt.plot(lstnet_test_predict[1:,0] * normalize_std + normalize_mean, label='lstnet')\n",
    "plt.ylabel('Throughput (Mbits/sec)')\n",
    "plt.xlabel('Day')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(test_target[1:,0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
