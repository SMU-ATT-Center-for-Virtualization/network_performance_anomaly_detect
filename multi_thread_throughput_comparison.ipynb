{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_name = \"lstnet\"\n",
    "\n",
    "# Path appended in order to import from util\n",
    "import sys\n",
    "# from util.model_util import LoadModel, SaveModel, SaveResults, SaveHistory\n",
    "# from util.Msglog import LogInit\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "#from lstnet_util import GetArguments, LSTNetInit\n",
    "from pandas_data_util import DataUtil\n",
    "#from lstnet_model import PreSkipTrans, PostSkipTrans, PreARTrans, PostARTrans, LSTNetModel, ModelCompile\n",
    "#from lstnet_plot import AutoCorrelationPlot, PlotHistory, PlotPrediction\n",
    "\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA\n",
    "\n",
    "### Filter data to be premium tier, internal IP, and n1-standard-16 machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/users/dphanekham/network_performance_anomaly_detect/pandas_data_util.py:71: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,14,20,45,82,83,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, dtype={\"ping_average_latency\": float,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['run_uri', 'vm_1_cloud', 'vm_2_cloud', 'sending_zone', 'receiving_zone',\n",
      "       'vm_1_machine_type', 'vm_2_machine_type', 'ip_type',\n",
      "       'vm_1_gce_network_tier', 'vm_2_gce_network_tier',\n",
      "       ...\n",
      "       'sending_zone_hour_sin', 'receiving_zone_hour_cos',\n",
      "       'receiving_zone_hour_sin', 'kernel_version', 'n1-standard-16',\n",
      "       'external', 'internal', 'vm_1_os_info_trunc', 'bbr', 'cubic'],\n",
      "      dtype='object', length=109)\n"
     ]
    }
   ],
   "source": [
    "# Reading data\n",
    "filename = 'data/bq_results_09082022.csv'\n",
    "trainpercent = 0.6\n",
    "validpercent = 0.2\n",
    "horizon=0\n",
    "window=10\n",
    "normalize=0\n",
    "\n",
    "# query='vm_1_gce_network_tier == \"premium\"'\n",
    "query = 'vm_1_gce_network_tier == \"premium\" and vm_1_machine_type == \"n1-standard-16\" and ip_type == \"internal\" and tcp_congestion_control == \"bbr\" and sending_zone != \"asia-east2-a\"'\n",
    "\n",
    "Data = DataUtil(filename,\n",
    "                trainpercent,\n",
    "                validpercent,\n",
    "                horizon,\n",
    "                window,\n",
    "                normalize=normalize,\n",
    "                query=query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance = {}\n",
    "performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Root relative squared error\n",
    "def tf_rse(y_true, y_pred):\n",
    "    #\n",
    "    # The formula is:\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred)))     \n",
    "    #    RSE = -----------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)))       \n",
    "    #\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred))/(N-1))\n",
    "    #        = ----------------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)/(N-1)))\n",
    "    #\n",
    "    #\n",
    "    #           K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    #        = ------------------------------------------\n",
    "    #           K.std(y_true)\n",
    "    #\n",
    "    num = K.sqrt(K.mean(K.square(y_true - y_pred), axis=None))\n",
    "    den = K.std(y_true, axis=None)\n",
    "    \n",
    "    return num / den\n",
    "\n",
    "def rse_test1(y_true, y_pred):\n",
    "    return K.square(y_true - y_pred)\n",
    "\n",
    "def rse_test2(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred), axis=None))\n",
    "\n",
    "def rse_test3(y_true, y_pred):\n",
    "    return K.std(y_true, axis=None)\n",
    "\n",
    "def rse(y_true, y_pred):\n",
    "    #\n",
    "    # The formula is:\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred)))     \n",
    "    #    RSE = -----------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)))       \n",
    "    #\n",
    "    #           K.sqrt(K.sum(K.square( y_true - y_pred))/(N-1))\n",
    "    #        = ----------------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)/(N-1)))\n",
    "    #\n",
    "    #\n",
    "    #           K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    #        = ------------------------------------------\n",
    "    #           K.std(y_true)\n",
    "    #\n",
    "    num = np.sqrt(np.mean(np.square(y_true - y_pred), axis=None))\n",
    "    den = np.std(y_true, axis=None)\n",
    "    \n",
    "    return num / den\n",
    "\n",
    "def tf_corr(y_true, y_pred):\n",
    "    #\n",
    "    # This function calculates the correlation between the true and the predicted outputs\n",
    "    #\n",
    "    num1 = y_true - K.mean(y_true, axis=0)\n",
    "    num2 = y_pred - K.mean(y_pred, axis=0)\n",
    "    \n",
    "    num  = K.mean(num1 * num2, axis=0)\n",
    "    den  = K.std(y_true, axis=0) * K.std(y_pred, axis=0)\n",
    "    \n",
    "    return K.mean(num / den)\n",
    "\n",
    "def corr(y_true, y_pred):\n",
    "    #\n",
    "    # This function calculates the correlation between the true and the predicted outputs\n",
    "    #\n",
    "    num1 = y_true - np.mean(y_true, axis=0)\n",
    "    num2 = y_pred - np.mean(y_pred, axis=0)\n",
    "    \n",
    "    num  = np.mean(num1 * num2, axis=0)\n",
    "    den  = np.std(y_true, axis=0) * np.std(y_pred, axis=0)\n",
    "    \n",
    "    return np.mean(num / den)\n",
    "\n",
    "def single_rse(y_true, y_pred):\n",
    "    #\n",
    "    # The formula is:\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred)))     \n",
    "    #    RSE = -----------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)))       \n",
    "    #\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred))/(N-1))\n",
    "    #        = ----------------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)/(N-1)))\n",
    "    #\n",
    "    #\n",
    "    #           K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    #        = ------------------------------------------\n",
    "    #           K.std(y_true)\n",
    "    #\n",
    "    num = K.sqrt(K.mean(K.square(y_true[:,0] - y_pred[:,0]), axis=None))\n",
    "    den = K.std(y_true, axis=None)\n",
    "    \n",
    "    return num / den\n",
    "\n",
    "\n",
    "def single_corr(y_true, y_pred):\n",
    "    #\n",
    "    # This function calculates the correlation between the true and the predicted outputs\n",
    "    #\n",
    "    num1 = y_true[:,0] - K.mean(y_true[:,0], axis=0)\n",
    "    num2 = y_pred[:,0] - K.mean(y_pred[:,0], axis=0)\n",
    "    \n",
    "    num  = K.mean(num1 * num2, axis=0)\n",
    "    den  = K.std(y_true[:,0], axis=0) * K.std(y_pred[:,0], axis=0)\n",
    "    \n",
    "    return K.mean(num / den)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=10,\n",
    "                                                mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pandas_datetime',\n",
       " 'iperf_throughput_1_thread',\n",
       " 'iperf_throughput_32_threads',\n",
       " 'ping_average_latency',\n",
       " 'tcp_max_receive_buffer',\n",
       " 'sending_zone_day_cos',\n",
       " 'sending_zone_day_sin',\n",
       " 'receiving_zone_day_cos',\n",
       " 'receiving_zone_day_sin',\n",
       " 'sending_zone_hour_cos',\n",
       " 'sending_zone_hour_sin',\n",
       " 'receiving_zone_hour_cos',\n",
       " 'receiving_zone_hour_sin',\n",
       " 'kernel_version']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[Timestamp('2022-03-03 04:11:17.582279+0000', tz='UTC'),\n",
       "        0.647868511710962, 0.4911949386759684, -1.452150107380791,\n",
       "        0.26244171035143865, -0.900968867902419, 0.43388373911755823,\n",
       "        -0.900968867902419, 0.43388373911755823, -1.0,\n",
       "        1.2246467991473532e-16, -1.0, 1.2246467991473532e-16,\n",
       "        -2.6754726659424377],\n",
       "       [Timestamp('2022-03-04 06:55:46.812430+0000', tz='UTC'),\n",
       "        0.8653518849693854, 0.6660143353451784, -1.4523551030513613,\n",
       "        0.26244171035143865, -0.9009688679024191, -0.433883739117558,\n",
       "        -0.9009688679024191, -0.433883739117558, -0.8660254037844388,\n",
       "        -0.4999999999999997, -0.8660254037844388, -0.4999999999999997,\n",
       "        -2.6754726659424377],\n",
       "       [Timestamp('2022-03-05 10:11:20.458815+0000', tz='UTC'),\n",
       "        1.5256418593213947, 0.972490395188188, -1.4474954998019587,\n",
       "        0.26244171035143865, -0.2225209339563146, -0.9749279121818236,\n",
       "        -0.2225209339563146, -0.9749279121818236,\n",
       "        -1.8369701987210297e-16, -1.0, -1.8369701987210297e-16, -1.0,\n",
       "        -0.420537681783286],\n",
       "       [Timestamp('2022-03-06 13:16:17.535309+0000', tz='UTC'),\n",
       "        1.1766231481643519, 0.6573404845949046, -1.4523912787579325,\n",
       "        0.26244171035143865, 0.6234898018587334, -0.7818314824680299,\n",
       "        0.6234898018587334, -0.7818314824680299, 0.7071067811865474,\n",
       "        -0.7071067811865477, 0.7071067811865474, -0.7071067811865477,\n",
       "        -0.420537681783286],\n",
       "       [Timestamp('2022-03-07 15:57:23.335103+0000', tz='UTC'),\n",
       "        1.91531166828375, 1.227233130913493, -1.4476160854905296,\n",
       "        0.26244171035143865, 1.0, 0.0, 1.0, 0.0, 0.9659258262890681,\n",
       "        -0.25881904510252157, 0.9659258262890681, -0.25881904510252157,\n",
       "        -0.420537681783286],\n",
       "       [Timestamp('2022-03-08 19:07:16.288104+0000', tz='UTC'),\n",
       "        1.2460203794177074, 1.0141042267639067, -1.4531268514582143,\n",
       "        0.26244171035143865, -0.22252093395631434, 0.9749279121818236,\n",
       "        -0.22252093395631434, 0.9749279121818236, 0.7071067811865476,\n",
       "        0.7071067811865475, 0.7071067811865476, 0.7071067811865475,\n",
       "        -0.420537681783286],\n",
       "       [Timestamp('2022-03-09 22:22:28.062353+0000', tz='UTC'),\n",
       "        1.2074018365026602, 1.048076808869146, -1.4533077299910702,\n",
       "        0.26244171035143865, -0.900968867902419, 0.43388373911755823,\n",
       "        -0.900968867902419, 0.43388373911755823, 6.123233995736766e-17,\n",
       "        1.0, 6.123233995736766e-17, 1.0, -0.420537681783286],\n",
       "       [Timestamp('2022-03-11 01:06:07.065495+0000', tz='UTC'),\n",
       "        1.0404419705165542, 0.532808770251687, -1.447374914113388,\n",
       "        0.26244171035143865, -0.9009688679024191, -0.433883739117558,\n",
       "        -0.9009688679024191, -0.433883739117558, -0.7071067811865475,\n",
       "        0.7071067811865476, -0.7071067811865475, 0.7071067811865476,\n",
       "        -0.420537681783286],\n",
       "       [Timestamp('2022-03-12 04:17:12.899867+0000', tz='UTC'),\n",
       "        1.4939920760301153, 0.8759421755274016, -1.4468805127902478,\n",
       "        0.26244171035143865, -0.2225209339563146, -0.9749279121818236,\n",
       "        -0.2225209339563146, -0.9749279121818236, -1.0,\n",
       "        1.2246467991473532e-16, -1.0, 1.2246467991473532e-16,\n",
       "        -0.420537681783286],\n",
       "       [Timestamp('2022-03-13 07:17:41.524483+0000', tz='UTC'),\n",
       "        0.9373624010816538, 0.7405681477463418, -1.4477969640233856,\n",
       "        0.26244171035143865, 0.6234898018587334, -0.7818314824680299,\n",
       "        0.6234898018587334, -0.7818314824680299, -0.7071067811865479,\n",
       "        -0.7071067811865471, -0.7071067811865479, -0.7071067811865471,\n",
       "        -0.420537681783286]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.train[0][:,:,1:12][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Timestamp('2022-03-14 10:15:48.291610+0000', tz='UTC'),\n",
       "       Timestamp('2022-03-15 13:15:39.680529+0000', tz='UTC'),\n",
       "       Timestamp('2022-03-16 16:16:57.966655+0000', tz='UTC'), ...,\n",
       "       Timestamp('2022-06-03 11:10:47.358064+0000', tz='UTC'),\n",
       "       Timestamp('2022-06-04 16:24:33.753598+0000', tz='UTC'),\n",
       "       Timestamp('2022-06-05 17:01:43.350594+0000', tz='UTC')],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.train[1][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_col_top = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_data_columns = Data.columns[1:data_col_top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iperf_throughput_1_thread',\n",
       " 'iperf_throughput_32_threads',\n",
       " 'ping_average_latency',\n",
       " 'tcp_max_receive_buffer',\n",
       " 'sending_zone_day_cos',\n",
       " 'sending_zone_day_sin',\n",
       " 'receiving_zone_day_cos',\n",
       " 'receiving_zone_day_sin',\n",
       " 'sending_zone_hour_cos',\n",
       " 'sending_zone_hour_sin',\n",
       " 'receiving_zone_hour_cos',\n",
       " 'receiving_zone_hour_sin']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_data_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = len(adjusted_data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_x_float32 = np.array(list(Data.train[0][:,:,1:data_col_top])).astype(np.float32)\n",
    "data_train_y_float32 = np.array(list(Data.train[1][:,1:data_col_top])).astype(np.float32)\n",
    "data_train_y_float32_32_thread_reshaped = data_train_y_float32[:,1].reshape(data_train_y_float32[:,1].shape[0],1)\n",
    "data_train_y_float32_1_thread_reshaped = data_train_y_float32[:,0].reshape(data_train_y_float32[:,0].shape[0],1)\n",
    "\n",
    "data_valid_x_float32 = np.array(list(Data.valid[0][:,:,1:data_col_top])).astype(np.float32)\n",
    "data_valid_y_float32 = np.array(list(Data.valid[1][:,1:data_col_top])).astype(np.float32)\n",
    "data_valid_y_float32_32_thread_reshaped = data_valid_y_float32[:,1].reshape(data_valid_y_float32[:,1].shape[0],1)\n",
    "data_valid_y_float32_1_thread_reshaped = data_valid_y_float32[:,0].reshape(data_valid_y_float32[:,0].shape[0],1)\n",
    "\n",
    "data_test_x_float32 = np.array(list(Data.test[0][:,:,1:data_col_top])).astype(np.float32)\n",
    "data_test_y_float32 = np.array(list(Data.test[1][:,1:data_col_top])).astype(np.float32)\n",
    "data_test_y_float32_32_thread_reshaped = data_test_y_float32[:,1].reshape(data_test_y_float32[:,1].shape[0],1)\n",
    "data_test_y_float32_1_thread_reshaped = data_test_y_float32[:,0].reshape(data_test_y_float32[:,0].shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = {}\n",
    "accuracy_stats['rmse'] = {}\n",
    "accuracy_stats['rse'] = {}\n",
    "accuracy_stats['corr'] = {}\n",
    "accuracy_stats['accuracy'] = {}\n",
    "accuracy_stats['mae'] = {}\n",
    "accuracy_stats['predicted'] = {}\n",
    "accuracy_stats['mse'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def SimpleAnomalyDetection(actual, predicted, data_high, data_low=0):\n",
    "  # Finds average difference for entire data range\n",
    "  # if point is more different than this, it is an anomaly\n",
    "  # return anomaly list\n",
    "\n",
    "  anomaly_index_list = []\n",
    "  count = 0\n",
    "  total=0\n",
    "  for x in range(data_low, data_high):\n",
    "      difference = abs(actual[x]-predicted[x])\n",
    "      total = difference + total\n",
    "      count += 1\n",
    "  average = total / count\n",
    "  print(f\"The Average is: {average}\")\n",
    "  count = 0\n",
    "  for x in range(data_low, data_high):\n",
    "      difference = abs(actual[x]-predicted[x])\n",
    "      if difference > 3*average:\n",
    "          # anomaly_list.append(data_test_y_float32_32_thread_reshaped[x])\n",
    "          # anomaly_list_x_coords.append(count)\n",
    "          anomaly_index_list.append(x)\n",
    "      count += 1\n",
    "  print(anomaly_index_list)\n",
    "  return anomaly_index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MLP\n",
    "\n",
    "Here we are testing the effectiveness of a simple ANN (MLP) on our dataset\n",
    "\n",
    "the output here is 32 thread throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=10,\n",
    "                                                mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(10,num_vars)),\n",
    "    tf.keras.layers.Dense(units=100, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=100, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(units=20),\n",
    "    tf.keras.layers.Dense(units=1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf_rse, \n",
    "                         tf_corr, \n",
    "                         tf.metrics.MeanAbsoluteError(), \n",
    "                         tf.metrics.MeanSquaredError(), \n",
    "                         tf.metrics.RootMeanSquaredError(), \n",
    "                         tf.metrics.MeanAbsolutePercentageError()\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = linear.fit(data_train_x_float32, \n",
    "           data_train_y_float32_32_thread_reshaped,\n",
    "           epochs=1000, \n",
    "           validation_data=(data_valid_x_float32, \n",
    "                            data_valid_y_float32_32_thread_reshaped), \n",
    "           callbacks=[early_stopping],\n",
    "           verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_stats = linear.evaluate(data_test_x_float32, data_test_y_float32_32_thread_reshaped)\n",
    "\n",
    "linear_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predicted = linear.predict(data_test_x_float32)\n",
    "\n",
    "np.save('predicted_results/mlp_predicted.npy', linear_predicted)\n",
    "np.savetxt('predicted_results/mlp_predicted.txt', linear_predicted)\n",
    "linear.save_weights('./checkpoints/linear_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_y_float32[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_y_float32_32_thread_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import iqr\n",
    "import matplotlib.cm as cm\n",
    "inquartileRange = iqr(data_test_y_float32_32_thread_reshaped,interpolation = 'midpoint')\n",
    "print(inquartileRange)\n",
    "higherRange = inquartileRange * 1.5\n",
    "\n",
    "half = data_test_y_float32_32_thread_reshaped.shape[0] // 2\n",
    " \n",
    "import numpy as np\n",
    "# First quartile (Q1)\n",
    "#print(Data.test[])\n",
    "Q1 = np.median(data_test_y_float32_32_thread_reshaped[0:half])\n",
    "  \n",
    "# Third quartile (Q3)\n",
    "Q3 = np.median(data_test_y_float32_32_thread_reshaped[half:])\n",
    "  \n",
    "# Interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "print(f\"IQR: {IQR}\")\n",
    "# Quartile Deviation\n",
    "qd = IQR / 2\n",
    "  \n",
    "print(f\"Quartile Deviation: {qd}\")\n",
    "highRange = IQR + qd\n",
    "lowRange = IQR - qd\n",
    "print(f\"High Range: {highRange}\")\n",
    "print(f\"Low Range: {lowRange}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_y_float32_32_thread_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_high = 2000\n",
    "data_low = 0\n",
    "anomaly_index_list = SimpleAnomalyDetection(data_test_y_float32_32_thread_reshaped, linear_predicted, data_high, data_low=data_low)\n",
    "\n",
    "anomaly_y_coords = []\n",
    "\n",
    "for x in anomaly_index_list:\n",
    "  anomaly_y_coords.append(data_test_y_float32_32_thread_reshaped[x])\n",
    "\n",
    "print(f\"The len of anomalyList: {len(anomaly_index_list)}\")\n",
    "colors = cm.rainbow(np.linspace(1, 1, len(anomaly_index_list)))\n",
    "plt.plot(data_test_y_float32_32_thread_reshaped[data_low:data_high])\n",
    "plt.plot(linear_predicted[data_low:data_high])\n",
    "plt.scatter(anomaly_index_list, anomaly_y_coords, c=colors)\n",
    "\n",
    "plt.legend([\"Actual\", \"Anomoly Points\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_y_float32_32_thread_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRange=1000\n",
    "\n",
    "plt.plot(data_test_y_float32_32_thread_reshaped[0:dataRange])\n",
    "plt.plot(linear_predicted[0:dataRange])\n",
    "plt.legend([\"Actual\", \"Predicted\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(data_test_y_float32_32_thread_reshaped.flatten(), linear_predicted.flatten())\n",
    "rmse = sqrt(mean_squared_error(data_test_y_float32_32_thread_reshaped.flatten(), linear_predicted.flatten()))\n",
    "mae = mean_absolute_error(data_test_y_float32_32_thread_reshaped.flatten(), linear_predicted.flatten())\n",
    "rse_val = rse(data_test_y_float32_32_thread_reshaped.flatten(), linear_predicted.flatten())\n",
    "mape = mean_absolute_percentage_error(data_test_y_float32_32_thread_reshaped.flatten(), linear_predicted.flatten())\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "print(f'MAPE: {mape}')\n",
    "\n",
    "# accuracy_stats['rmse']['mlp'] = rmse\n",
    "# accuracy_stats['rse']['mlp'] = rse_val\n",
    "# # accuracy_stats['corr']['mlp'] = corr\n",
    "# # accuracy_stats['accuracy']['mlp'] = acc\n",
    "# accuracy_stats['mae']['mlp'] = mae\n",
    "# accuracy_stats['predicted']['mlp'] = linear_predicted\n",
    "# accuracy_stats['mse']['mlp'] = mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMPLE LSTM\n",
    "\n",
    "Here we run our data through a simple lstm for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                                patience=40,\n",
    "                                                mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# define lstm network\n",
    "\n",
    "# lstm_model = tf.keras.models.Sequential([\n",
    "#     # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "#     tf.keras.layers.GRU(32, input_shape=(10), return_sequences=False),\n",
    "#     # Shape => [batch, time, features]\n",
    "#     tf.keras.layers.Dense(units=1)\n",
    "# ])\n",
    "\n",
    "ts_inputs = tf.keras.Input(shape=(10,num_vars))\n",
    "x = tf.keras.layers.LSTM(units=250, dropout=0.1, recurrent_dropout=0.1)(ts_inputs)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(1,activation='linear')(x)\n",
    "lstm_model = tf.keras.Model(inputs=ts_inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), \n",
    "                         tf.metrics.RootMeanSquaredError(), tf.metrics.MeanAbsolutePercentageError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 12)]          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 250)               263000    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 263,251\n",
      "Trainable params: 263,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lstm_model.fit(data_train_x_float32, \n",
    "                         data_train_y_float32_32_thread_reshaped,\n",
    "                         epochs=1000, \n",
    "                         validation_data=(data_valid_x_float32, \n",
    "                                          data_valid_y_float32_32_thread_reshaped), \n",
    "                         callbacks=[early_stopping],\n",
    "                         shuffle=False,\n",
    "                         verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_stats = lstm_model.evaluate(data_test_x_float32, data_test_y_float32_32_thread_reshaped)\n",
    "lstm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted = lstm_model.predict(data_test_x_float32).flatten()\n",
    "\n",
    "np.save('predicted_results/lstm_predicted.npy', lstm_predicted)\n",
    "np.savetxt('predicted_results/lstm_predicted.txt', lstm_predicted)\n",
    "lstm_model.save_weights('./checkpoints/lstm_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted = np.load('predicted_results/lstm_predicted.npy')#*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "# data_true = Data.test[1][:,0]*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "# def mean_absolute_percentage_error(y_true, y_pred): \n",
    "#   return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100\n",
    "lstm_mape = mean_absolute_percentage_error(data_test_y_float32_32_thread_reshaped, lstm_predicted)\n",
    "lstm_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_test_y_float32_32_thread_reshaped[0:500])\n",
    "plt.plot(lstm_predicted[0:500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_high = 500\n",
    "data_low = 0\n",
    "anomaly_index_list = SimpleAnomalyDetection(data_test_y_float32_32_thread_reshaped, lstm_predicted, data_high, data_low=data_low)\n",
    "\n",
    "anomaly_y_coords = []\n",
    "\n",
    "for x in anomaly_index_list:\n",
    "  anomaly_y_coords.append(data_test_y_float32_32_thread_reshaped[x])\n",
    "\n",
    "print(f\"The len of anomalyList: {len(anomaly_index_list)}\")\n",
    "colors = cm.rainbow(np.linspace(1, 1, len(anomaly_index_list)))\n",
    "plt.plot(data_test_y_float32_32_thread_reshaped[data_low:data_high])\n",
    "plt.plot(lstm_predicted[data_low:data_high])\n",
    "plt.scatter(anomaly_index_list, anomaly_y_coords, c=colors)\n",
    "\n",
    "plt.legend([\"Actual\", \"Anomoly Points\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 10))\n",
    "plt.plot(data_test_y_float32_32_thread_reshaped,label=\"actual\")\n",
    "plt.plot(lstm_predicted, color='r',label=\"predicted\")\n",
    "plt.legend(loc='best', fontsize='xx-large')\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(data_test_y_float32_32_thread_reshaped.flatten(), lstm_predicted)\n",
    "rmse = sqrt(mean_squared_error(data_test_y_float32_32_thread_reshaped.flatten(), lstm_predicted))\n",
    "mae = mean_absolute_error(data_test_y_float32_32_thread_reshaped.flatten(), lstm_predicted)\n",
    "rse_val = rse(data_test_y_float32_32_thread_reshaped.flatten(), lstm_predicted)\n",
    "mape = mean_absolute_percentage_error(data_test_y_float32_32_thread_reshaped.flatten(), lstm_predicted.flatten())\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "print(f'MAPE: {mape}')\n",
    "\n",
    "accuracy_stats['rmse']['lstm'] = rmse\n",
    "accuracy_stats['rse']['lstm'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['lstm'] = mae\n",
    "accuracy_stats['predicted']['lstm'] = lstm_predicted\n",
    "accuracy_stats['mse']['lstm'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.test[1][:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GRU\n",
    "\n",
    "Do the same thing but with a GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=40,\n",
    "                                                mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_inputs = tf.keras.Input(shape=(10,num_vars))\n",
    "x = tf.keras.layers.GRU(units=250, dropout=0.1)(ts_inputs)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(1,activation='linear')(x)\n",
    "gru_model = tf.keras.Model(inputs=ts_inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                  optimizer=tf.optimizers.Adam(),\n",
    "                  metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError(),\n",
    "                           tf.metrics.MeanAbsolutePercentageError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gru_model.fit(data_train_x_float32, \n",
    "              data_train_y_float32_32_thread_reshaped,\n",
    "              epochs=1000, \n",
    "              validation_data=(data_valid_x_float32, \n",
    "                              data_valid_y_float32_32_thread_reshaped), \n",
    "               callbacks=[early_stopping],\n",
    "               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.evaluate(data_test_x_float32, \n",
    "                   data_test_y_float32_32_thread_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_predicted = gru_model.predict(data_test_x_float32).flatten()\n",
    "\n",
    "np.save('predicted_results/gru_predicted.npy', gru_predicted)\n",
    "np.savetxt('predicted_results/gru_predicted.txt', gru_predicted)\n",
    "gru_model.save_weights('./checkpoints/gru_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gru_predicted = np.load('predicted_results/gru_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "# data_true = Data.test[1][:,0]*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "# def mean_absolute_percentage_error(y_true, y_pred): \n",
    "#   return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100\n",
    "# gru_mape = mean_absolute_percentage_error(data_true, gru_predicted)\n",
    "# gru_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_test_y_float32_32_thread_reshaped[0:100], label='actual')\n",
    "plt.plot(gru_predicted[0:100], label=\"predicted\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(data_test_y_float32_32_thread_reshaped.flatten(), gru_predicted)\n",
    "rmse = sqrt(mean_squared_error(data_test_y_float32_32_thread_reshaped.flatten(), gru_predicted))\n",
    "mae = mean_absolute_error(data_test_y_float32_32_thread_reshaped.flatten(), gru_predicted)\n",
    "rse_val = rse(data_test_y_float32_32_thread_reshaped.flatten(), gru_predicted)\n",
    "mape = mean_absolute_percentage_error(data_test_y_float32_32_thread_reshaped.flatten(), gru_predicted.flatten())\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "print(f'MAPE: {mape}')\n",
    "\n",
    "\n",
    "accuracy_stats['rmse']['gru'] = rmse\n",
    "accuracy_stats['rse']['gru'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['gru'] = mae\n",
    "accuracy_stats['predicted']['gru'] = gru_predicted\n",
    "accuracy_stats['mse']['gru'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_high = 2000\n",
    "data_low = 0\n",
    "anomaly_index_list = SimpleAnomalyDetection(data_test_y_float32_32_thread_reshaped, gru_predicted, data_high, data_low=data_low)\n",
    "\n",
    "anomaly_y_coords = []\n",
    "\n",
    "for x in anomaly_index_list:\n",
    "  anomaly_y_coords.append(data_test_y_float32_32_thread_reshaped[x])\n",
    "\n",
    "print(f\"The len of anomalyList: {len(anomaly_index_list)}\")\n",
    "colors = cm.rainbow(np.linspace(1, 1, len(anomaly_index_list)))\n",
    "plt.plot(data_test_y_float32_32_thread_reshaped[data_low:data_high])\n",
    "plt.plot(gru_predicted[data_low:data_high])\n",
    "plt.scatter(anomaly_index_list, anomaly_y_coords, c=colors)\n",
    "\n",
    "plt.legend([\"Actual\", \"Anomoly Points\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_y_float32_32_thread_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRange=1000\n",
    "\n",
    "plt.plot(data_test_y_float32_32_thread_reshaped[0:dataRange])\n",
    "plt.plot(gru_predicted[0:dataRange])\n",
    "plt.legend([\"Actual\", \"Predicted\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  patience=40,\n",
    "                                                  mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "\n",
    "\n",
    "# cnn_model = Sequential()\n",
    "# cnn_model.add(Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=(10, 3)))\n",
    "# cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "# cnn_model.add(Flatten())\n",
    "# cnn_model.add(Dense(50, activation='relu'))\n",
    "# cnn_model.add(Dense(1))\n",
    "# cnn_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=30, kernel_size=5, activation='relu', padding='SAME', strides=1, input_shape=(10, num_vars)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "cnn_model.add(Conv1D(filters=45, kernel_size=5, activation='relu', padding='SAME', strides=1))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "cnn_model.add(Conv1D(filters=60, kernel_size=5, activation='relu', padding='SAME', strides=1))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(120, activation='relu'))\n",
    "cnn_model.add(Dense(1))\n",
    "# cnn_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "              optimizer=tf.optimizers.Adam(),\n",
    "              metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError(), tf.metrics.MeanAbsolutePercentageError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_model.fit(data_train_x_float32, \n",
    "              data_train_y_float32_32_thread_reshaped,\n",
    "              epochs=1000, \n",
    "              validation_data=(data_valid_x_float32, \n",
    "                              data_valid_y_float32_32_thread_reshaped), \n",
    "              callbacks=[early_stopping],\n",
    "              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_stats = cnn_model.evaluate(data_test_x_float32, \n",
    "                               data_test_y_float32_32_thread_reshaped)\n",
    "cnn_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_predicted = cnn_model.predict(data_test_x_float32).flatten()\n",
    "\n",
    "np.save('predicted_results/cnn_predicted.npy', cnn_predicted)\n",
    "np.savetxt('predicted_results/cnn_predicted.txt', cnn_predicted)\n",
    "cnn_model.save_weights('./checkpoints/cnn_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_test_y_float32_32_thread_reshaped.flatten()[0:100], label='actual')\n",
    "plt.plot(cnn_predicted[0:100], label=\"predicted\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(data_test_y_float32_32_thread_reshaped.flatten(), cnn_predicted)\n",
    "rmse = sqrt(mean_squared_error(data_test_y_float32_32_thread_reshaped.flatten(), cnn_predicted))\n",
    "mae = mean_absolute_error(data_test_y_float32_32_thread_reshaped.flatten(), cnn_predicted)\n",
    "rse_val = rse(data_test_y_float32_32_thread_reshaped.flatten(), cnn_predicted)\n",
    "mape = mean_absolute_percentage_error(data_test_y_float32_32_thread_reshaped.flatten(), cnn_predicted.flatten())\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "print(f'MAPE: {mape}')\n",
    "\n",
    "accuracy_stats['rmse']['cnn'] = rmse\n",
    "accuracy_stats['rse']['cnn'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['cnn'] = mae\n",
    "accuracy_stats['predicted']['cnn'] = cnn_predicted\n",
    "accuracy_stats['mse']['cnn'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_predicted = np.load('predicted_results/cnn_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "# data_true = Data.test[1][:,0]*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "\n",
    "# cnn_mape = mean_absolute_percentage_error(data_true, cnn_predicted)\n",
    "# cnn_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_high = 2000\n",
    "data_low = 0\n",
    "anomaly_index_list = SimpleAnomalyDetection(data_test_y_float32_32_thread_reshaped, cnn_predicted, data_high, data_low=data_low)\n",
    "\n",
    "anomaly_y_coords = []\n",
    "\n",
    "for x in anomaly_index_list:\n",
    "  anomaly_y_coords.append(data_test_y_float32_32_thread_reshaped[x])\n",
    "\n",
    "print(f\"The len of anomalyList: {len(anomaly_index_list)}\")\n",
    "colors = cm.rainbow(np.linspace(1, 1, len(anomaly_index_list)))\n",
    "plt.plot(data_test_y_float32_32_thread_reshaped[data_low:data_high])\n",
    "plt.plot(cnn_predicted[data_low:data_high])\n",
    "plt.scatter(anomaly_index_list, anomaly_y_coords, c=colors)\n",
    "\n",
    "plt.legend([\"Actual\", \"Anomoly Points\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-LSTM HYBRID MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, Conv2D, LSTM, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model = Sequential()\n",
    "cnn_lstm_model.add(Conv1D(filters=64, kernel_size=5, activation='relu', padding='SAME', strides=1, input_shape=(10, num_vars)))\n",
    "cnn_lstm_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "cnn_lstm_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='SAME', strides=1))\n",
    "cnn_lstm_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "# cnn_lstm_model.add(Conv1D(filters=10, kernel_size=3, activation='relu', padding='SAME', strides=1))\n",
    "# cnn_lstm_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "# cnn_model.add(Flatten())\n",
    "cnn_lstm_model.add(LSTM(32, dropout=0.1, recurrent_dropout=0.1, return_sequences=False))\n",
    "cnn_lstm_model.add(Dense(100, activation='relu'))\n",
    "cnn_lstm_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                       optimizer=tf.optimizers.Adam(),\n",
    "                       metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_lstm_model.fit(data_train_x_float32, \n",
    "              data_train_y_float32_32_thread_reshaped,\n",
    "              epochs=1000, \n",
    "              validation_data=(data_valid_x_float32, \n",
    "                              data_valid_y_float32_32_thread_reshaped), \n",
    "              callbacks=[early_stopping],\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm1_stats = cnn_lstm_model.evaluate(data_test_x_float32, \n",
    "                               data_test_y_float32_32_thread_reshaped)\n",
    "cnn_lstm1_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_predicted = cnn_lstm_model.predict(data_test_x_float32).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_test_y_float32_32_thread_reshaped.flatten()[0:100], label='actual')\n",
    "plt.plot(cnn_lstm_predicted[0:100], label=\"predicted\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(data_test_y_float32_32_thread_reshaped.flatten(), cnn_lstm_predicted)\n",
    "rmse = sqrt(mean_squared_error(data_test_y_float32_32_thread_reshaped.flatten(), cnn_lstm_predicted))\n",
    "mae = mean_absolute_error(data_test_y_float32_32_thread_reshaped.flatten(), cnn_lstm_predicted)\n",
    "rse_val = rse(data_test_y_float32_32_thread_reshaped.flatten(), cnn_lstm_predicted)\n",
    "mape = mean_absolute_percentage_error(data_test_y_float32_32_thread_reshaped.flatten(), cnn_lstm_predicted.flatten())\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "print(f'MAPE: {mape}')\n",
    "\n",
    "\n",
    "accuracy_stats['rmse']['cnn_lstm'] = rmse\n",
    "accuracy_stats['rse']['cnn_lstm'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['cnn_lstm'] = mae\n",
    "accuracy_stats['predicted']['cnn_lstm'] = cnn_lstm_predicted\n",
    "accuracy_stats['mse']['cnn_lstm'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_high = 2000\n",
    "data_low = 0\n",
    "anomaly_index_list = SimpleAnomalyDetection(data_test_y_float32_32_thread_reshaped, cnn_lstm_predicted, data_high, data_low=data_low)\n",
    "\n",
    "anomaly_y_coords = []\n",
    "\n",
    "for x in anomaly_index_list:\n",
    "  anomaly_y_coords.append(data_test_y_float32_32_thread_reshaped[x])\n",
    "\n",
    "print(f\"The len of anomalyList: {len(anomaly_index_list)}\")\n",
    "colors = cm.rainbow(np.linspace(1, 1, len(anomaly_index_list)))\n",
    "plt.plot(data_test_y_float32_32_thread_reshaped[data_low:data_high])\n",
    "plt.plot(cnn_lstm_predicted[data_low:data_high])\n",
    "plt.scatter(anomaly_index_list, anomaly_y_coords, c=colors)\n",
    "\n",
    "plt.legend([\"Actual\", \"Anomoly Points\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_x_float32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=10,\n",
    "                                                mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, LSTM, MaxPooling2D, Reshape, TimeDistributed, Input, Dropout, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mc_shape\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'c_shape' is not defined"
     ]
    }
   ],
   "source": [
    "c_shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Input(shape = (10, num_vars))\n",
    "\n",
    "\n",
    "#CNN\n",
    "C = Reshape((10, num_vars, 1))(X)\n",
    "print(C.shape)\n",
    "# Apply a Conv2D that will transform it into data of dimensions (batchsize, time, 1, NumofFilters)\n",
    "C = Conv2D(filters=200, kernel_size=(1, num_vars), kernel_initializer='glorot_uniform')(C)\n",
    "print(C.shape)\n",
    "C = Dropout(0.2)(C)\n",
    "\n",
    "# Adjust data dimensions by removing axis=2 which is always equal to 1\n",
    "c_shape = K.int_shape(C)\n",
    "C = Reshape((c_shape[1], c_shape[3]))(C)\n",
    "\n",
    "# Apply a GRU layer (with activation set to 'relu' as per the paper) and take the returned states as result\n",
    "_, R = GRU(200, activation=\"relu\", return_sequences = False, return_state = True)(C)\n",
    "R    = Dropout(0.2)(R)\n",
    "Y = Flatten()(R)\n",
    "Y = Dense(3)(Y)\n",
    "cnn_lstm_model2 = Model(inputs = X, outputs = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model2.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                       optimizer=tf.optimizers.Adam(),\n",
    "                       metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError(), tf.metrics.MeanAbsolutePercentageError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.set_seed(123456)\n",
    "history = cnn_lstm_model2.fit(data_train_x_float32, \n",
    "                    data_train_y_float32_32_thread_reshaped,\n",
    "                    epochs=1000, \n",
    "                    validation_data=(data_valid_x_float32, \n",
    "                                    data_valid_y_float32_32_thread_reshaped), \n",
    "                    callbacks=[early_stopping],\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model2.evaluate(data_test_x_float32, \n",
    "                         data_test_y_float32_32_thread_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model2_predicted = cnn_lstm_model2.predict(data_test_x_float32)\n",
    "\n",
    "np.save('predicted_results/cnn_lstm_predicted.npy', cnn_lstm_model2_predicted)\n",
    "np.savetxt('predicted_results/cnn_lstm_predicted.txt', cnn_lstm_model2_predicted)\n",
    "cnn_lstm_model.save_weights('./checkpoints/cnn_lstm_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_test_y_float32_32_thread_reshaped[0:100], label='actual')\n",
    "plt.plot(cnn_lstm_model2_predicted[0:100,0], label=\"predicted\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_x_float32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model2_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_y_float32_32_thread_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(data_test_y_float32_32_thread_reshaped.flatten(), cnn_lstm_model2_predicted[:,0].flatten())\n",
    "rmse = sqrt(mean_squared_error(data_test_y_float32_32_thread_reshaped.flatten(), cnn_lstm_model2_predicted[:,0].flatten()))\n",
    "mae = mean_absolute_error(data_test_y_float32_32_thread_reshaped.flatten(), cnn_lstm_model2_predicted[:,0].flatten())\n",
    "rse_val = rse(data_test_y_float32_32_thread_reshaped.flatten(), cnn_lstm_model2_predicted[:,0].flatten())\n",
    "mape = mean_absolute_percentage_error(data_test_y_float32_32_thread_reshaped.flatten(), cnn_lstm_model2_predicted[:,0].flatten())\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "print(f'MAPE: {mape}')\n",
    "\n",
    "accuracy_stats['rmse']['cnn_lstm2'] = rmse\n",
    "accuracy_stats['rse']['cnn_lstm2'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['cnn_lstm2'] = mae\n",
    "accuracy_stats['predicted']['cnn_lstm2'] = cnn_lstm_model2_predicted\n",
    "accuracy_stats['mse']['cnn_lstm2'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_high = 2000\n",
    "data_low = 0\n",
    "anomaly_index_list = SimpleAnomalyDetection(data_test_y_float32_32_thread_reshaped, cnn_lstm_model2_predicted[:,0], data_high, data_low=data_low)\n",
    "\n",
    "anomaly_y_coords = []\n",
    "\n",
    "for x in anomaly_index_list:\n",
    "  anomaly_y_coords.append(data_test_y_float32_32_thread_reshaped[x])\n",
    "\n",
    "print(f\"The len of anomalyList: {len(anomaly_index_list)}\")\n",
    "colors = cm.rainbow(np.linspace(1, 1, len(anomaly_index_list)))\n",
    "plt.plot(data_test_y_float32_32_thread_reshaped[data_low:data_high])\n",
    "plt.plot(cnn_lstm_model2_predicted[data_low:data_high,0])\n",
    "plt.scatter(anomaly_index_list, anomaly_y_coords, c=colors)\n",
    "\n",
    "plt.legend([\"Actual\", \"Anomoly Points\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTNET MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, model_from_json\n",
    "\n",
    "custom_objects = {\n",
    "        'PreSkipTrans': PreSkipTrans,\n",
    "        'PostSkipTrans': PostSkipTrans,\n",
    "        'PreARTrans': PreARTrans,\n",
    "        'PostARTrans': PostARTrans\n",
    "        }\n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # print(\"CUSTOM LOSS BABBBY\")\n",
    "    # print(type(y_true))\n",
    "    # print(type(y_pred))\n",
    "    # print(y_true)\n",
    "    # print(y_true.shape)\n",
    "    # tf.print(y_true[:,0, sys.stdout)\n",
    "    return tf.keras.losses.mean_absolute_error(y_true[:,0], y_pred[:,0])\n",
    "\n",
    "file = 'models/model2.json'\n",
    "lstnet_model = None\n",
    "with open(file, \"r\") as json_file:\n",
    "  lstnet_model = model_from_json(json_file.read(), custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_model.compile(loss=custom_loss,\n",
    "                       optimizer=tf.optimizers.Adam(),\n",
    "                       metrics=[single_rse, single_corr, tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lstnet_model.fit(Data.train[0][:,:,:], Data.train[1][:,0], \n",
    "                   epochs=20, \n",
    "                   validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]), \n",
    "                   callbacks=[early_stopping],\n",
    "                   shuffle=True,\n",
    "                   batch_size=91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_model.evaluate(Data.test[0], Data.test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_predicted = lstnet_model.predict(Data.test[0])\n",
    "\n",
    "np.save('predicted_results/lstnet_predicted.npy', lstnet_predicted)\n",
    "np.savetxt('predicted_results/lstnet_predicted.txt', lstnet_predicted)\n",
    "lstnet_model.save_weights('./checkpoints/lstnet_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Data.test[1][0:100,0], label='actual')\n",
    "plt.plot(lstnet_predicted[0:100, 0], label=\"predicted\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "print(f'MSE: {mean_squared_error(Data.test[1][:,0], lstnet_predicted[:,0])}')\n",
    "print(f'RMSE: {sqrt(mean_squared_error(Data.test[1][:,0], lstnet_predicted[:,0]))}')\n",
    "print(f'MAE: {mean_absolute_error(Data.test[1][:,0], lstnet_predicted[:,0])}')\n",
    "print(f'RSE: {rse(Data.test[1][:,0], lstnet_predicted[:,0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.test[1][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_predicted[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(Data.test[1][:,0]*Data.normalize_std[0] + Data.normalize_mean[0], lstnet_predicted[:,0]*Data.normalize_std[0] + Data.normalize_mean[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between Different Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_predicted = np.load('predicted_results/mlp_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "lstm_predicted = np.load('predicted_results/lstm_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "gru_predicted = np.load('predicted_results/gru_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "cnn_predicted = np.load('predicted_results/cnn_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "cnn_lstm_predicted = np.load('predicted_results/cnn_lstm_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "lstnet_predicted = np.load('predicted_results/lstnet_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "\n",
    "data_true = Data.test[1][:,0]*Data.normalize_std[0] + Data.normalize_mean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "\n",
    "# Create cycler object. Use any styling from above you please\n",
    "monochrome = (cycler('color', ['k']) * cycler('linestyle', ['-', '--', ':']) * cycler('marker', ['^',',', '.']))\n",
    "\n",
    "# Print examples of output from cycler object. \n",
    "# A cycler object, when called, returns a `iter.cycle` object that iterates over items indefinitely\n",
    "\n",
    "default_cycler = (cycler(color=['black', 'r', 'b', 'y', 'teal', 'green', 'purple']) +\n",
    "                  cycler(linestyle=['-', '--', ':', '-.', '-.', '-', '--']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "cmap_1 = ListedColormap([\"darkorange\", \"gold\", \"lawngreen\", \"lightseagreen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 150\n",
    "end_time = 200\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "# plt.rc('axes', prop_cycle=default_cycler)\n",
    "# plt.style.use('grayscale')\n",
    "plt.plot(data_true[start_time:end_time], label='actual')\n",
    "plt.plot(mlp_predicted[start_time:end_time, 0], label=\"mlp\")\n",
    "plt.plot(lstm_predicted[start_time:end_time], label=\"lstm\")\n",
    "plt.plot(gru_predicted[start_time:end_time], label=\"gru\")\n",
    "plt.plot(cnn_predicted[start_time:end_time], label=\"cnn\")\n",
    "plt.plot(cnn_lstm_predicted[start_time:end_time, 0], label=\"cnn+gru\")\n",
    "plt.plot(lstnet_predicted[start_time:end_time, 0], label=\"lstnet\")\n",
    "plt.ylabel('Throughput (Mbits/sec)')\n",
    "plt.xlabel('Day')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_rmse = sqrt(mean_squared_error(data_true, mlp_predicted[:, 0]))\n",
    "mlp_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_rmse = sqrt(mean_squared_error(data_true, lstm_predicted))\n",
    "lstm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_rmse = sqrt(mean_squared_error(data_true, gru_predicted))\n",
    "gru_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_rmse = sqrt(mean_squared_error(data_true, cnn_predicted))\n",
    "cnn_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_rmse = sqrt(mean_squared_error(data_true, cnn_lstm_predicted[:, 0]))\n",
    "cnn_lstm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_rmse = sqrt(mean_squared_error(data_true, lstnet_predicted[:, 0]))\n",
    "lstnet_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[0.45, mlp_rmse, lstm_rmse, gru_rmse, cnn_rmse, cnn_lstm_rmse, lstnet_rmse])\n",
    "ax.set_xlabel('Model')\n",
    "\n",
    "ax.set_ylabel('Root Mean Squared Error (RMSE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mape = mean_absolute_percentage_error(data_true, mlp_predicted[:, 0])\n",
    "mlp_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mape = mean_absolute_percentage_error(data_true, lstm_predicted)\n",
    "lstm_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_mape = mean_absolute_percentage_error(data_true, gru_predicted)\n",
    "gru_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mape = mean_absolute_percentage_error(data_true, cnn_predicted)\n",
    "cnn_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_mape = mean_absolute_percentage_error(data_true, cnn_lstm_predicted[:, 0])\n",
    "cnn_lstm_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_mape = mean_absolute_percentage_error(data_true, lstnet_predicted[:, 0])\n",
    "lstnet_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[79, mlp_mape, lstm_mape, gru_mape, cnn_mape, cnn_lstm_mape, lstnet_mape])\n",
    "ax.set_xlabel('Model')\n",
    "# ax.set_ylim(0.0, 0.9)\n",
    "ax.set_ylabel('Mean Absolute Percentage Error (MAPE) %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_corr = corr(data_true, mlp_predicted[:, 0])\n",
    "mlp_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_corr = corr(data_true, lstm_predicted)\n",
    "lstm_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_corr = corr(data_true, gru_predicted)\n",
    "gru_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_corr = corr(data_true, cnn_predicted)\n",
    "cnn_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_corr = corr(data_true, cnn_lstm_predicted[:, 0])\n",
    "cnn_lstm_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_corr = corr(data_true, lstnet_predicted[:, 0])\n",
    "lstnet_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "scipy.stats.pearsonr(data_true, lstnet_predicted[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[0.88, mlp_corr, lstm_corr, gru_corr, cnn_corr, cnn_lstm_corr, lstnet_corr])\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylim(0.85, 0.95)\n",
    "ax.set_ylabel('Mean Absolute Percentage Error (MAPE) %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_r2 = r2_score(data_true, mlp_predicted[:, 0])\n",
    "lstm_r2 = r2_score(data_true, lstm_predicted)\n",
    "gru_r2 = r2_score(data_true, gru_predicted)\n",
    "cnn_r2 = r2_score(data_true, cnn_predicted)\n",
    "cnn_lstm_r2 = r2_score(data_true, cnn_lstm_predicted[:, 0])\n",
    "lstnet_r2 = r2_score(data_true, lstnet_predicted[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'mlp r2:     {mlp_r2}')\n",
    "print(f'lstm r2:    {lstm_r2}')\n",
    "print(f'gru r2:     {gru_r2}')\n",
    "print(f'cnn r2:     {cnn_r2}')\n",
    "print(f'cnn+gru r2: {cnn_lstm_r2}')\n",
    "print(f'lstnet r2:  {lstnet_r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RRSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_rrse = rse(data_true, mlp_predicted[:, 0])\n",
    "mlp_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_rrse = rse(data_true, lstm_predicted)\n",
    "lstm_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_rrse = rse(data_true, gru_predicted)\n",
    "gru_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_rrse = rse(data_true, cnn_predicted)\n",
    "cnn_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_rrse = rse(data_true, cnn_lstm_predicted[:, 0].flatten())\n",
    "cnn_lstm_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_rrse = rse(data_true, lstnet_predicted[:, 0].flatten())\n",
    "lstnet_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[0.79, mlp_rrse,lstm_rrse,gru_rrse,cnn_rrse,cnn_lstm_rrse,lstnet_rrse])\n",
    "ax.set_xlabel('Model')\n",
    "# ax.set_ylim(0.0, 0.9)\n",
    "ax.set_ylabel('Root Relative Squared Error (RRSE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mae = mean_absolute_error(data_true, mlp_predicted[:, 0])\n",
    "mlp_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mae = mean_absolute_error(data_true, lstm_predicted)\n",
    "lstm_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_mae = mean_absolute_error(data_true, gru_predicted)\n",
    "gru_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mae = mean_absolute_error(data_true, cnn_predicted)\n",
    "cnn_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_mae = mean_absolute_error(data_true, cnn_lstm_predicted[:, 0])\n",
    "cnn_lstm_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_mae = mean_absolute_error(data_true, lstnet_predicted[:, 0])\n",
    "lstnet_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[79, mlp_mae, lstm_mae, gru_mae, cnn_mae, cnn_lstm_mae, lstnet_mae])\n",
    "ax.set_xlabel('Model')\n",
    "# ax.set_ylim(0.0, 0.9)\n",
    "ax.set_ylabel('Mean Absolute Percentage Error (MAPE) %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSRE (root mean square relative error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mae = mean_absolute_error(data_true, mlp_predicted[:, 0])\n",
    "mlp_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mae = mean_absolute_error(data_true, lstm_predicted)\n",
    "lstm_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_mae = mean_absolute_error(data_true, gru_predicted)\n",
    "gru_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mae = mean_absolute_error(data_true, cnn_predicted)\n",
    "cnn_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_mae = mean_absolute_error(data_true, cnn_lstm_predicted[:, 0])\n",
    "cnn_lstm_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_mae = mean_absolute_error(data_true, lstnet_predicted[:, 0])\n",
    "lstnet_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[79, mlp_mae, lstm_mae, gru_mae, cnn_mae, cnn_lstm_mae, lstnet_mae])\n",
    "ax.set_xlabel('Model')\n",
    "# ax.set_ylim(0.0, 0.9)\n",
    "ax.set_ylabel('Mean Absolute Percentage Error (MAPE) %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDF of Relative Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_relative_error = (data_true - mlp_predicted[:, 0]) / data_true\n",
    "lstm_relative_error = (data_true - lstm_predicted) / data_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_residual_error = (data_true - mlp_predicted[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_relative_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mlp_relative_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 40\n",
    "counts, bin_edges = np.histogram (abs(mlp_relative_error), bins=num_bins, normed=True)\n",
    "cdf = np.cumsum (counts)\n",
    "plt.plot (bin_edges[1:], cdf/cdf[-1])\n",
    "counts, bin_edges = np.histogram (abs(lstm_relative_error), bins=num_bins, normed=True)\n",
    "cdf = np.cumsum (counts)\n",
    "plt.plot (bin_edges[1:], cdf/cdf[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_actual = np.load('predicted_results/arima_data_actual_multivar_1.npy')\n",
    "arima_predicted = np.load('predicted_results/arima_data_predictions_multivar_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(arima_actual[0:300])\n",
    "plt.plot(arima_predicted[0:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rrse = rse(arima_actual, arima_predicted)\n",
    "arima_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "arima_mae = mean_absolute_error(arima_actual, arima_predicted)\n",
    "arima_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100\n",
    "\n",
    "arima_mape = mean_absolute_percentage_error(arima_actual, arima_predicted)\n",
    "arima_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "arima_rmse = sqrt(mean_squared_error(arima_actual, arima_predicted))\n",
    "arima_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_corr = corr(arima_actual, arima_predicted)\n",
    "arima_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for all models on a single route (from test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = np.load('numpy_group_test_data/1_stream_test_sample_group_95.npy')\n",
    "test_target = np.load('numpy_group_test_data/1_stream_test_target_group_95.npy')\n",
    "\n",
    "normalize_mean = 9726.925995055048\n",
    "normalize_std  = 6670.752950995383\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm \n",
    "\n",
    "arma_mod = sm.tsa.ARIMA(test_target[:,0], order=(8,0,8))\n",
    "arma_res = arma_mod.fit(trend='nc', disp=-1)\n",
    "arma_predictions = arma_res.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model instance\n",
    "\n",
    "# Restore the weights\n",
    "linear.load_weights('./checkpoints/linear_weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_test_predict = linear.predict(test_sample)\n",
    "lstm_test_predict = lstm_model.predict(test_sample)\n",
    "gru_test_predict = gru_model.predict(test_sample)\n",
    "cnn_test_predict = cnn_model.predict(test_sample)\n",
    "cnn_lstm_test_predict = cnn_lstm_model.predict(test_sample)\n",
    "lstnet_test_predict = lstnet_model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "plt.plot(test_target[1:,0] * normalize_std + normalize_mean, label='actual')\n",
    "plt.plot(arma_predictions[1:] * normalize_std + normalize_mean, label='arima')\n",
    "plt.plot(linear_test_predict[1:] * normalize_std + normalize_mean, label='mlp')\n",
    "plt.plot(lstm_test_predict[1:] * normalize_std + normalize_mean, label='lstm')\n",
    "plt.plot(gru_test_predict[1:] * normalize_std + normalize_mean, label='gru')\n",
    "plt.plot(cnn_test_predict[1:] * normalize_std + normalize_mean, label='cnn')\n",
    "plt.plot(cnn_lstm_test_predict[1:,0] * normalize_std + normalize_mean, label='cnn+gru')\n",
    "plt.plot(lstnet_test_predict[1:,0] * normalize_std + normalize_mean, label='lstnet')\n",
    "plt.ylabel('Throughput (Mbits/sec)')\n",
    "plt.xlabel('Day')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(test_target[1:,0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
