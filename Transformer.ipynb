{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a17252-c270-4f37-a837-4db9ae8fde4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e8d258c-484e-48ef-bddd-d628672393b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is: [[-0.66439208 -0.37301463  0.04081512 ... -0.66439208 -1.0737958\n",
      "  -1.5643427 ]\n",
      " [ 0.63462859  0.37347448  0.03834345 ... -0.71488505 -0.56044294\n",
      "  -0.31908642]\n",
      " [ 0.11128392 -0.49912439 -1.0686291  ...  0.39446303  0.33940042\n",
      "   0.25539062]\n",
      " ...\n",
      " [-0.33316523 -0.29351853 -0.42534381 ... -1.3937145  -0.94273327\n",
      "  -0.27072168]\n",
      " [ 2.0791499   2.0220362   1.8675596  ... -0.43214504 -0.44123126\n",
      "  -0.28070891]\n",
      " [-0.32536268 -0.48823697 -0.59904489 ...  0.55576053  0.57445102\n",
      "   0.57311598]]\n",
      "y is: [-0.79717168  0.80485472  0.7279851  ... -0.57005428  2.0067321\n",
      " -0.12524091]\n",
      "x is: [[ 0.17164128  0.30204415  0.23280369 ... -0.69040244 -0.97659635\n",
      "  -0.79426313]\n",
      " [ 0.32225332  0.45384397  0.67185236 ... -1.0417721  -1.1596145\n",
      "  -1.3756589 ]\n",
      " [ 0.74436655  0.72591291  0.66132516 ... -3.6752806  -4.1366217\n",
      "  -4.3396117 ]\n",
      " ...\n",
      " [ 0.59397882  0.3818858   0.12728536 ... -0.12655282 -0.11782239\n",
      "  -0.18909413]\n",
      " [-0.14062427 -0.27059412 -0.37883494 ... -1.0007084  -1.0841075\n",
      "  -1.109963  ]\n",
      " [-0.24172258  0.10074086  0.46895321 ... -0.09362504 -0.90080431\n",
      "  -1.778341  ]]\n",
      "y is: [-0.14040239  0.33403756  0.71668608 ...  0.71008362  0.00684706\n",
      " -0.54135529]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
    "    y = data[:, 1]\n",
    "    x = data[:, 2:]\n",
    "    print(f\"x is: {x}\")\n",
    "    print(f\"y is: {y}\")\n",
    "    return x, y.astype(int)\n",
    "\n",
    "\n",
    "#root_url = \"data/\"\n",
    "#x_train, y_train = readucr(root_url + \"bq-results-train-data-only.csv\")\n",
    "#x_test, y_test = readucr(root_url + \"bq-results-train-data-only.csv\")\n",
    "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
    "\n",
    "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
    "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88f928a-e208-48c8-9e20-a00cbcdd0ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is: [[-0.66439208 -0.37301463  0.04081512 ... -0.66439208 -1.0737958\n",
      "  -1.5643427 ]\n",
      " [ 0.63462859  0.37347448  0.03834345 ... -0.71488505 -0.56044294\n",
      "  -0.31908642]\n",
      " [ 0.11128392 -0.49912439 -1.0686291  ...  0.39446303  0.33940042\n",
      "   0.25539062]\n",
      " ...\n",
      " [-0.33316523 -0.29351853 -0.42534381 ... -1.3937145  -0.94273327\n",
      "  -0.27072168]\n",
      " [ 2.0791499   2.0220362   1.8675596  ... -0.43214504 -0.44123126\n",
      "  -0.28070891]\n",
      " [-0.32536268 -0.48823697 -0.59904489 ...  0.55576053  0.57445102\n",
      "   0.57311598]]\n",
      "y is: [-0.79717168  0.80485472  0.7279851  ... -0.57005428  2.0067321\n",
      " -0.12524091]\n",
      "x is: [[ 0.17164128  0.30204415  0.23280369 ... -0.69040244 -0.97659635\n",
      "  -0.79426313]\n",
      " [ 0.32225332  0.45384397  0.67185236 ... -1.0417721  -1.1596145\n",
      "  -1.3756589 ]\n",
      " [ 0.74436655  0.72591291  0.66132516 ... -3.6752806  -4.1366217\n",
      "  -4.3396117 ]\n",
      " ...\n",
      " [ 0.59397882  0.3818858   0.12728536 ... -0.12655282 -0.11782239\n",
      "  -0.18909413]\n",
      " [-0.14062427 -0.27059412 -0.37883494 ... -1.0007084  -1.0841075\n",
      "  -1.109963  ]\n",
      " [-0.24172258  0.10074086  0.46895321 ... -0.09362504 -0.90080431\n",
      "  -1.778341  ]]\n",
      "y is: [-0.14040239  0.33403756  0.71668608 ...  0.71008362  0.00684706\n",
      " -0.54135529]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
    "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
    "\n",
    "\n",
    "#print(f\"x train is: {x_train.shape(0)}\")\n",
    "#print(f\"y train is: {y_train}\")\n",
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e63cfa4-c316-4acb-aea5-ddf1ad539458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train is: [[[-0.66439208]\n",
      "  [-0.37301463]\n",
      "  [ 0.04081512]\n",
      "  ...\n",
      "  [-0.66439208]\n",
      "  [-1.0737958 ]\n",
      "  [-1.5643427 ]]\n",
      "\n",
      " [[ 0.63462859]\n",
      "  [ 0.37347448]\n",
      "  [ 0.03834345]\n",
      "  ...\n",
      "  [-0.71488505]\n",
      "  [-0.56044294]\n",
      "  [-0.31908642]]\n",
      "\n",
      " [[ 0.11128392]\n",
      "  [-0.49912439]\n",
      "  [-1.0686291 ]\n",
      "  ...\n",
      "  [ 0.39446303]\n",
      "  [ 0.33940042]\n",
      "  [ 0.25539062]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.33316523]\n",
      "  [-0.29351853]\n",
      "  [-0.42534381]\n",
      "  ...\n",
      "  [-1.3937145 ]\n",
      "  [-0.94273327]\n",
      "  [-0.27072168]]\n",
      "\n",
      " [[ 2.0791499 ]\n",
      "  [ 2.0220362 ]\n",
      "  [ 1.8675596 ]\n",
      "  ...\n",
      "  [-0.43214504]\n",
      "  [-0.44123126]\n",
      "  [-0.28070891]]\n",
      "\n",
      " [[-0.32536268]\n",
      "  [-0.48823697]\n",
      "  [-0.59904489]\n",
      "  ...\n",
      "  [ 0.55576053]\n",
      "  [ 0.57445102]\n",
      "  [ 0.57311598]]]\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "print(f\"x train is: {x_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14d64572-a4b6-4646-aa28-f0f6cfdfb873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(np.unique(y_train))\n",
    "print(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f88a679-b955-410c-911f-4912a931beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(len(x_train))\n",
    "x_train = x_train[idx]\n",
    "y_train = y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3f351fd-ca4b-401d-b52d-acd2824df5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == -1] = 0\n",
    "y_test[y_test == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "205ed189-3331-444d-b08e-70e04ed82b25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: [[[-0.3456689 ]\n",
      "  [-0.75012875]\n",
      "  [-1.125885  ]\n",
      "  ...\n",
      "  [ 0.91207076]\n",
      "  [ 0.9172896 ]\n",
      "  [ 0.87032006]]\n",
      "\n",
      " [[ 1.2169933 ]\n",
      "  [ 1.5955059 ]\n",
      "  [ 1.6901341 ]\n",
      "  ...\n",
      "  [ 0.46091429]\n",
      "  [ 1.3400099 ]\n",
      "  [ 1.9361673 ]]\n",
      "\n",
      " [[ 1.6622896 ]\n",
      "  [ 1.3117216 ]\n",
      "  [ 0.76864539]\n",
      "  ...\n",
      "  [-0.14378917]\n",
      "  [ 0.26509931]\n",
      "  [ 0.67144833]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.03842955]\n",
      "  [-0.03604911]\n",
      "  [-0.14474174]\n",
      "  ...\n",
      "  [ 2.228234  ]\n",
      "  [ 2.2337347 ]\n",
      "  [ 2.0797168 ]]\n",
      "\n",
      " [[ 1.0147185 ]\n",
      "  [ 0.92108795]\n",
      "  [ 0.73781112]\n",
      "  ...\n",
      "  [-1.2224541 ]\n",
      "  [-1.1148785 ]\n",
      "  [-0.87382966]]\n",
      "\n",
      " [[-0.17637349]\n",
      "  [-0.62232784]\n",
      "  [-0.9604686 ]\n",
      "  ...\n",
      "  [ 0.23260053]\n",
      "  [ 0.05249432]\n",
      "  [-0.15635623]]]\n",
      "y_train: [0 0 1 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train: {x_train}\")\n",
    "print(f\"y_train: {y_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70f10ee3-e50d-4cd0-83b2-7080a49221e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47fb7edf-d52d-4eaf-8cf6-803a5975004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c664cff4-c46f-4b5e-b358-894f5a638738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faa1fcbd-ce84-47e3-aeae-ced9a7642f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: [[[-0.3456689 ]\n",
      "  [-0.75012875]\n",
      "  [-1.125885  ]\n",
      "  ...\n",
      "  [ 0.91207076]\n",
      "  [ 0.9172896 ]\n",
      "  [ 0.87032006]]\n",
      "\n",
      " [[ 1.2169933 ]\n",
      "  [ 1.5955059 ]\n",
      "  [ 1.6901341 ]\n",
      "  ...\n",
      "  [ 0.46091429]\n",
      "  [ 1.3400099 ]\n",
      "  [ 1.9361673 ]]\n",
      "\n",
      " [[ 1.6622896 ]\n",
      "  [ 1.3117216 ]\n",
      "  [ 0.76864539]\n",
      "  ...\n",
      "  [-0.14378917]\n",
      "  [ 0.26509931]\n",
      "  [ 0.67144833]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.03842955]\n",
      "  [-0.03604911]\n",
      "  [-0.14474174]\n",
      "  ...\n",
      "  [ 2.228234  ]\n",
      "  [ 2.2337347 ]\n",
      "  [ 2.0797168 ]]\n",
      "\n",
      " [[ 1.0147185 ]\n",
      "  [ 0.92108795]\n",
      "  [ 0.73781112]\n",
      "  ...\n",
      "  [-1.2224541 ]\n",
      "  [-1.1148785 ]\n",
      "  [-0.87382966]]\n",
      "\n",
      " [[-0.17637349]\n",
      "  [-0.62232784]\n",
      "  [-0.9604686 ]\n",
      "  ...\n",
      "  [ 0.23260053]\n",
      "  [ 0.05249432]\n",
      "  [-0.15635623]]]\n"
     ]
    }
   ],
   "source": [
    "#print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"x_train shape: {x_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe363ce8-6ef0-480d-8147-c9c4e63e059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: <class 'tuple'>\n",
      "x_train shape: (499, 1)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 499, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 499, 1)      2           ['input_1[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 499, 1)      7169        ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 499, 1)       0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 499, 1)      0           ['dropout[0][0]',                \n",
      " da)                                                              'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 499, 1)      2           ['tf.__operators__.add[0][0]']   \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 499, 4)       8           ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 499, 4)       0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 499, 1)       5           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 499, 1)      0           ['conv1d_1[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 499, 1)      2           ['tf.__operators__.add_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 499, 1)      7169        ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 499, 1)       0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 499, 1)      0           ['dropout_2[0][0]',              \n",
      " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 499, 1)      2           ['tf.__operators__.add_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 499, 4)       8           ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 499, 4)       0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 499, 1)       5           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 499, 1)      0           ['conv1d_3[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 499, 1)      2           ['tf.__operators__.add_3[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 499, 1)      7169        ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 499, 1)       0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 499, 1)      0           ['dropout_4[0][0]',              \n",
      " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 499, 1)      2           ['tf.__operators__.add_4[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 499, 4)       8           ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 499, 4)       0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 499, 1)       5           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 499, 1)      0           ['conv1d_5[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 499, 1)      2           ['tf.__operators__.add_5[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 499, 1)      7169        ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 499, 1)       0           ['multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 499, 1)      0           ['dropout_6[0][0]',              \n",
      " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 499, 1)      2           ['tf.__operators__.add_6[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 499, 4)       8           ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 499, 4)       0           ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 499, 1)       5           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 499, 1)      0           ['conv1d_7[0][0]',               \n",
      " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 499)         0           ['tf.__operators__.add_7[0][0]'] \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          64000       ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 7)            903         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 93,647\n",
      "Trainable params: 93,647\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      " 1/45 [..............................] - ETA: 8:43 - loss: 3.0104 - sparse_categorical_accuracy: 0.0625"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Received a label value of -2 which is outside the valid range of [0, 7).  Label values: 0 -2 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 -2 0 0 0 0 0 0 0 -2 0 0 0 0 0 0 -2 0 0 0 0 0 0 0 0 0 1 0 0 0 -2 0 0 0 0 0 0 0 1 1 0 0\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n (defined at C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py:5113)\n]] [Op:__inference_train_function_5012]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:\nIn[0] sparse_categorical_crossentropy/Reshape_1 (defined at C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py:5109)\t\nIn[1] sparse_categorical_crossentropy/Reshape (defined at C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py:3561)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 381, in dispatch_queue\n>>>     yield self.process_one()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 250, in wrapper\n>>>     runner = Runner(ctx_run, result, future, yielded)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 741, in __init__\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-16-de6afb484236>\", line 25, in <module>\n>>>     model.fit(\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n>>>     loss = self.compiled_loss(\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1737, in sparse_categorical_crossentropy\n>>>     return backend.sparse_categorical_crossentropy(\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5113, in sparse_categorical_crossentropy\n>>>     res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-de6afb484236>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  Received a label value of -2 which is outside the valid range of [0, 7).  Label values: 0 -2 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 -2 0 0 0 0 0 0 0 -2 0 0 0 0 0 0 -2 0 0 0 0 0 0 0 0 0 1 0 0 0 -2 0 0 0 0 0 0 0 1 1 0 0\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n (defined at C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py:5113)\n]] [Op:__inference_train_function_5012]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:\nIn[0] sparse_categorical_crossentropy/Reshape_1 (defined at C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py:5109)\t\nIn[1] sparse_categorical_crossentropy/Reshape (defined at C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py:3561)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 381, in dispatch_queue\n>>>     yield self.process_one()\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 250, in wrapper\n>>>     runner = Runner(ctx_run, result, future, yielded)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 741, in __init__\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-16-de6afb484236>\", line 25, in <module>\n>>>     model.fit(\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n>>>     loss = self.compiled_loss(\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1737, in sparse_categorical_crossentropy\n>>>     return backend.sparse_categorical_crossentropy(\n>>> \n>>>   File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5113, in sparse_categorical_crossentropy\n>>>     res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n>>> "
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "print(f\"x_train shape: {type(x_train.shape[1:])}\")\n",
    "print(f\"x_train shape: {x_train.shape[1:]}\")\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374ab6a8-27b7-4f6a-bcfd-0246a9be47c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
