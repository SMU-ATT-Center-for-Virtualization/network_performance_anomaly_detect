{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/examples/timeseries/timeseries_transformer_classification/\n",
    "logger_name = \"lstnet\"\n",
    "\n",
    "# Path appended in order to import from util\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from util.model_util import LoadModel, SaveModel, SaveResults, SaveHistory\n",
    "# from util.Msglog import LogInit\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "#from lstnet_util import GetArguments, LSTNetInit\n",
    "from pandas_data_util import DataUtil\n",
    "#from lstnet_model import PreSkipTrans, PostSkipTrans, PreARTrans, PostARTrans, LSTNetModel, ModelCompile\n",
    "#from lstnet_plot import AutoCorrelationPlot, PlotHistory, PlotPrediction\n",
    "\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\n",
    "    device_type=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and process it using DataUtil\n",
    "look at pandas_util for more info about this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/users/dphanekham/network_performance_anomaly_detect/pandas_data_util.py:71: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,14,20,45,82,83,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, dtype={\"ping_average_latency\": float,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['run_uri', 'vm_1_cloud', 'vm_2_cloud', 'sending_zone', 'receiving_zone',\n",
      "       'vm_1_machine_type', 'vm_2_machine_type', 'ip_type',\n",
      "       'vm_1_gce_network_tier', 'vm_2_gce_network_tier',\n",
      "       ...\n",
      "       'sending_zone_hour_sin', 'receiving_zone_hour_cos',\n",
      "       'receiving_zone_hour_sin', 'kernel_version', 'n1-standard-16',\n",
      "       'external', 'internal', 'vm_1_os_info_trunc', 'bbr', 'cubic'],\n",
      "      dtype='object', length=109)\n"
     ]
    }
   ],
   "source": [
    "# Reading data\n",
    "filename = 'data/bq_results_09082022.csv'\n",
    "trainpercent = 0.6\n",
    "validpercent = 0.2\n",
    "horizon=0\n",
    "window=10\n",
    "normalize=0\n",
    "\n",
    "# query='vm_1_gce_network_tier == \"premium\"'\n",
    "query = 'vm_1_gce_network_tier == \"premium\" and vm_1_machine_type == \"n1-standard-16\" and ip_type == \"internal\" and tcp_congestion_control == \"bbr\" and sending_zone != \"asia-east2-a\"'\n",
    "\n",
    "Data = DataUtil(filename,\n",
    "                trainpercent,\n",
    "                validpercent,\n",
    "                horizon,\n",
    "                window,\n",
    "                normalize=normalize,\n",
    "                query=query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21956, 10, 14)\n"
     ]
    }
   ],
   "source": [
    "print(Data.train[0].shape)\n",
    "# print(Data.train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=10,\n",
    "                                                mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_col_top = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pandas_datetime',\n",
       " 'iperf_throughput_1_thread',\n",
       " 'iperf_throughput_32_threads',\n",
       " 'ping_average_latency',\n",
       " 'tcp_max_receive_buffer',\n",
       " 'sending_zone_day_cos',\n",
       " 'sending_zone_day_sin',\n",
       " 'receiving_zone_day_cos',\n",
       " 'receiving_zone_day_sin',\n",
       " 'sending_zone_hour_cos',\n",
       " 'sending_zone_hour_sin',\n",
       " 'receiving_zone_hour_cos',\n",
       " 'receiving_zone_hour_sin',\n",
       " 'kernel_version']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_data_columns = Data.columns[1:data_col_top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iperf_throughput_1_thread',\n",
       " 'iperf_throughput_32_threads',\n",
       " 'ping_average_latency',\n",
       " 'tcp_max_receive_buffer',\n",
       " 'sending_zone_day_cos',\n",
       " 'sending_zone_day_sin',\n",
       " 'receiving_zone_day_cos',\n",
       " 'receiving_zone_day_sin',\n",
       " 'sending_zone_hour_cos',\n",
       " 'sending_zone_hour_sin',\n",
       " 'receiving_zone_hour_cos',\n",
       " 'receiving_zone_hour_sin']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_data_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = len(adjusted_data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_x_float32 = np.array(list(Data.train[0][:,:,1:data_col_top])).astype(np.float32)\n",
    "data_train_y_float32 = np.array(list(Data.train[1][:,1:data_col_top])).astype(np.float32)\n",
    "data_train_y_float32_32_thread_reshaped = data_train_y_float32[:,1].reshape(data_train_y_float32[:,1].shape[0],1)\n",
    "data_train_y_float32_1_thread_reshaped = data_train_y_float32[:,0].reshape(data_train_y_float32[:,0].shape[0],1)\n",
    "\n",
    "data_valid_x_float32 = np.array(list(Data.valid[0][:,:,1:data_col_top])).astype(np.float32)\n",
    "data_valid_y_float32 = np.array(list(Data.valid[1][:,1:data_col_top])).astype(np.float32)\n",
    "data_valid_y_float32_32_thread_reshaped = data_valid_y_float32[:,1].reshape(data_valid_y_float32[:,1].shape[0],1)\n",
    "data_valid_y_float32_1_thread_reshaped = data_valid_y_float32[:,0].reshape(data_valid_y_float32[:,0].shape[0],1)\n",
    "\n",
    "data_test_x_float32 = np.array(list(Data.test[0][:,:,1:data_col_top])).astype(np.float32)\n",
    "data_test_y_float32 = np.array(list(Data.test[1][:,1:data_col_top])).astype(np.float32)\n",
    "data_test_y_float32_32_thread_reshaped = data_test_y_float32[:,1].reshape(data_test_y_float32[:,1].shape[0],1)\n",
    "data_test_y_float32_1_thread_reshaped = data_test_y_float32[:,0].reshape(data_test_y_float32[:,0].shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = {}\n",
    "accuracy_stats['rmse'] = {}\n",
    "accuracy_stats['rse'] = {}\n",
    "accuracy_stats['corr'] = {}\n",
    "accuracy_stats['accuracy'] = {}\n",
    "accuracy_stats['mae'] = {}\n",
    "accuracy_stats['predicted'] = {}\n",
    "accuracy_stats['mse'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def SimpleAnomalyDetection(actual, predicted, data_high, data_low=0, threshold=3):\n",
    "  # Finds average difference for entire data range\n",
    "  # if point is more different than this, it is an anomaly\n",
    "  # return anomaly list\n",
    "\n",
    "  anomaly_index_list = []\n",
    "  count = 0\n",
    "  total=0\n",
    "  for x in range(data_low, data_high):\n",
    "      difference = abs(actual[x]-predicted[x])\n",
    "      total = difference + total\n",
    "      count += 1\n",
    "  average = total / count\n",
    "  print(f\"The Average is: {average}\")\n",
    "  count = 0\n",
    "  for x in range(data_low, data_high):\n",
    "      difference = abs(actual[x]-predicted[x])\n",
    "      if difference > threshold*average:\n",
    "          # anomaly_list.append(data_test_y_float32_32_thread_reshaped[x])\n",
    "          # anomaly_list_x_coords.append(count)\n",
    "          anomaly_index_list.append(x)\n",
    "      count += 1\n",
    "  print(anomaly_index_list)\n",
    "  return anomaly_index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some error metrics we can use that aren't in tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Root relative squared error\n",
    "def tf_rse(y_true, y_pred):\n",
    "    #\n",
    "    # The formula is:\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred)))     \n",
    "    #    RSE = -----------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)))       \n",
    "    #\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred))/(N-1))\n",
    "    #        = ----------------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)/(N-1)))\n",
    "    #\n",
    "    #\n",
    "    #           K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    #        = ------------------------------------------\n",
    "    #           K.std(y_true)\n",
    "    #\n",
    "    num = K.sqrt(K.mean(K.square(y_true - y_pred), axis=None))\n",
    "    den = K.std(y_true, axis=None)\n",
    "    \n",
    "    return num / den\n",
    "\n",
    "def rse_test1(y_true, y_pred):\n",
    "    return K.square(y_true - y_pred)\n",
    "\n",
    "def rse_test2(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred), axis=None))\n",
    "\n",
    "def rse_test3(y_true, y_pred):\n",
    "    return K.std(y_true, axis=None)\n",
    "\n",
    "def rse(y_true, y_pred):\n",
    "    #\n",
    "    # The formula is:\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred)))     \n",
    "    #    RSE = -----------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)))       \n",
    "    #\n",
    "    #           K.sqrt(K.sum(K.square( y_true - y_pred))/(N-1))\n",
    "    #        = ----------------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)/(N-1)))\n",
    "    #\n",
    "    #\n",
    "    #           K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    #        = ------------------------------------------\n",
    "    #           K.std(y_true)\n",
    "    #\n",
    "    num = np.sqrt(np.mean(np.square(y_true - y_pred), axis=None))\n",
    "    den = np.std(y_true, axis=None)\n",
    "    \n",
    "    return num / den\n",
    "\n",
    "def tf_corr(y_true, y_pred):\n",
    "    #\n",
    "    # This function calculates the correlation between the true and the predicted outputs\n",
    "    #\n",
    "    num1 = y_true - K.mean(y_true, axis=0)\n",
    "    num2 = y_pred - K.mean(y_pred, axis=0)\n",
    "    \n",
    "    num  = K.mean(num1 * num2, axis=0)\n",
    "    den  = K.std(y_true, axis=0) * K.std(y_pred, axis=0)\n",
    "    \n",
    "    return K.mean(num / den)\n",
    "\n",
    "def corr(y_true, y_pred):\n",
    "    #\n",
    "    # This function calculates the correlation between the true and the predicted outputs\n",
    "    #\n",
    "    num1 = y_true - np.mean(y_true, axis=0)\n",
    "    num2 = y_pred - np.mean(y_pred, axis=0)\n",
    "    \n",
    "    num  = np.mean(num1 * num2, axis=0)\n",
    "    den  = np.std(y_true, axis=0) * np.std(y_pred, axis=0)\n",
    "    \n",
    "    return np.mean(num / den)\n",
    "\n",
    "def single_rse(y_true, y_pred):\n",
    "    #\n",
    "    # The formula is:\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred)))     \n",
    "    #    RSE = -----------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)))       \n",
    "    #\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred))/(N-1))\n",
    "    #        = ----------------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)/(N-1)))\n",
    "    #\n",
    "    #\n",
    "    #           K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    #        = ------------------------------------------\n",
    "    #           K.std(y_true)\n",
    "    #\n",
    "    num = K.sqrt(K.mean(K.square(y_true[:,0] - y_pred[:,0]), axis=None))\n",
    "    den = K.std(y_true, axis=None)\n",
    "    \n",
    "    return num / den\n",
    "\n",
    "\n",
    "def single_corr(y_true, y_pred):\n",
    "    #\n",
    "    # This function calculates the correlation between the true and the predicted outputs\n",
    "    #\n",
    "    num1 = y_true[:,0] - K.mean(y_true[:,0], axis=0)\n",
    "    num2 = y_pred[:,0] - K.mean(y_pred[:,0], axis=0)\n",
    "    \n",
    "    num  = K.mean(num1 * num2, axis=0)\n",
    "    den  = K.std(y_true[:,0], axis=0) * K.std(y_pred[:,0], axis=0)\n",
    "    \n",
    "    return K.mean(num / den)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our Transformer Model with Time series embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vec(keras.layers.Layer):\n",
    "    def __init__(self, kernel_size=1):\n",
    "        super(Time2Vec, self).__init__(trainable=True, name='Time2VecLayer')\n",
    "        self.k = kernel_size\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # trend\n",
    "        self.wb = self.add_weight(name='wb',shape=(input_shape[1],),initializer='uniform',trainable=True)\n",
    "        self.bb = self.add_weight(name='bb',shape=(input_shape[1],),initializer='uniform',trainable=True)\n",
    "        # periodic\n",
    "        self.wa = self.add_weight(name='wa',shape=(1, input_shape[1], self.k),initializer='uniform',trainable=True)\n",
    "        self.ba = self.add_weight(name='ba',shape=(1, input_shape[1], self.k),initializer='uniform',trainable=True)\n",
    "        super(Time2Vec, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs, **kwargs):\n",
    "        bias = self.wb * inputs + self.bb\n",
    "        dp = K.dot(inputs, self.wa) + self.ba\n",
    "        wgts = K.sin(dp) # or K.cos(.)\n",
    "\n",
    "        ret = K.concatenate([K.expand_dims(bias, -1), wgts], -1)\n",
    "        ret = K.reshape(ret, (-1, inputs.shape[1]*(self.k+1)))\n",
    "        return ret\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1]*(self.k + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_batch = Data.train[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t2v = Time2Vec()\n",
    "# t2v.compute_output_shape(sample_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = tf.math.reduce_mean(sample_batch[:,:,:3], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Attention and Normalization\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape,\n",
    "                head_size,\n",
    "                num_heads,\n",
    "                ff_dim,\n",
    "                num_transformer_blocks,\n",
    "                mlp_units,\n",
    "                dropout=0,\n",
    "                mlp_dropout=0):\n",
    "    time2vec = Time2Vec(kernel_size=num_vars)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    time_embedding = layers.TimeDistributed(time2vec)(inputs)\n",
    "    x = K.concatenate([inputs, time_embedding], -1)\n",
    "\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(1,activation='linear')(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and test Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 10, 12)]     0           []                               \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 10, 156)     312         ['input_2[0][0]']                \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 10, 168)      0           ['input_2[0][0]',                \n",
      "                                                                  'time_distributed_1[0][0]']     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 10, 168)     691368      ['tf.concat_1[0][0]',            \n",
      " eadAttention)                                                    'tf.concat_1[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 10, 168)      0           ['multi_head_attention_4[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 10, 168)     336         ['dropout_9[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 10, 168)     0           ['layer_normalization_8[0][0]',  \n",
      " mbda)                                                            'tf.concat_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 10, 4)        676         ['tf.__operators__.add_8[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 10, 4)        0           ['conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 10, 168)      840         ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 10, 168)     336         ['conv1d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TFOpLa  (None, 10, 168)     0           ['layer_normalization_9[0][0]',  \n",
      " mbda)                                                            'tf.__operators__.add_8[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 10, 168)     691368      ['tf.__operators__.add_9[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_9[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 10, 168)      0           ['multi_head_attention_5[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 10, 168)     336         ['dropout_11[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (TFOpL  (None, 10, 168)     0           ['layer_normalization_10[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_9[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 10, 4)        676         ['tf.__operators__.add_10[0][0]']\n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 10, 4)        0           ['conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 10, 168)      840         ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 10, 168)     336         ['conv1d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  (None, 10, 168)     0           ['layer_normalization_11[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_10[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 10, 168)     691368      ['tf.__operators__.add_11[0][0]',\n",
      " eadAttention)                                                    'tf.__operators__.add_11[0][0]']\n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 10, 168)      0           ['multi_head_attention_6[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 10, 168)     336         ['dropout_13[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (TFOpL  (None, 10, 168)     0           ['layer_normalization_12[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_11[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 10, 4)        676         ['tf.__operators__.add_12[0][0]']\n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 10, 4)        0           ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 10, 168)      840         ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 10, 168)     336         ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (TFOpL  (None, 10, 168)     0           ['layer_normalization_13[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_12[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 10, 168)     691368      ['tf.__operators__.add_13[0][0]',\n",
      " eadAttention)                                                    'tf.__operators__.add_13[0][0]']\n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 10, 168)      0           ['multi_head_attention_7[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 10, 168)     336         ['dropout_15[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (TFOpL  (None, 10, 168)     0           ['layer_normalization_14[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_13[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 10, 4)        676         ['tf.__operators__.add_14[0][0]']\n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 10, 4)        0           ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 10, 168)      840         ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 10, 168)     336         ['conv1d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (TFOpL  (None, 10, 168)     0           ['layer_normalization_15[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_14[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 10)          0           ['tf.__operators__.add_15[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          1408        ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 128)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            129         ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,776,073\n",
      "Trainable params: 2,776,073\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "687/687 [==============================] - 23s 26ms/step - loss: 54.4188 - tf_rse: 0.9969 - tf_corr: 0.5795 - mean_absolute_error: 0.4117 - mean_squared_error: 0.2777 - root_mean_squared_error: 0.5269 - mean_absolute_percentage_error: 54.4188 - val_loss: 39.5484 - val_tf_rse: 1.1135 - val_tf_corr: 0.1027 - val_mean_absolute_error: 0.2106 - val_mean_squared_error: 0.0825 - val_root_mean_squared_error: 0.2873 - val_mean_absolute_percentage_error: 39.5484\n",
      "Epoch 2/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 35.8907 - tf_rse: 0.6391 - tf_corr: 0.7870 - mean_absolute_error: 0.2320 - mean_squared_error: 0.0958 - root_mean_squared_error: 0.3095 - mean_absolute_percentage_error: 35.8907 - val_loss: 40.1219 - val_tf_rse: 1.1920 - val_tf_corr: 0.1035 - val_mean_absolute_error: 0.2271 - val_mean_squared_error: 0.0910 - val_root_mean_squared_error: 0.3016 - val_mean_absolute_percentage_error: 40.1219\n",
      "Epoch 3/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 35.6299 - tf_rse: 0.6284 - tf_corr: 0.7969 - mean_absolute_error: 0.2283 - mean_squared_error: 0.0928 - root_mean_squared_error: 0.3047 - mean_absolute_percentage_error: 35.6299 - val_loss: 41.6655 - val_tf_rse: 1.2731 - val_tf_corr: 0.0733 - val_mean_absolute_error: 0.2452 - val_mean_squared_error: 0.1115 - val_root_mean_squared_error: 0.3339 - val_mean_absolute_percentage_error: 41.6655\n",
      "Epoch 4/1000\n",
      "687/687 [==============================] - 16s 23ms/step - loss: 34.8858 - tf_rse: 0.6128 - tf_corr: 0.7963 - mean_absolute_error: 0.2228 - mean_squared_error: 0.0892 - root_mean_squared_error: 0.2987 - mean_absolute_percentage_error: 34.8858 - val_loss: 39.2854 - val_tf_rse: 1.3575 - val_tf_corr: 0.0983 - val_mean_absolute_error: 0.2610 - val_mean_squared_error: 0.1100 - val_root_mean_squared_error: 0.3317 - val_mean_absolute_percentage_error: 39.2854\n",
      "Epoch 5/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 34.8863 - tf_rse: 0.6158 - tf_corr: 0.8040 - mean_absolute_error: 0.2251 - mean_squared_error: 0.0899 - root_mean_squared_error: 0.2999 - mean_absolute_percentage_error: 34.8863 - val_loss: 38.6812 - val_tf_rse: 1.2273 - val_tf_corr: 0.0960 - val_mean_absolute_error: 0.2346 - val_mean_squared_error: 0.0960 - val_root_mean_squared_error: 0.3098 - val_mean_absolute_percentage_error: 38.6812\n",
      "Epoch 6/1000\n",
      "687/687 [==============================] - 18s 25ms/step - loss: 34.6898 - tf_rse: 0.6167 - tf_corr: 0.8043 - mean_absolute_error: 0.2254 - mean_squared_error: 0.0904 - root_mean_squared_error: 0.3007 - mean_absolute_percentage_error: 34.6898 - val_loss: 38.4381 - val_tf_rse: 1.1408 - val_tf_corr: 0.1081 - val_mean_absolute_error: 0.2166 - val_mean_squared_error: 0.0866 - val_root_mean_squared_error: 0.2943 - val_mean_absolute_percentage_error: 38.4381\n",
      "Epoch 7/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 34.0936 - tf_rse: 0.6037 - tf_corr: 0.8095 - mean_absolute_error: 0.2215 - mean_squared_error: 0.0882 - root_mean_squared_error: 0.2970 - mean_absolute_percentage_error: 34.0936 - val_loss: 40.6412 - val_tf_rse: 1.2544 - val_tf_corr: 0.0987 - val_mean_absolute_error: 0.2399 - val_mean_squared_error: 0.0976 - val_root_mean_squared_error: 0.3124 - val_mean_absolute_percentage_error: 40.6412\n",
      "Epoch 8/1000\n",
      "687/687 [==============================] - 18s 26ms/step - loss: 34.8166 - tf_rse: 0.6211 - tf_corr: 0.8006 - mean_absolute_error: 0.2258 - mean_squared_error: 0.0915 - root_mean_squared_error: 0.3025 - mean_absolute_percentage_error: 34.8166 - val_loss: 40.8763 - val_tf_rse: 1.1709 - val_tf_corr: 0.0720 - val_mean_absolute_error: 0.2229 - val_mean_squared_error: 0.0890 - val_root_mean_squared_error: 0.2983 - val_mean_absolute_percentage_error: 40.8763\n",
      "Epoch 9/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 34.5034 - tf_rse: 0.6273 - tf_corr: 0.7935 - mean_absolute_error: 0.2282 - mean_squared_error: 0.0933 - root_mean_squared_error: 0.3054 - mean_absolute_percentage_error: 34.5034 - val_loss: 38.3243 - val_tf_rse: 1.1621 - val_tf_corr: 0.0874 - val_mean_absolute_error: 0.2202 - val_mean_squared_error: 0.0869 - val_root_mean_squared_error: 0.2948 - val_mean_absolute_percentage_error: 38.3243\n",
      "Epoch 10/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 33.5817 - tf_rse: 0.6132 - tf_corr: 0.8028 - mean_absolute_error: 0.2196 - mean_squared_error: 0.0876 - root_mean_squared_error: 0.2960 - mean_absolute_percentage_error: 33.5817 - val_loss: 40.4524 - val_tf_rse: 1.2061 - val_tf_corr: 0.0859 - val_mean_absolute_error: 0.2300 - val_mean_squared_error: 0.0929 - val_root_mean_squared_error: 0.3048 - val_mean_absolute_percentage_error: 40.4524\n",
      "Epoch 11/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 33.6355 - tf_rse: 0.5972 - tf_corr: 0.8092 - mean_absolute_error: 0.2176 - mean_squared_error: 0.0856 - root_mean_squared_error: 0.2925 - mean_absolute_percentage_error: 33.6355 - val_loss: 39.6485 - val_tf_rse: 1.1465 - val_tf_corr: 0.0890 - val_mean_absolute_error: 0.2168 - val_mean_squared_error: 0.0850 - val_root_mean_squared_error: 0.2916 - val_mean_absolute_percentage_error: 39.6485\n",
      "Epoch 12/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 33.8232 - tf_rse: 0.6049 - tf_corr: 0.8057 - mean_absolute_error: 0.2183 - mean_squared_error: 0.0856 - root_mean_squared_error: 0.2925 - mean_absolute_percentage_error: 33.8232 - val_loss: 38.2647 - val_tf_rse: 1.1462 - val_tf_corr: 0.0922 - val_mean_absolute_error: 0.2169 - val_mean_squared_error: 0.0849 - val_root_mean_squared_error: 0.2914 - val_mean_absolute_percentage_error: 38.2647\n",
      "Epoch 13/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 33.8520 - tf_rse: 0.5986 - tf_corr: 0.8102 - mean_absolute_error: 0.2185 - mean_squared_error: 0.0855 - root_mean_squared_error: 0.2924 - mean_absolute_percentage_error: 33.8520 - val_loss: 39.9164 - val_tf_rse: 1.1994 - val_tf_corr: 0.0674 - val_mean_absolute_error: 0.2279 - val_mean_squared_error: 0.0911 - val_root_mean_squared_error: 0.3019 - val_mean_absolute_percentage_error: 39.9164\n",
      "Epoch 14/1000\n",
      "687/687 [==============================] - 16s 23ms/step - loss: 33.0033 - tf_rse: 0.6079 - tf_corr: 0.8057 - mean_absolute_error: 0.2178 - mean_squared_error: 0.0855 - root_mean_squared_error: 0.2924 - mean_absolute_percentage_error: 33.0033 - val_loss: 39.5810 - val_tf_rse: 1.1666 - val_tf_corr: 0.0711 - val_mean_absolute_error: 0.2217 - val_mean_squared_error: 0.0874 - val_root_mean_squared_error: 0.2956 - val_mean_absolute_percentage_error: 39.5810\n",
      "Epoch 15/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 33.0031 - tf_rse: 0.6000 - tf_corr: 0.8077 - mean_absolute_error: 0.2169 - mean_squared_error: 0.0849 - root_mean_squared_error: 0.2914 - mean_absolute_percentage_error: 33.0031 - val_loss: 39.5843 - val_tf_rse: 1.1330 - val_tf_corr: 0.0790 - val_mean_absolute_error: 0.2147 - val_mean_squared_error: 0.0838 - val_root_mean_squared_error: 0.2895 - val_mean_absolute_percentage_error: 39.5843\n",
      "Epoch 16/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 33.9795 - tf_rse: 0.6026 - tf_corr: 0.8006 - mean_absolute_error: 0.2192 - mean_squared_error: 0.0863 - root_mean_squared_error: 0.2937 - mean_absolute_percentage_error: 33.9795 - val_loss: 39.3092 - val_tf_rse: 1.1023 - val_tf_corr: 0.0893 - val_mean_absolute_error: 0.2077 - val_mean_squared_error: 0.0805 - val_root_mean_squared_error: 0.2837 - val_mean_absolute_percentage_error: 39.3092\n",
      "Epoch 17/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 33.6475 - tf_rse: 0.5983 - tf_corr: 0.8099 - mean_absolute_error: 0.2194 - mean_squared_error: 0.0860 - root_mean_squared_error: 0.2933 - mean_absolute_percentage_error: 33.6475 - val_loss: 39.7687 - val_tf_rse: 1.1139 - val_tf_corr: 0.0929 - val_mean_absolute_error: 0.2092 - val_mean_squared_error: 0.0813 - val_root_mean_squared_error: 0.2850 - val_mean_absolute_percentage_error: 39.7687\n",
      "Epoch 18/1000\n",
      "687/687 [==============================] - 16s 23ms/step - loss: 33.9857 - tf_rse: 0.6030 - tf_corr: 0.8052 - mean_absolute_error: 0.2191 - mean_squared_error: 0.0862 - root_mean_squared_error: 0.2937 - mean_absolute_percentage_error: 33.9857 - val_loss: 41.1411 - val_tf_rse: 1.1923 - val_tf_corr: 0.0513 - val_mean_absolute_error: 0.2245 - val_mean_squared_error: 0.0918 - val_root_mean_squared_error: 0.3029 - val_mean_absolute_percentage_error: 41.1411\n",
      "Epoch 19/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 33.2922 - tf_rse: 0.5964 - tf_corr: 0.8114 - mean_absolute_error: 0.2174 - mean_squared_error: 0.0851 - root_mean_squared_error: 0.2918 - mean_absolute_percentage_error: 33.2922 - val_loss: 40.0350 - val_tf_rse: 1.1260 - val_tf_corr: 0.0876 - val_mean_absolute_error: 0.2131 - val_mean_squared_error: 0.0830 - val_root_mean_squared_error: 0.2881 - val_mean_absolute_percentage_error: 40.0350\n",
      "Epoch 20/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 33.3152 - tf_rse: 0.5946 - tf_corr: 0.8118 - mean_absolute_error: 0.2170 - mean_squared_error: 0.0848 - root_mean_squared_error: 0.2913 - mean_absolute_percentage_error: 33.3152 - val_loss: 38.8238 - val_tf_rse: 1.1041 - val_tf_corr: 0.0787 - val_mean_absolute_error: 0.2083 - val_mean_squared_error: 0.0806 - val_root_mean_squared_error: 0.2840 - val_mean_absolute_percentage_error: 38.8238\n",
      "Epoch 21/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 33.2736 - tf_rse: 0.5955 - tf_corr: 0.8148 - mean_absolute_error: 0.2178 - mean_squared_error: 0.0850 - root_mean_squared_error: 0.2916 - mean_absolute_percentage_error: 33.2736 - val_loss: 39.5770 - val_tf_rse: 1.0953 - val_tf_corr: 0.0820 - val_mean_absolute_error: 0.2066 - val_mean_squared_error: 0.0799 - val_root_mean_squared_error: 0.2827 - val_mean_absolute_percentage_error: 39.5770\n",
      "Epoch 22/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 33.2517 - tf_rse: 0.5940 - tf_corr: 0.8100 - mean_absolute_error: 0.2163 - mean_squared_error: 0.0842 - root_mean_squared_error: 0.2902 - mean_absolute_percentage_error: 33.2517 - val_loss: 39.2361 - val_tf_rse: 1.0945 - val_tf_corr: 0.0903 - val_mean_absolute_error: 0.2063 - val_mean_squared_error: 0.0797 - val_root_mean_squared_error: 0.2822 - val_mean_absolute_percentage_error: 39.2361\n",
      "Epoch 23/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 33.3196 - tf_rse: 0.6026 - tf_corr: 0.8053 - mean_absolute_error: 0.2163 - mean_squared_error: 0.0842 - root_mean_squared_error: 0.2901 - mean_absolute_percentage_error: 33.3196 - val_loss: 38.6667 - val_tf_rse: 1.1371 - val_tf_corr: 0.0847 - val_mean_absolute_error: 0.2153 - val_mean_squared_error: 0.0841 - val_root_mean_squared_error: 0.2899 - val_mean_absolute_percentage_error: 38.6667\n",
      "Epoch 24/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 33.1097 - tf_rse: 0.5953 - tf_corr: 0.8130 - mean_absolute_error: 0.2167 - mean_squared_error: 0.0848 - root_mean_squared_error: 0.2912 - mean_absolute_percentage_error: 33.1097 - val_loss: 39.4210 - val_tf_rse: 1.0728 - val_tf_corr: 0.0894 - val_mean_absolute_error: 0.2016 - val_mean_squared_error: 0.0774 - val_root_mean_squared_error: 0.2783 - val_mean_absolute_percentage_error: 39.4210\n",
      "Epoch 25/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 32.6890 - tf_rse: 0.5807 - tf_corr: 0.8207 - mean_absolute_error: 0.2135 - mean_squared_error: 0.0821 - root_mean_squared_error: 0.2866 - mean_absolute_percentage_error: 32.6890 - val_loss: 38.3134 - val_tf_rse: 1.1081 - val_tf_corr: 0.0951 - val_mean_absolute_error: 0.2089 - val_mean_squared_error: 0.0806 - val_root_mean_squared_error: 0.2839 - val_mean_absolute_percentage_error: 38.3134\n",
      "Epoch 26/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 33.3385 - tf_rse: 0.5860 - tf_corr: 0.8183 - mean_absolute_error: 0.2165 - mean_squared_error: 0.0841 - root_mean_squared_error: 0.2900 - mean_absolute_percentage_error: 33.3385 - val_loss: 38.0257 - val_tf_rse: 1.1387 - val_tf_corr: 0.0947 - val_mean_absolute_error: 0.2153 - val_mean_squared_error: 0.0839 - val_root_mean_squared_error: 0.2896 - val_mean_absolute_percentage_error: 38.0257\n",
      "Epoch 27/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 32.9892 - tf_rse: 0.5852 - tf_corr: 0.8191 - mean_absolute_error: 0.2147 - mean_squared_error: 0.0830 - root_mean_squared_error: 0.2881 - mean_absolute_percentage_error: 32.9892 - val_loss: 39.8446 - val_tf_rse: 1.1013 - val_tf_corr: 0.0943 - val_mean_absolute_error: 0.2079 - val_mean_squared_error: 0.0803 - val_root_mean_squared_error: 0.2834 - val_mean_absolute_percentage_error: 39.8446\n",
      "Epoch 28/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 33.5242 - tf_rse: 0.5893 - tf_corr: 0.8167 - mean_absolute_error: 0.2159 - mean_squared_error: 0.0838 - root_mean_squared_error: 0.2894 - mean_absolute_percentage_error: 33.5242 - val_loss: 39.2053 - val_tf_rse: 1.1283 - val_tf_corr: 0.0828 - val_mean_absolute_error: 0.2132 - val_mean_squared_error: 0.0828 - val_root_mean_squared_error: 0.2877 - val_mean_absolute_percentage_error: 39.2053\n",
      "Epoch 29/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 33.3643 - tf_rse: 0.5947 - tf_corr: 0.8122 - mean_absolute_error: 0.2161 - mean_squared_error: 0.0835 - root_mean_squared_error: 0.2890 - mean_absolute_percentage_error: 33.3643 - val_loss: 39.3886 - val_tf_rse: 1.1411 - val_tf_corr: 0.0969 - val_mean_absolute_error: 0.2163 - val_mean_squared_error: 0.0842 - val_root_mean_squared_error: 0.2901 - val_mean_absolute_percentage_error: 39.3886\n",
      "Epoch 30/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 32.8810 - tf_rse: 0.5910 - tf_corr: 0.8132 - mean_absolute_error: 0.2146 - mean_squared_error: 0.0821 - root_mean_squared_error: 0.2865 - mean_absolute_percentage_error: 32.8810 - val_loss: 38.6876 - val_tf_rse: 1.0937 - val_tf_corr: 0.0925 - val_mean_absolute_error: 0.2065 - val_mean_squared_error: 0.0795 - val_root_mean_squared_error: 0.2820 - val_mean_absolute_percentage_error: 38.6876\n",
      "Epoch 31/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 33.0280 - tf_rse: 0.5943 - tf_corr: 0.8101 - mean_absolute_error: 0.2155 - mean_squared_error: 0.0830 - root_mean_squared_error: 0.2881 - mean_absolute_percentage_error: 33.0280 - val_loss: 38.4033 - val_tf_rse: 1.0895 - val_tf_corr: 0.0975 - val_mean_absolute_error: 0.2055 - val_mean_squared_error: 0.0788 - val_root_mean_squared_error: 0.2807 - val_mean_absolute_percentage_error: 38.4033\n",
      "Epoch 32/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 32.9944 - tf_rse: 0.5858 - tf_corr: 0.8151 - mean_absolute_error: 0.2137 - mean_squared_error: 0.0816 - root_mean_squared_error: 0.2857 - mean_absolute_percentage_error: 32.9944 - val_loss: 37.7357 - val_tf_rse: 1.1051 - val_tf_corr: 0.0889 - val_mean_absolute_error: 0.2090 - val_mean_squared_error: 0.0804 - val_root_mean_squared_error: 0.2835 - val_mean_absolute_percentage_error: 37.7357\n",
      "Epoch 33/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 32.5355 - tf_rse: 0.5851 - tf_corr: 0.8209 - mean_absolute_error: 0.2143 - mean_squared_error: 0.0820 - root_mean_squared_error: 0.2864 - mean_absolute_percentage_error: 32.5355 - val_loss: 37.6897 - val_tf_rse: 1.0946 - val_tf_corr: 0.0943 - val_mean_absolute_error: 0.2067 - val_mean_squared_error: 0.0793 - val_root_mean_squared_error: 0.2816 - val_mean_absolute_percentage_error: 37.6897\n",
      "Epoch 34/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 32.5498 - tf_rse: 0.5884 - tf_corr: 0.8115 - mean_absolute_error: 0.2108 - mean_squared_error: 0.0799 - root_mean_squared_error: 0.2827 - mean_absolute_percentage_error: 32.5498 - val_loss: 40.0893 - val_tf_rse: 1.3978 - val_tf_corr: 0.0824 - val_mean_absolute_error: 0.2694 - val_mean_squared_error: 0.1146 - val_root_mean_squared_error: 0.3385 - val_mean_absolute_percentage_error: 40.0893\n",
      "Epoch 35/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 33.1191 - tf_rse: 0.5857 - tf_corr: 0.8256 - mean_absolute_error: 0.2164 - mean_squared_error: 0.0830 - root_mean_squared_error: 0.2881 - mean_absolute_percentage_error: 33.1191 - val_loss: 37.6461 - val_tf_rse: 1.1054 - val_tf_corr: 0.0920 - val_mean_absolute_error: 0.2090 - val_mean_squared_error: 0.0803 - val_root_mean_squared_error: 0.2834 - val_mean_absolute_percentage_error: 37.6461\n",
      "Epoch 36/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 32.7016 - tf_rse: 0.5851 - tf_corr: 0.8180 - mean_absolute_error: 0.2126 - mean_squared_error: 0.0807 - root_mean_squared_error: 0.2842 - mean_absolute_percentage_error: 32.7016 - val_loss: 37.9484 - val_tf_rse: 1.1386 - val_tf_corr: 0.0951 - val_mean_absolute_error: 0.2157 - val_mean_squared_error: 0.0836 - val_root_mean_squared_error: 0.2891 - val_mean_absolute_percentage_error: 37.9484\n",
      "Epoch 37/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 32.5963 - tf_rse: 0.5833 - tf_corr: 0.8169 - mean_absolute_error: 0.2133 - mean_squared_error: 0.0816 - root_mean_squared_error: 0.2856 - mean_absolute_percentage_error: 32.5963 - val_loss: 38.1839 - val_tf_rse: 1.1024 - val_tf_corr: 0.0795 - val_mean_absolute_error: 0.2086 - val_mean_squared_error: 0.0805 - val_root_mean_squared_error: 0.2837 - val_mean_absolute_percentage_error: 38.1839\n",
      "Epoch 38/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 32.9858 - tf_rse: 0.5894 - tf_corr: 0.8128 - mean_absolute_error: 0.2149 - mean_squared_error: 0.0823 - root_mean_squared_error: 0.2869 - mean_absolute_percentage_error: 32.9858 - val_loss: 37.9572 - val_tf_rse: 1.1005 - val_tf_corr: 0.0884 - val_mean_absolute_error: 0.2078 - val_mean_squared_error: 0.0797 - val_root_mean_squared_error: 0.2824 - val_mean_absolute_percentage_error: 37.9572\n",
      "Epoch 39/1000\n",
      "687/687 [==============================] - 18s 26ms/step - loss: 32.3721 - tf_rse: 0.5816 - tf_corr: 0.8172 - mean_absolute_error: 0.2119 - mean_squared_error: 0.0805 - root_mean_squared_error: 0.2837 - mean_absolute_percentage_error: 32.3721 - val_loss: 38.0796 - val_tf_rse: 1.0791 - val_tf_corr: 0.0882 - val_mean_absolute_error: 0.2037 - val_mean_squared_error: 0.0777 - val_root_mean_squared_error: 0.2787 - val_mean_absolute_percentage_error: 38.0796\n",
      "Epoch 40/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 32.7734 - tf_rse: 0.5961 - tf_corr: 0.8062 - mean_absolute_error: 0.2131 - mean_squared_error: 0.0815 - root_mean_squared_error: 0.2855 - mean_absolute_percentage_error: 32.7734 - val_loss: 37.8807 - val_tf_rse: 1.0924 - val_tf_corr: 0.0807 - val_mean_absolute_error: 0.2066 - val_mean_squared_error: 0.0791 - val_root_mean_squared_error: 0.2813 - val_mean_absolute_percentage_error: 37.8807\n",
      "Epoch 41/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 33.0911 - tf_rse: 0.5936 - tf_corr: 0.8097 - mean_absolute_error: 0.2138 - mean_squared_error: 0.0817 - root_mean_squared_error: 0.2859 - mean_absolute_percentage_error: 33.0911 - val_loss: 38.2999 - val_tf_rse: 1.0984 - val_tf_corr: 0.0828 - val_mean_absolute_error: 0.2077 - val_mean_squared_error: 0.0796 - val_root_mean_squared_error: 0.2821 - val_mean_absolute_percentage_error: 38.2999\n",
      "Epoch 42/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 33.3752 - tf_rse: 0.5861 - tf_corr: 0.8167 - mean_absolute_error: 0.2142 - mean_squared_error: 0.0818 - root_mean_squared_error: 0.2861 - mean_absolute_percentage_error: 33.3752 - val_loss: 37.3297 - val_tf_rse: 1.1356 - val_tf_corr: 0.0848 - val_mean_absolute_error: 0.2152 - val_mean_squared_error: 0.0832 - val_root_mean_squared_error: 0.2884 - val_mean_absolute_percentage_error: 37.3297\n",
      "Epoch 43/1000\n",
      "687/687 [==============================] - 16s 23ms/step - loss: 33.3244 - tf_rse: 0.5909 - tf_corr: 0.8139 - mean_absolute_error: 0.2130 - mean_squared_error: 0.0811 - root_mean_squared_error: 0.2848 - mean_absolute_percentage_error: 33.3244 - val_loss: 38.0804 - val_tf_rse: 1.1534 - val_tf_corr: 0.0841 - val_mean_absolute_error: 0.2189 - val_mean_squared_error: 0.0852 - val_root_mean_squared_error: 0.2918 - val_mean_absolute_percentage_error: 38.0804\n",
      "Epoch 44/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 33.2119 - tf_rse: 0.5803 - tf_corr: 0.8269 - mean_absolute_error: 0.2150 - mean_squared_error: 0.0819 - root_mean_squared_error: 0.2862 - mean_absolute_percentage_error: 33.2119 - val_loss: 38.2978 - val_tf_rse: 1.0832 - val_tf_corr: 0.0832 - val_mean_absolute_error: 0.2043 - val_mean_squared_error: 0.0781 - val_root_mean_squared_error: 0.2795 - val_mean_absolute_percentage_error: 38.2978\n",
      "Epoch 45/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 33.2044 - tf_rse: 0.5793 - tf_corr: 0.8266 - mean_absolute_error: 0.2138 - mean_squared_error: 0.0812 - root_mean_squared_error: 0.2849 - mean_absolute_percentage_error: 33.2044 - val_loss: 37.4668 - val_tf_rse: 1.1118 - val_tf_corr: 0.0820 - val_mean_absolute_error: 0.2106 - val_mean_squared_error: 0.0810 - val_root_mean_squared_error: 0.2846 - val_mean_absolute_percentage_error: 37.4668\n",
      "Epoch 46/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 33.0403 - tf_rse: 0.5736 - tf_corr: 0.8260 - mean_absolute_error: 0.2124 - mean_squared_error: 0.0803 - root_mean_squared_error: 0.2833 - mean_absolute_percentage_error: 33.0403 - val_loss: 38.4331 - val_tf_rse: 1.1328 - val_tf_corr: 0.0755 - val_mean_absolute_error: 0.2150 - val_mean_squared_error: 0.0832 - val_root_mean_squared_error: 0.2884 - val_mean_absolute_percentage_error: 38.4331\n",
      "Epoch 47/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 32.7280 - tf_rse: 0.5837 - tf_corr: 0.8161 - mean_absolute_error: 0.2116 - mean_squared_error: 0.0804 - root_mean_squared_error: 0.2836 - mean_absolute_percentage_error: 32.7280 - val_loss: 38.8707 - val_tf_rse: 1.0910 - val_tf_corr: 0.0823 - val_mean_absolute_error: 0.2059 - val_mean_squared_error: 0.0790 - val_root_mean_squared_error: 0.2810 - val_mean_absolute_percentage_error: 38.8707\n",
      "Epoch 48/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 33.1468 - tf_rse: 0.5901 - tf_corr: 0.8120 - mean_absolute_error: 0.2144 - mean_squared_error: 0.0815 - root_mean_squared_error: 0.2855 - mean_absolute_percentage_error: 33.1468 - val_loss: 37.5104 - val_tf_rse: 1.0922 - val_tf_corr: 0.0834 - val_mean_absolute_error: 0.2062 - val_mean_squared_error: 0.0788 - val_root_mean_squared_error: 0.2808 - val_mean_absolute_percentage_error: 37.5104\n",
      "Epoch 49/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 32.6099 - tf_rse: 0.5738 - tf_corr: 0.8258 - mean_absolute_error: 0.2109 - mean_squared_error: 0.0799 - root_mean_squared_error: 0.2827 - mean_absolute_percentage_error: 32.6099 - val_loss: 38.3106 - val_tf_rse: 1.2831 - val_tf_corr: 0.0757 - val_mean_absolute_error: 0.2460 - val_mean_squared_error: 0.0999 - val_root_mean_squared_error: 0.3160 - val_mean_absolute_percentage_error: 38.3106\n",
      "Epoch 50/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 33.0450 - tf_rse: 0.5892 - tf_corr: 0.8149 - mean_absolute_error: 0.2147 - mean_squared_error: 0.0817 - root_mean_squared_error: 0.2859 - mean_absolute_percentage_error: 33.0450 - val_loss: 37.5610 - val_tf_rse: 1.0794 - val_tf_corr: 0.0795 - val_mean_absolute_error: 0.2038 - val_mean_squared_error: 0.0777 - val_root_mean_squared_error: 0.2787 - val_mean_absolute_percentage_error: 37.5610\n",
      "Epoch 51/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 32.8409 - tf_rse: 0.5822 - tf_corr: 0.8174 - mean_absolute_error: 0.2134 - mean_squared_error: 0.0810 - root_mean_squared_error: 0.2846 - mean_absolute_percentage_error: 32.8409 - val_loss: 37.6349 - val_tf_rse: 1.1123 - val_tf_corr: 0.0791 - val_mean_absolute_error: 0.2106 - val_mean_squared_error: 0.0808 - val_root_mean_squared_error: 0.2842 - val_mean_absolute_percentage_error: 37.6349\n",
      "Epoch 52/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 32.5082 - tf_rse: 0.5819 - tf_corr: 0.8183 - mean_absolute_error: 0.2114 - mean_squared_error: 0.0800 - root_mean_squared_error: 0.2829 - mean_absolute_percentage_error: 32.5082 - val_loss: 37.5492 - val_tf_rse: 1.1027 - val_tf_corr: 0.0825 - val_mean_absolute_error: 0.2084 - val_mean_squared_error: 0.0799 - val_root_mean_squared_error: 0.2826 - val_mean_absolute_percentage_error: 37.5492\n",
      "Epoch 53/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 32.5047 - tf_rse: 0.5767 - tf_corr: 0.8244 - mean_absolute_error: 0.2117 - mean_squared_error: 0.0796 - root_mean_squared_error: 0.2821 - mean_absolute_percentage_error: 32.5047 - val_loss: 37.7074 - val_tf_rse: 1.1169 - val_tf_corr: 0.0747 - val_mean_absolute_error: 0.2117 - val_mean_squared_error: 0.0813 - val_root_mean_squared_error: 0.2851 - val_mean_absolute_percentage_error: 37.7074\n",
      "Epoch 54/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 32.7630 - tf_rse: 0.5818 - tf_corr: 0.8181 - mean_absolute_error: 0.2133 - mean_squared_error: 0.0804 - root_mean_squared_error: 0.2836 - mean_absolute_percentage_error: 32.7630 - val_loss: 37.4965 - val_tf_rse: 1.1359 - val_tf_corr: 0.0825 - val_mean_absolute_error: 0.2152 - val_mean_squared_error: 0.0831 - val_root_mean_squared_error: 0.2883 - val_mean_absolute_percentage_error: 37.4965\n",
      "Epoch 55/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 32.5173 - tf_rse: 0.5799 - tf_corr: 0.8183 - mean_absolute_error: 0.2129 - mean_squared_error: 0.0807 - root_mean_squared_error: 0.2840 - mean_absolute_percentage_error: 32.5173 - val_loss: 37.7704 - val_tf_rse: 1.1580 - val_tf_corr: 0.0798 - val_mean_absolute_error: 0.2200 - val_mean_squared_error: 0.0856 - val_root_mean_squared_error: 0.2926 - val_mean_absolute_percentage_error: 37.7704\n",
      "Epoch 56/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 32.4911 - tf_rse: 0.5765 - tf_corr: 0.8213 - mean_absolute_error: 0.2108 - mean_squared_error: 0.0791 - root_mean_squared_error: 0.2813 - mean_absolute_percentage_error: 32.4911 - val_loss: 37.8041 - val_tf_rse: 1.1790 - val_tf_corr: 0.0766 - val_mean_absolute_error: 0.2243 - val_mean_squared_error: 0.0879 - val_root_mean_squared_error: 0.2964 - val_mean_absolute_percentage_error: 37.8041\n",
      "Epoch 57/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 32.3464 - tf_rse: 0.5799 - tf_corr: 0.8218 - mean_absolute_error: 0.2119 - mean_squared_error: 0.0799 - root_mean_squared_error: 0.2826 - mean_absolute_percentage_error: 32.3464 - val_loss: 37.7111 - val_tf_rse: 1.1469 - val_tf_corr: 0.0763 - val_mean_absolute_error: 0.2177 - val_mean_squared_error: 0.0843 - val_root_mean_squared_error: 0.2904 - val_mean_absolute_percentage_error: 37.7111\n",
      "Epoch 58/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 32.6841 - tf_rse: 0.5761 - tf_corr: 0.8258 - mean_absolute_error: 0.2123 - mean_squared_error: 0.0799 - root_mean_squared_error: 0.2827 - mean_absolute_percentage_error: 32.6841 - val_loss: 37.9379 - val_tf_rse: 1.1174 - val_tf_corr: 0.0746 - val_mean_absolute_error: 0.2118 - val_mean_squared_error: 0.0814 - val_root_mean_squared_error: 0.2852 - val_mean_absolute_percentage_error: 37.9379\n",
      "Epoch 59/1000\n",
      "687/687 [==============================] - 18s 26ms/step - loss: 32.9112 - tf_rse: 0.5750 - tf_corr: 0.8190 - mean_absolute_error: 0.2093 - mean_squared_error: 0.0781 - root_mean_squared_error: 0.2795 - mean_absolute_percentage_error: 32.9112 - val_loss: 38.0891 - val_tf_rse: 1.1975 - val_tf_corr: 0.0807 - val_mean_absolute_error: 0.2283 - val_mean_squared_error: 0.0900 - val_root_mean_squared_error: 0.3000 - val_mean_absolute_percentage_error: 38.0891\n",
      "Epoch 60/1000\n",
      "687/687 [==============================] - 18s 27ms/step - loss: 32.5770 - tf_rse: 0.5837 - tf_corr: 0.8244 - mean_absolute_error: 0.2149 - mean_squared_error: 0.0816 - root_mean_squared_error: 0.2857 - mean_absolute_percentage_error: 32.5770 - val_loss: 38.1453 - val_tf_rse: 1.0940 - val_tf_corr: 0.0778 - val_mean_absolute_error: 0.2070 - val_mean_squared_error: 0.0791 - val_root_mean_squared_error: 0.2812 - val_mean_absolute_percentage_error: 38.1453\n",
      "Epoch 61/1000\n",
      "687/687 [==============================] - 19s 27ms/step - loss: 32.8581 - tf_rse: 0.5806 - tf_corr: 0.8212 - mean_absolute_error: 0.2115 - mean_squared_error: 0.0794 - root_mean_squared_error: 0.2818 - mean_absolute_percentage_error: 32.8581 - val_loss: 37.7397 - val_tf_rse: 1.1205 - val_tf_corr: 0.0763 - val_mean_absolute_error: 0.2123 - val_mean_squared_error: 0.0817 - val_root_mean_squared_error: 0.2859 - val_mean_absolute_percentage_error: 37.7397\n",
      "Epoch 62/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 32.3759 - tf_rse: 0.5808 - tf_corr: 0.8195 - mean_absolute_error: 0.2126 - mean_squared_error: 0.0803 - root_mean_squared_error: 0.2833 - mean_absolute_percentage_error: 32.3759 - val_loss: 37.7249 - val_tf_rse: 1.1060 - val_tf_corr: 0.0807 - val_mean_absolute_error: 0.2093 - val_mean_squared_error: 0.0801 - val_root_mean_squared_error: 0.2831 - val_mean_absolute_percentage_error: 37.7249\n",
      "Epoch 63/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 32.6077 - tf_rse: 0.5794 - tf_corr: 0.8198 - mean_absolute_error: 0.2117 - mean_squared_error: 0.0793 - root_mean_squared_error: 0.2816 - mean_absolute_percentage_error: 32.6077 - val_loss: 37.2697 - val_tf_rse: 1.0985 - val_tf_corr: 0.0812 - val_mean_absolute_error: 0.2076 - val_mean_squared_error: 0.0795 - val_root_mean_squared_error: 0.2820 - val_mean_absolute_percentage_error: 37.2697\n",
      "Epoch 64/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 32.5161 - tf_rse: 0.5761 - tf_corr: 0.8216 - mean_absolute_error: 0.2106 - mean_squared_error: 0.0788 - root_mean_squared_error: 0.2807 - mean_absolute_percentage_error: 32.5161 - val_loss: 37.9834 - val_tf_rse: 1.1231 - val_tf_corr: 0.0708 - val_mean_absolute_error: 0.2130 - val_mean_squared_error: 0.0822 - val_root_mean_squared_error: 0.2868 - val_mean_absolute_percentage_error: 37.9834\n",
      "Epoch 65/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 32.2586 - tf_rse: 0.5827 - tf_corr: 0.8204 - mean_absolute_error: 0.2115 - mean_squared_error: 0.0797 - root_mean_squared_error: 0.2823 - mean_absolute_percentage_error: 32.2586 - val_loss: 37.9509 - val_tf_rse: 1.0894 - val_tf_corr: 0.0670 - val_mean_absolute_error: 0.2057 - val_mean_squared_error: 0.0788 - val_root_mean_squared_error: 0.2807 - val_mean_absolute_percentage_error: 37.9509\n",
      "Epoch 66/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 32.4244 - tf_rse: 0.5722 - tf_corr: 0.8294 - mean_absolute_error: 0.2119 - mean_squared_error: 0.0796 - root_mean_squared_error: 0.2821 - mean_absolute_percentage_error: 32.4244 - val_loss: 38.1924 - val_tf_rse: 1.0943 - val_tf_corr: 0.0677 - val_mean_absolute_error: 0.2069 - val_mean_squared_error: 0.0794 - val_root_mean_squared_error: 0.2818 - val_mean_absolute_percentage_error: 38.1924\n",
      "Epoch 67/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 32.5642 - tf_rse: 0.5799 - tf_corr: 0.8186 - mean_absolute_error: 0.2127 - mean_squared_error: 0.0804 - root_mean_squared_error: 0.2835 - mean_absolute_percentage_error: 32.5642 - val_loss: 37.6674 - val_tf_rse: 1.0931 - val_tf_corr: 0.0654 - val_mean_absolute_error: 0.2067 - val_mean_squared_error: 0.0797 - val_root_mean_squared_error: 0.2823 - val_mean_absolute_percentage_error: 37.6674\n",
      "Epoch 68/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 31.8833 - tf_rse: 0.5734 - tf_corr: 0.8231 - mean_absolute_error: 0.2107 - mean_squared_error: 0.0793 - root_mean_squared_error: 0.2817 - mean_absolute_percentage_error: 31.8833 - val_loss: 37.5938 - val_tf_rse: 1.1813 - val_tf_corr: 0.0714 - val_mean_absolute_error: 0.2245 - val_mean_squared_error: 0.0885 - val_root_mean_squared_error: 0.2976 - val_mean_absolute_percentage_error: 37.5938\n",
      "Epoch 69/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 31.9981 - tf_rse: 0.5773 - tf_corr: 0.8216 - mean_absolute_error: 0.2114 - mean_squared_error: 0.0794 - root_mean_squared_error: 0.2818 - mean_absolute_percentage_error: 31.9981 - val_loss: 37.3540 - val_tf_rse: 1.1445 - val_tf_corr: 0.0828 - val_mean_absolute_error: 0.2173 - val_mean_squared_error: 0.0842 - val_root_mean_squared_error: 0.2901 - val_mean_absolute_percentage_error: 37.3540\n",
      "Epoch 70/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 31.7355 - tf_rse: 0.5756 - tf_corr: 0.8223 - mean_absolute_error: 0.2112 - mean_squared_error: 0.0793 - root_mean_squared_error: 0.2817 - mean_absolute_percentage_error: 31.7355 - val_loss: 37.2632 - val_tf_rse: 1.0851 - val_tf_corr: 0.0835 - val_mean_absolute_error: 0.2050 - val_mean_squared_error: 0.0781 - val_root_mean_squared_error: 0.2795 - val_mean_absolute_percentage_error: 37.2632\n",
      "Epoch 71/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.8176 - tf_rse: 0.5795 - tf_corr: 0.8226 - mean_absolute_error: 0.2097 - mean_squared_error: 0.0784 - root_mean_squared_error: 0.2800 - mean_absolute_percentage_error: 30.8176 - val_loss: 36.9236 - val_tf_rse: 1.1623 - val_tf_corr: 0.0814 - val_mean_absolute_error: 0.2208 - val_mean_squared_error: 0.0861 - val_root_mean_squared_error: 0.2934 - val_mean_absolute_percentage_error: 36.9236\n",
      "Epoch 72/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 31.2302 - tf_rse: 0.5730 - tf_corr: 0.8225 - mean_absolute_error: 0.2104 - mean_squared_error: 0.0789 - root_mean_squared_error: 0.2809 - mean_absolute_percentage_error: 31.2302 - val_loss: 37.6570 - val_tf_rse: 1.0982 - val_tf_corr: 0.0711 - val_mean_absolute_error: 0.2073 - val_mean_squared_error: 0.0803 - val_root_mean_squared_error: 0.2833 - val_mean_absolute_percentage_error: 37.6570\n",
      "Epoch 73/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 30.6805 - tf_rse: 0.5771 - tf_corr: 0.8191 - mean_absolute_error: 0.2087 - mean_squared_error: 0.0782 - root_mean_squared_error: 0.2797 - mean_absolute_percentage_error: 30.6805 - val_loss: 37.5061 - val_tf_rse: 1.1152 - val_tf_corr: 0.0877 - val_mean_absolute_error: 0.2111 - val_mean_squared_error: 0.0812 - val_root_mean_squared_error: 0.2850 - val_mean_absolute_percentage_error: 37.5061\n",
      "Epoch 74/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 30.6249 - tf_rse: 0.5779 - tf_corr: 0.8161 - mean_absolute_error: 0.2099 - mean_squared_error: 0.0784 - root_mean_squared_error: 0.2800 - mean_absolute_percentage_error: 30.6249 - val_loss: 37.7248 - val_tf_rse: 1.0641 - val_tf_corr: 0.0867 - val_mean_absolute_error: 0.2004 - val_mean_squared_error: 0.0764 - val_root_mean_squared_error: 0.2764 - val_mean_absolute_percentage_error: 37.7248\n",
      "Epoch 75/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 31.3446 - tf_rse: 0.5802 - tf_corr: 0.8159 - mean_absolute_error: 0.2105 - mean_squared_error: 0.0790 - root_mean_squared_error: 0.2810 - mean_absolute_percentage_error: 31.3446 - val_loss: 37.5075 - val_tf_rse: 1.0665 - val_tf_corr: 0.0828 - val_mean_absolute_error: 0.2008 - val_mean_squared_error: 0.0767 - val_root_mean_squared_error: 0.2769 - val_mean_absolute_percentage_error: 37.5075\n",
      "Epoch 76/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 31.3640 - tf_rse: 0.5797 - tf_corr: 0.8162 - mean_absolute_error: 0.2102 - mean_squared_error: 0.0783 - root_mean_squared_error: 0.2799 - mean_absolute_percentage_error: 31.3640 - val_loss: 37.0402 - val_tf_rse: 1.1108 - val_tf_corr: 0.0789 - val_mean_absolute_error: 0.2102 - val_mean_squared_error: 0.0811 - val_root_mean_squared_error: 0.2847 - val_mean_absolute_percentage_error: 37.0402\n",
      "Epoch 77/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 30.7995 - tf_rse: 0.5771 - tf_corr: 0.8179 - mean_absolute_error: 0.2104 - mean_squared_error: 0.0787 - root_mean_squared_error: 0.2805 - mean_absolute_percentage_error: 30.7995 - val_loss: 37.2522 - val_tf_rse: 1.0718 - val_tf_corr: 0.0845 - val_mean_absolute_error: 0.2021 - val_mean_squared_error: 0.0771 - val_root_mean_squared_error: 0.2777 - val_mean_absolute_percentage_error: 37.2522\n",
      "Epoch 78/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.7042 - tf_rse: 0.5807 - tf_corr: 0.8166 - mean_absolute_error: 0.2092 - mean_squared_error: 0.0782 - root_mean_squared_error: 0.2796 - mean_absolute_percentage_error: 30.7042 - val_loss: 37.1948 - val_tf_rse: 1.0754 - val_tf_corr: 0.0774 - val_mean_absolute_error: 0.2031 - val_mean_squared_error: 0.0776 - val_root_mean_squared_error: 0.2786 - val_mean_absolute_percentage_error: 37.1948\n",
      "Epoch 79/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.4380 - tf_rse: 0.5785 - tf_corr: 0.8127 - mean_absolute_error: 0.2080 - mean_squared_error: 0.0770 - root_mean_squared_error: 0.2774 - mean_absolute_percentage_error: 30.4380 - val_loss: 37.0114 - val_tf_rse: 1.1265 - val_tf_corr: 0.0839 - val_mean_absolute_error: 0.2139 - val_mean_squared_error: 0.0826 - val_root_mean_squared_error: 0.2875 - val_mean_absolute_percentage_error: 37.0114\n",
      "Epoch 80/1000\n",
      "687/687 [==============================] - 18s 26ms/step - loss: 31.3972 - tf_rse: 0.5717 - tf_corr: 0.8265 - mean_absolute_error: 0.2097 - mean_squared_error: 0.0782 - root_mean_squared_error: 0.2797 - mean_absolute_percentage_error: 31.3972 - val_loss: 37.5780 - val_tf_rse: 1.0703 - val_tf_corr: 0.0795 - val_mean_absolute_error: 0.2021 - val_mean_squared_error: 0.0771 - val_root_mean_squared_error: 0.2777 - val_mean_absolute_percentage_error: 37.5780\n",
      "Epoch 81/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.4553 - tf_rse: 0.5782 - tf_corr: 0.8147 - mean_absolute_error: 0.2081 - mean_squared_error: 0.0773 - root_mean_squared_error: 0.2780 - mean_absolute_percentage_error: 30.4553 - val_loss: 37.2042 - val_tf_rse: 1.0655 - val_tf_corr: 0.0786 - val_mean_absolute_error: 0.2009 - val_mean_squared_error: 0.0765 - val_root_mean_squared_error: 0.2766 - val_mean_absolute_percentage_error: 37.2042\n",
      "Epoch 82/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.6350 - tf_rse: 0.5755 - tf_corr: 0.8203 - mean_absolute_error: 0.2093 - mean_squared_error: 0.0784 - root_mean_squared_error: 0.2799 - mean_absolute_percentage_error: 30.6350 - val_loss: 37.2994 - val_tf_rse: 1.0705 - val_tf_corr: 0.0772 - val_mean_absolute_error: 0.2022 - val_mean_squared_error: 0.0770 - val_root_mean_squared_error: 0.2776 - val_mean_absolute_percentage_error: 37.2994\n",
      "Epoch 83/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 30.6285 - tf_rse: 0.5687 - tf_corr: 0.8214 - mean_absolute_error: 0.2074 - mean_squared_error: 0.0771 - root_mean_squared_error: 0.2777 - mean_absolute_percentage_error: 30.6285 - val_loss: 36.9712 - val_tf_rse: 1.0968 - val_tf_corr: 0.0794 - val_mean_absolute_error: 0.2077 - val_mean_squared_error: 0.0793 - val_root_mean_squared_error: 0.2815 - val_mean_absolute_percentage_error: 36.9712\n",
      "Epoch 84/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 32.0217 - tf_rse: 0.5702 - tf_corr: 0.8283 - mean_absolute_error: 0.2093 - mean_squared_error: 0.0777 - root_mean_squared_error: 0.2787 - mean_absolute_percentage_error: 32.0217 - val_loss: 36.9926 - val_tf_rse: 1.1534 - val_tf_corr: 0.0760 - val_mean_absolute_error: 0.2196 - val_mean_squared_error: 0.0853 - val_root_mean_squared_error: 0.2921 - val_mean_absolute_percentage_error: 36.9926\n",
      "Epoch 85/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 31.1282 - tf_rse: 0.5787 - tf_corr: 0.8165 - mean_absolute_error: 0.2095 - mean_squared_error: 0.0785 - root_mean_squared_error: 0.2802 - mean_absolute_percentage_error: 31.1282 - val_loss: 37.2296 - val_tf_rse: 1.0660 - val_tf_corr: 0.0746 - val_mean_absolute_error: 0.2013 - val_mean_squared_error: 0.0765 - val_root_mean_squared_error: 0.2766 - val_mean_absolute_percentage_error: 37.2296\n",
      "Epoch 86/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.7051 - tf_rse: 0.5659 - tf_corr: 0.8256 - mean_absolute_error: 0.2079 - mean_squared_error: 0.0772 - root_mean_squared_error: 0.2778 - mean_absolute_percentage_error: 30.7051 - val_loss: 37.3420 - val_tf_rse: 1.0738 - val_tf_corr: 0.0777 - val_mean_absolute_error: 0.2027 - val_mean_squared_error: 0.0772 - val_root_mean_squared_error: 0.2778 - val_mean_absolute_percentage_error: 37.3420\n",
      "Epoch 87/1000\n",
      "687/687 [==============================] - 18s 26ms/step - loss: 31.7604 - tf_rse: 0.5706 - tf_corr: 0.8279 - mean_absolute_error: 0.2084 - mean_squared_error: 0.0775 - root_mean_squared_error: 0.2784 - mean_absolute_percentage_error: 31.7604 - val_loss: 37.0083 - val_tf_rse: 1.1188 - val_tf_corr: 0.0763 - val_mean_absolute_error: 0.2123 - val_mean_squared_error: 0.0817 - val_root_mean_squared_error: 0.2858 - val_mean_absolute_percentage_error: 37.0083\n",
      "Epoch 88/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 31.4031 - tf_rse: 0.5724 - tf_corr: 0.8281 - mean_absolute_error: 0.2094 - mean_squared_error: 0.0780 - root_mean_squared_error: 0.2793 - mean_absolute_percentage_error: 31.4031 - val_loss: 37.8769 - val_tf_rse: 1.0500 - val_tf_corr: 0.0750 - val_mean_absolute_error: 0.1973 - val_mean_squared_error: 0.0751 - val_root_mean_squared_error: 0.2741 - val_mean_absolute_percentage_error: 37.8769\n",
      "Epoch 89/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 31.3067 - tf_rse: 0.5732 - tf_corr: 0.8240 - mean_absolute_error: 0.2083 - mean_squared_error: 0.0769 - root_mean_squared_error: 0.2773 - mean_absolute_percentage_error: 31.3067 - val_loss: 37.3562 - val_tf_rse: 1.0603 - val_tf_corr: 0.0794 - val_mean_absolute_error: 0.1996 - val_mean_squared_error: 0.0760 - val_root_mean_squared_error: 0.2756 - val_mean_absolute_percentage_error: 37.3562\n",
      "Epoch 90/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.8412 - tf_rse: 0.5752 - tf_corr: 0.8211 - mean_absolute_error: 0.2093 - mean_squared_error: 0.0787 - root_mean_squared_error: 0.2806 - mean_absolute_percentage_error: 30.8412 - val_loss: 37.3074 - val_tf_rse: 1.0653 - val_tf_corr: 0.0768 - val_mean_absolute_error: 0.2007 - val_mean_squared_error: 0.0766 - val_root_mean_squared_error: 0.2769 - val_mean_absolute_percentage_error: 37.3074\n",
      "Epoch 91/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.3875 - tf_rse: 0.5783 - tf_corr: 0.8197 - mean_absolute_error: 0.2085 - mean_squared_error: 0.0778 - root_mean_squared_error: 0.2790 - mean_absolute_percentage_error: 30.3875 - val_loss: 36.8614 - val_tf_rse: 1.0995 - val_tf_corr: 0.0728 - val_mean_absolute_error: 0.2081 - val_mean_squared_error: 0.0798 - val_root_mean_squared_error: 0.2825 - val_mean_absolute_percentage_error: 36.8614\n",
      "Epoch 92/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.7706 - tf_rse: 0.5800 - tf_corr: 0.8150 - mean_absolute_error: 0.2079 - mean_squared_error: 0.0772 - root_mean_squared_error: 0.2778 - mean_absolute_percentage_error: 30.7706 - val_loss: 38.6646 - val_tf_rse: 1.0474 - val_tf_corr: 0.0812 - val_mean_absolute_error: 0.1961 - val_mean_squared_error: 0.0749 - val_root_mean_squared_error: 0.2737 - val_mean_absolute_percentage_error: 38.6646\n",
      "Epoch 93/1000\n",
      "687/687 [==============================] - 18s 26ms/step - loss: 30.8159 - tf_rse: 0.5676 - tf_corr: 0.8267 - mean_absolute_error: 0.2082 - mean_squared_error: 0.0773 - root_mean_squared_error: 0.2780 - mean_absolute_percentage_error: 30.8159 - val_loss: 38.3443 - val_tf_rse: 1.0591 - val_tf_corr: 0.0786 - val_mean_absolute_error: 0.1990 - val_mean_squared_error: 0.0757 - val_root_mean_squared_error: 0.2751 - val_mean_absolute_percentage_error: 38.3443\n",
      "Epoch 94/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 30.7792 - tf_rse: 0.5688 - tf_corr: 0.8281 - mean_absolute_error: 0.2092 - mean_squared_error: 0.0777 - root_mean_squared_error: 0.2787 - mean_absolute_percentage_error: 30.7792 - val_loss: 37.9608 - val_tf_rse: 1.0527 - val_tf_corr: 0.0741 - val_mean_absolute_error: 0.1977 - val_mean_squared_error: 0.0753 - val_root_mean_squared_error: 0.2743 - val_mean_absolute_percentage_error: 37.9608\n",
      "Epoch 95/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.5865 - tf_rse: 0.5701 - tf_corr: 0.8257 - mean_absolute_error: 0.2071 - mean_squared_error: 0.0764 - root_mean_squared_error: 0.2765 - mean_absolute_percentage_error: 30.5865 - val_loss: 38.5281 - val_tf_rse: 1.0522 - val_tf_corr: 0.0752 - val_mean_absolute_error: 0.1975 - val_mean_squared_error: 0.0751 - val_root_mean_squared_error: 0.2741 - val_mean_absolute_percentage_error: 38.5281\n",
      "Epoch 96/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.5257 - tf_rse: 0.5672 - tf_corr: 0.8299 - mean_absolute_error: 0.2081 - mean_squared_error: 0.0772 - root_mean_squared_error: 0.2778 - mean_absolute_percentage_error: 30.5257 - val_loss: 38.3433 - val_tf_rse: 1.0643 - val_tf_corr: 0.0731 - val_mean_absolute_error: 0.2003 - val_mean_squared_error: 0.0761 - val_root_mean_squared_error: 0.2759 - val_mean_absolute_percentage_error: 38.3433\n",
      "Epoch 97/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 31.8509 - tf_rse: 0.5739 - tf_corr: 0.8275 - mean_absolute_error: 0.2104 - mean_squared_error: 0.0784 - root_mean_squared_error: 0.2800 - mean_absolute_percentage_error: 31.8509 - val_loss: 38.6418 - val_tf_rse: 1.0469 - val_tf_corr: 0.0759 - val_mean_absolute_error: 0.1960 - val_mean_squared_error: 0.0746 - val_root_mean_squared_error: 0.2731 - val_mean_absolute_percentage_error: 38.6418\n",
      "Epoch 98/1000\n",
      "687/687 [==============================] - 16s 23ms/step - loss: 30.4342 - tf_rse: 0.5608 - tf_corr: 0.8301 - mean_absolute_error: 0.2066 - mean_squared_error: 0.0761 - root_mean_squared_error: 0.2759 - mean_absolute_percentage_error: 30.4342 - val_loss: 37.5950 - val_tf_rse: 1.0740 - val_tf_corr: 0.0771 - val_mean_absolute_error: 0.2022 - val_mean_squared_error: 0.0768 - val_root_mean_squared_error: 0.2772 - val_mean_absolute_percentage_error: 37.5950\n",
      "Epoch 99/1000\n",
      "687/687 [==============================] - 18s 26ms/step - loss: 30.5668 - tf_rse: 0.5621 - tf_corr: 0.8325 - mean_absolute_error: 0.2077 - mean_squared_error: 0.0764 - root_mean_squared_error: 0.2765 - mean_absolute_percentage_error: 30.5668 - val_loss: 37.9758 - val_tf_rse: 1.0648 - val_tf_corr: 0.0657 - val_mean_absolute_error: 0.2005 - val_mean_squared_error: 0.0763 - val_root_mean_squared_error: 0.2762 - val_mean_absolute_percentage_error: 37.9758\n",
      "Epoch 100/1000\n",
      "687/687 [==============================] - 18s 27ms/step - loss: 30.7974 - tf_rse: 0.5687 - tf_corr: 0.8254 - mean_absolute_error: 0.2064 - mean_squared_error: 0.0758 - root_mean_squared_error: 0.2754 - mean_absolute_percentage_error: 30.7974 - val_loss: 37.6713 - val_tf_rse: 1.0614 - val_tf_corr: 0.0715 - val_mean_absolute_error: 0.1998 - val_mean_squared_error: 0.0759 - val_root_mean_squared_error: 0.2755 - val_mean_absolute_percentage_error: 37.6713\n",
      "Epoch 101/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.3254 - tf_rse: 0.5572 - tf_corr: 0.8346 - mean_absolute_error: 0.2061 - mean_squared_error: 0.0756 - root_mean_squared_error: 0.2749 - mean_absolute_percentage_error: 30.3254 - val_loss: 37.7743 - val_tf_rse: 1.0824 - val_tf_corr: 0.0718 - val_mean_absolute_error: 0.2042 - val_mean_squared_error: 0.0777 - val_root_mean_squared_error: 0.2788 - val_mean_absolute_percentage_error: 37.7743\n",
      "Epoch 102/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 31.0619 - tf_rse: 0.5746 - tf_corr: 0.8217 - mean_absolute_error: 0.2093 - mean_squared_error: 0.0778 - root_mean_squared_error: 0.2789 - mean_absolute_percentage_error: 31.0619 - val_loss: 37.3477 - val_tf_rse: 1.0924 - val_tf_corr: 0.0714 - val_mean_absolute_error: 0.2065 - val_mean_squared_error: 0.0789 - val_root_mean_squared_error: 0.2808 - val_mean_absolute_percentage_error: 37.3477\n",
      "Epoch 103/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.3801 - tf_rse: 0.5670 - tf_corr: 0.8256 - mean_absolute_error: 0.2075 - mean_squared_error: 0.0768 - root_mean_squared_error: 0.2771 - mean_absolute_percentage_error: 30.3801 - val_loss: 37.9597 - val_tf_rse: 1.0647 - val_tf_corr: 0.0763 - val_mean_absolute_error: 0.2006 - val_mean_squared_error: 0.0762 - val_root_mean_squared_error: 0.2761 - val_mean_absolute_percentage_error: 37.9597\n",
      "Epoch 104/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 30.7475 - tf_rse: 0.5709 - tf_corr: 0.8222 - mean_absolute_error: 0.2086 - mean_squared_error: 0.0778 - root_mean_squared_error: 0.2789 - mean_absolute_percentage_error: 30.7475 - val_loss: 38.1352 - val_tf_rse: 1.0490 - val_tf_corr: 0.0756 - val_mean_absolute_error: 0.1970 - val_mean_squared_error: 0.0747 - val_root_mean_squared_error: 0.2734 - val_mean_absolute_percentage_error: 38.1352\n",
      "Epoch 105/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 30.5880 - tf_rse: 0.5621 - tf_corr: 0.8304 - mean_absolute_error: 0.2069 - mean_squared_error: 0.0761 - root_mean_squared_error: 0.2759 - mean_absolute_percentage_error: 30.5880 - val_loss: 37.6235 - val_tf_rse: 1.0644 - val_tf_corr: 0.0770 - val_mean_absolute_error: 0.2004 - val_mean_squared_error: 0.0759 - val_root_mean_squared_error: 0.2756 - val_mean_absolute_percentage_error: 37.6235\n",
      "Epoch 106/1000\n",
      "687/687 [==============================] - 18s 26ms/step - loss: 31.7515 - tf_rse: 0.5733 - tf_corr: 0.8263 - mean_absolute_error: 0.2096 - mean_squared_error: 0.0785 - root_mean_squared_error: 0.2803 - mean_absolute_percentage_error: 31.7515 - val_loss: 37.6908 - val_tf_rse: 1.0677 - val_tf_corr: 0.0730 - val_mean_absolute_error: 0.2012 - val_mean_squared_error: 0.0766 - val_root_mean_squared_error: 0.2767 - val_mean_absolute_percentage_error: 37.6908\n",
      "Epoch 107/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.5170 - tf_rse: 0.5717 - tf_corr: 0.8218 - mean_absolute_error: 0.2066 - mean_squared_error: 0.0761 - root_mean_squared_error: 0.2759 - mean_absolute_percentage_error: 30.5170 - val_loss: 37.4559 - val_tf_rse: 1.1049 - val_tf_corr: 0.0771 - val_mean_absolute_error: 0.2086 - val_mean_squared_error: 0.0798 - val_root_mean_squared_error: 0.2825 - val_mean_absolute_percentage_error: 37.4559\n",
      "Epoch 108/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 30.7071 - tf_rse: 0.5703 - tf_corr: 0.8290 - mean_absolute_error: 0.2080 - mean_squared_error: 0.0773 - root_mean_squared_error: 0.2781 - mean_absolute_percentage_error: 30.7071 - val_loss: 37.8569 - val_tf_rse: 1.0567 - val_tf_corr: 0.0733 - val_mean_absolute_error: 0.1985 - val_mean_squared_error: 0.0754 - val_root_mean_squared_error: 0.2746 - val_mean_absolute_percentage_error: 37.8569\n",
      "Epoch 109/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.4395 - tf_rse: 0.5683 - tf_corr: 0.8279 - mean_absolute_error: 0.2078 - mean_squared_error: 0.0771 - root_mean_squared_error: 0.2777 - mean_absolute_percentage_error: 30.4395 - val_loss: 39.0020 - val_tf_rse: 1.0442 - val_tf_corr: 0.0716 - val_mean_absolute_error: 0.1957 - val_mean_squared_error: 0.0745 - val_root_mean_squared_error: 0.2729 - val_mean_absolute_percentage_error: 39.0020\n",
      "Epoch 110/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 30.4568 - tf_rse: 0.5676 - tf_corr: 0.8218 - mean_absolute_error: 0.2047 - mean_squared_error: 0.0749 - root_mean_squared_error: 0.2736 - mean_absolute_percentage_error: 30.4568 - val_loss: 38.6069 - val_tf_rse: 1.0550 - val_tf_corr: 0.0761 - val_mean_absolute_error: 0.1984 - val_mean_squared_error: 0.0751 - val_root_mean_squared_error: 0.2740 - val_mean_absolute_percentage_error: 38.6069\n",
      "Epoch 111/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 31.9116 - tf_rse: 0.5697 - tf_corr: 0.8278 - mean_absolute_error: 0.2082 - mean_squared_error: 0.0771 - root_mean_squared_error: 0.2777 - mean_absolute_percentage_error: 31.9116 - val_loss: 37.4354 - val_tf_rse: 1.0650 - val_tf_corr: 0.0757 - val_mean_absolute_error: 0.2006 - val_mean_squared_error: 0.0761 - val_root_mean_squared_error: 0.2759 - val_mean_absolute_percentage_error: 37.4354\n",
      "Epoch 112/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.7057 - tf_rse: 0.5634 - tf_corr: 0.8313 - mean_absolute_error: 0.2082 - mean_squared_error: 0.0768 - root_mean_squared_error: 0.2771 - mean_absolute_percentage_error: 30.7057 - val_loss: 37.9384 - val_tf_rse: 1.0654 - val_tf_corr: 0.0727 - val_mean_absolute_error: 0.2007 - val_mean_squared_error: 0.0765 - val_root_mean_squared_error: 0.2766 - val_mean_absolute_percentage_error: 37.9384\n",
      "Epoch 113/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 30.3662 - tf_rse: 0.5653 - tf_corr: 0.8301 - mean_absolute_error: 0.2070 - mean_squared_error: 0.0766 - root_mean_squared_error: 0.2768 - mean_absolute_percentage_error: 30.3662 - val_loss: 38.2331 - val_tf_rse: 1.0687 - val_tf_corr: 0.0787 - val_mean_absolute_error: 0.2013 - val_mean_squared_error: 0.0763 - val_root_mean_squared_error: 0.2763 - val_mean_absolute_percentage_error: 38.2331\n",
      "Epoch 114/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 31.4900 - tf_rse: 0.5686 - tf_corr: 0.8271 - mean_absolute_error: 0.2082 - mean_squared_error: 0.0771 - root_mean_squared_error: 0.2777 - mean_absolute_percentage_error: 31.4900 - val_loss: 37.2746 - val_tf_rse: 1.1323 - val_tf_corr: 0.0770 - val_mean_absolute_error: 0.2145 - val_mean_squared_error: 0.0828 - val_root_mean_squared_error: 0.2878 - val_mean_absolute_percentage_error: 37.2746\n",
      "Epoch 115/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 30.1858 - tf_rse: 0.5660 - tf_corr: 0.8253 - mean_absolute_error: 0.2066 - mean_squared_error: 0.0758 - root_mean_squared_error: 0.2754 - mean_absolute_percentage_error: 30.1858 - val_loss: 37.3186 - val_tf_rse: 1.0729 - val_tf_corr: 0.0763 - val_mean_absolute_error: 0.2023 - val_mean_squared_error: 0.0766 - val_root_mean_squared_error: 0.2768 - val_mean_absolute_percentage_error: 37.3186\n",
      "Epoch 116/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 30.5640 - tf_rse: 0.5739 - tf_corr: 0.8277 - mean_absolute_error: 0.2051 - mean_squared_error: 0.0750 - root_mean_squared_error: 0.2739 - mean_absolute_percentage_error: 30.5640 - val_loss: 37.4832 - val_tf_rse: 1.0940 - val_tf_corr: 0.0728 - val_mean_absolute_error: 0.2068 - val_mean_squared_error: 0.0787 - val_root_mean_squared_error: 0.2806 - val_mean_absolute_percentage_error: 37.4832\n",
      "Epoch 117/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 30.6344 - tf_rse: 0.5626 - tf_corr: 0.8292 - mean_absolute_error: 0.2063 - mean_squared_error: 0.0760 - root_mean_squared_error: 0.2757 - mean_absolute_percentage_error: 30.6344 - val_loss: 38.1799 - val_tf_rse: 1.0665 - val_tf_corr: 0.0680 - val_mean_absolute_error: 0.2011 - val_mean_squared_error: 0.0763 - val_root_mean_squared_error: 0.2763 - val_mean_absolute_percentage_error: 38.1799\n",
      "Epoch 118/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 30.9296 - tf_rse: 0.5605 - tf_corr: 0.8346 - mean_absolute_error: 0.2065 - mean_squared_error: 0.0762 - root_mean_squared_error: 0.2760 - mean_absolute_percentage_error: 30.9296 - val_loss: 37.8694 - val_tf_rse: 1.0611 - val_tf_corr: 0.0658 - val_mean_absolute_error: 0.2000 - val_mean_squared_error: 0.0759 - val_root_mean_squared_error: 0.2756 - val_mean_absolute_percentage_error: 37.8694\n",
      "Epoch 119/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 30.2149 - tf_rse: 0.5659 - tf_corr: 0.8265 - mean_absolute_error: 0.2061 - mean_squared_error: 0.0760 - root_mean_squared_error: 0.2757 - mean_absolute_percentage_error: 30.2149 - val_loss: 37.1607 - val_tf_rse: 1.1182 - val_tf_corr: 0.0684 - val_mean_absolute_error: 0.2120 - val_mean_squared_error: 0.0815 - val_root_mean_squared_error: 0.2855 - val_mean_absolute_percentage_error: 37.1607\n",
      "Epoch 120/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 30.4630 - tf_rse: 0.5652 - tf_corr: 0.8287 - mean_absolute_error: 0.2062 - mean_squared_error: 0.0753 - root_mean_squared_error: 0.2744 - mean_absolute_percentage_error: 30.4630 - val_loss: 37.9723 - val_tf_rse: 1.0689 - val_tf_corr: 0.0794 - val_mean_absolute_error: 0.2014 - val_mean_squared_error: 0.0765 - val_root_mean_squared_error: 0.2766 - val_mean_absolute_percentage_error: 37.9723\n",
      "Epoch 121/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 30.9470 - tf_rse: 0.5633 - tf_corr: 0.8262 - mean_absolute_error: 0.2059 - mean_squared_error: 0.0754 - root_mean_squared_error: 0.2746 - mean_absolute_percentage_error: 30.9470 - val_loss: 37.5501 - val_tf_rse: 1.0558 - val_tf_corr: 0.0729 - val_mean_absolute_error: 0.1987 - val_mean_squared_error: 0.0756 - val_root_mean_squared_error: 0.2749 - val_mean_absolute_percentage_error: 37.5501\n",
      "Epoch 122/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 30.4002 - tf_rse: 0.5640 - tf_corr: 0.8248 - mean_absolute_error: 0.2058 - mean_squared_error: 0.0759 - root_mean_squared_error: 0.2755 - mean_absolute_percentage_error: 30.4002 - val_loss: 38.1439 - val_tf_rse: 1.0571 - val_tf_corr: 0.0720 - val_mean_absolute_error: 0.1991 - val_mean_squared_error: 0.0756 - val_root_mean_squared_error: 0.2750 - val_mean_absolute_percentage_error: 38.1439\n",
      "Epoch 123/1000\n",
      "687/687 [==============================] - 18s 27ms/step - loss: 30.3408 - tf_rse: 0.5736 - tf_corr: 0.8204 - mean_absolute_error: 0.2066 - mean_squared_error: 0.0765 - root_mean_squared_error: 0.2765 - mean_absolute_percentage_error: 30.3408 - val_loss: 38.1544 - val_tf_rse: 1.0660 - val_tf_corr: 0.0727 - val_mean_absolute_error: 0.2011 - val_mean_squared_error: 0.0764 - val_root_mean_squared_error: 0.2763 - val_mean_absolute_percentage_error: 38.1544\n",
      "Epoch 124/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 30.2955 - tf_rse: 0.5682 - tf_corr: 0.8285 - mean_absolute_error: 0.2065 - mean_squared_error: 0.0763 - root_mean_squared_error: 0.2762 - mean_absolute_percentage_error: 30.2955 - val_loss: 38.5472 - val_tf_rse: 1.0514 - val_tf_corr: 0.0722 - val_mean_absolute_error: 0.1977 - val_mean_squared_error: 0.0751 - val_root_mean_squared_error: 0.2740 - val_mean_absolute_percentage_error: 38.5472\n",
      "Epoch 125/1000\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 30.2539 - tf_rse: 0.5587 - tf_corr: 0.8323 - mean_absolute_error: 0.2065 - mean_squared_error: 0.0757 - root_mean_squared_error: 0.2752 - mean_absolute_percentage_error: 30.2539 - val_loss: 37.8511 - val_tf_rse: 1.0776 - val_tf_corr: 0.0741 - val_mean_absolute_error: 0.2035 - val_mean_squared_error: 0.0775 - val_root_mean_squared_error: 0.2783 - val_mean_absolute_percentage_error: 37.8511\n",
      "Epoch 126/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.3695 - tf_rse: 0.5636 - tf_corr: 0.8291 - mean_absolute_error: 0.2065 - mean_squared_error: 0.0759 - root_mean_squared_error: 0.2754 - mean_absolute_percentage_error: 30.3695 - val_loss: 37.4468 - val_tf_rse: 1.0864 - val_tf_corr: 0.0666 - val_mean_absolute_error: 0.2060 - val_mean_squared_error: 0.0792 - val_root_mean_squared_error: 0.2814 - val_mean_absolute_percentage_error: 37.4468\n",
      "Epoch 127/1000\n",
      "687/687 [==============================] - 17s 24ms/step - loss: 30.4370 - tf_rse: 0.5739 - tf_corr: 0.8210 - mean_absolute_error: 0.2078 - mean_squared_error: 0.0769 - root_mean_squared_error: 0.2774 - mean_absolute_percentage_error: 30.4370 - val_loss: 36.7909 - val_tf_rse: 1.1116 - val_tf_corr: 0.0649 - val_mean_absolute_error: 0.2112 - val_mean_squared_error: 0.0819 - val_root_mean_squared_error: 0.2862 - val_mean_absolute_percentage_error: 36.7909\n",
      "Epoch 128/1000\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 30.7708 - tf_rse: 0.5656 - tf_corr: 0.8290 - mean_absolute_error: 0.2074 - mean_squared_error: 0.0762 - root_mean_squared_error: 0.2761 - mean_absolute_percentage_error: 30.7708 - val_loss: 38.3657 - val_tf_rse: 1.0568 - val_tf_corr: 0.0675 - val_mean_absolute_error: 0.1991 - val_mean_squared_error: 0.0758 - val_root_mean_squared_error: 0.2754 - val_mean_absolute_percentage_error: 38.3657\n",
      "Epoch 129/1000\n",
      "541/687 [======================>.......] - ETA: 3s - loss: 30.1028 - tf_rse: 0.5592 - tf_corr: 0.8288 - mean_absolute_error: 0.2051 - mean_squared_error: 0.0756 - root_mean_squared_error: 0.2750 - mean_absolute_percentage_error: 30.1028"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape = (10,num_vars)\n",
    "#print(f\"data.train: {type(Data.train)}\")\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    # loss=tf.losses.MeanSquaredError(),\n",
    "    loss=tf.losses.MeanAbsolutePercentageError(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError(), tf.metrics.MeanAbsolutePercentageError()]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=40,\n",
    "                                                mode='min',\n",
    "                                                restore_best_weights=True)\n",
    "\n",
    "fit_data = model.fit(\n",
    "                    data_train_x_float32, \n",
    "                    data_train_y_float32_32_thread_reshaped,\n",
    "                    epochs=1000, \n",
    "                    validation_data=(data_valid_x_float32, \n",
    "                          data_valid_y_float32_32_thread_reshaped), \n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(data_test_x_float32, data_test_y_float32_32_thread_reshaped, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_1_predicted = model.predict(data_test_x_float32)\n",
    "\n",
    "np.save('predicted_results/transformer_predicted.npy', transformer_1_predicted)\n",
    "np.savetxt('predicted_results/transformer_predicted.txt', transformer_1_predicted)\n",
    "model.save_weights('./checkpoints/transformer_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_data.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fit_data.history['loss'], label='train')\n",
    "plt.plot(fit_data.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fit_data.history['mean_absolute_percentage_error'], label='train')\n",
    "plt.plot(fit_data.history['val_mean_absolute_percentage_error'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fit_data.history['root_mean_squared_error'], label='train')\n",
    "plt.plot(fit_data.history['val_root_mean_squared_error'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 8))\n",
    "data_high = 2000\n",
    "data_low = 0\n",
    "anomaly_index_list = SimpleAnomalyDetection(data_test_y_float32_32_thread_reshaped, transformer_1_predicted, data_high, data_low=data_low, threshold=2)\n",
    "\n",
    "anomaly_y_coords = []\n",
    "\n",
    "for x in anomaly_index_list:\n",
    "  anomaly_y_coords.append(data_test_y_float32_32_thread_reshaped[x])\n",
    "\n",
    "print(f\"The len of anomalyList: {len(anomaly_index_list)}\")\n",
    "colors = cm.rainbow(np.linspace(1, 1, len(anomaly_index_list)))\n",
    "plt.plot(data_test_y_float32_32_thread_reshaped[data_low:data_high])\n",
    "plt.plot(transformer_1_predicted[data_low:data_high])\n",
    "plt.scatter(anomaly_index_list, anomaly_y_coords, c=colors)\n",
    "\n",
    "plt.legend([\"Actual\", \"Anomoly Points\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(f\"data.train: {Data.train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_history = model.fit\n",
    "# train_history.history['accuracy']\n",
    "# plt.plot(train_history.history['accuracy'])\n",
    "# plt.plot(train_history.history['val_accuracy'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#f = open(\"TransformerResults2.txt\", \"w\")\n",
    "results = []\n",
    "testing_head_size = [4,2,3,5,6]\n",
    "testing_num_heads = [4,3] #[4,2,3,5,6]\n",
    "testing_ff_dim = [4,3,4,5,6]\n",
    "testing_num_transformer_blocks = [4,6] #[2,3,4,5,6]\n",
    "# for x in testing_head_size:\n",
    "#     tempResults = []\n",
    "    \n",
    "#     input_shape = (10,3)\n",
    "#     #print(f\"data.train: {type(Data.train)}\")\n",
    "#     model = build_model(\n",
    "#         input_shape,\n",
    "#         head_size=x,\n",
    "#         num_heads=4,\n",
    "#         ff_dim=4,\n",
    "#         num_transformer_blocks=4,\n",
    "#         mlp_units=[128],\n",
    "#         mlp_dropout=0.4,\n",
    "#         dropout=0.25,\n",
    "#     )\n",
    "#     testCase = \"head_size \" + str(x)\n",
    "#     tempResults.append(testCase)\n",
    "\n",
    "#     model.compile(\n",
    "#         loss=tf.losses.MeanSquaredError(),\n",
    "#         optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "#         metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()]\n",
    "#     )\n",
    "#     model.summary()\n",
    "\n",
    "#     callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "#     model.fit(\n",
    "#         Data.train[0][:,:,:], Data.train[1][:,0],\n",
    "#         validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]),\n",
    "#         epochs=2000,\n",
    "#         batch_size=64,\n",
    "#     )\n",
    "#     tempResults.append(model.evaluate(Data.test[0][:,:,:], Data.test[1][:,0], verbose=1))\n",
    "#     results.append(tempResults)\n",
    "for x in testing_num_heads:\n",
    "    tempResults = []\n",
    "    \n",
    "    input_shape = (10,3)\n",
    "    #print(f\"data.train: {type(Data.train)}\")\n",
    "    model = build_model(\n",
    "        input_shape,\n",
    "        head_size=4,\n",
    "        num_heads=x,\n",
    "        ff_dim=4,\n",
    "        num_transformer_blocks=4,\n",
    "        mlp_units=[128],\n",
    "        mlp_dropout=0.4,\n",
    "        dropout=0.25,\n",
    "    )\n",
    "    testCase = \"num_heads \" + str(x)\n",
    "    tempResults.append(testCase)\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.losses.MeanSquaredError(),\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "    model.fit(\n",
    "        Data.train[0][:,:,:], Data.train[1][:,0],\n",
    "        validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]),\n",
    "        epochs=200,\n",
    "        batch_size=64,\n",
    "    )\n",
    "    tempResults.append(model.evaluate(Data.test[0][:,:,:], Data.test[1][:,0], verbose=1))\n",
    "    results.append(tempResults)\n",
    "# for x in testing_ff_dim:\n",
    "#     tempResults = []\n",
    "    \n",
    "#     input_shape = (10,3)\n",
    "#     #print(f\"data.train: {type(Data.train)}\")\n",
    "#     model = build_model(\n",
    "#         input_shape,\n",
    "#         head_size=4,\n",
    "#         num_heads=4,\n",
    "#         ff_dim=x,\n",
    "#         num_transformer_blocks=4,\n",
    "#         mlp_units=[128],\n",
    "#         mlp_dropout=0.4,\n",
    "#         dropout=0.25,\n",
    "#     )\n",
    "#     testCase = \"ff_dim \" + str(x)\n",
    "#     tempResults.append(testCase)\n",
    "\n",
    "#     model.compile(\n",
    "#         loss=tf.losses.MeanSquaredError(),\n",
    "#         optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "#         metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()]\n",
    "#     )\n",
    "#     model.summary()\n",
    "\n",
    "#     callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "#     model.fit(\n",
    "#         Data.train[0][:,:,:], Data.train[1][:,0],\n",
    "#         validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]),\n",
    "#         epochs=2000,\n",
    "#         batch_size=64,\n",
    "#     )\n",
    "#     tempResults.append(model.evaluate(Data.test[0][:,:,:], Data.test[1][:,0], verbose=1))\n",
    "#     results.append(tempResults)\n",
    "for x in testing_num_transformer_blocks:\n",
    "    tempResults = []\n",
    "    \n",
    "    input_shape = (10,3)\n",
    "    #print(f\"data.train: {type(Data.train)}\")\n",
    "    model = build_model(\n",
    "        input_shape,\n",
    "        head_size=4,\n",
    "        num_heads=4,\n",
    "        ff_dim=4,\n",
    "        num_transformer_blocks=x,\n",
    "        mlp_units=[128],\n",
    "        mlp_dropout=0.4,\n",
    "        dropout=0.25,\n",
    "    )\n",
    "    testCase = \"num_transformer_blocks \" + str(x)\n",
    "    tempResults.append(testCase)\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.losses.MeanSquaredError(),\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "    model.fit(\n",
    "        Data.train[0][:,:,:], Data.train[1][:,0],\n",
    "        validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]),\n",
    "        epochs=200,\n",
    "        batch_size=64,\n",
    "    )\n",
    "    tempResults.append(model.evaluate(Data.test[0][:,:,:], Data.test[1][:,0], verbose=1))\n",
    "    results.append(tempResults)\n",
    "    #for i in results:\n",
    "        #print(i)\n",
    "        #f.write(str(i))\n",
    "        #f.write(\"Hello\")\n",
    "#f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data.train[0][:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.train[1][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training = np.array([np.array(xi) for xi in Data.train])\n",
    "latency = []\n",
    "throughput = []\n",
    "tcp_buffer_size = []\n",
    "counter = 0\n",
    "for x in range(1):\n",
    "    \n",
    "    for y in range(10):\n",
    "        latency_list = []\n",
    "        throughput_list = []\n",
    "        tcp_buffer_size_list = []\n",
    "        for z in Data.train[x][y]:\n",
    "            #print(f\"y is: {z}\")\n",
    "            latency_list.append(z[0])\n",
    "            throughput_list.append(z[1])\n",
    "            tcp_buffer_size_list.append(z[2])\n",
    "        latency.append(latency_list)\n",
    "        throughput.append(throughput_list)\n",
    "        tcp_buffer_size.append(tcp_buffer_size_list)\n",
    "    break\n",
    "#print(f\"latency: {latency[0]}\")\n",
    "training = np.array([np.array(xi) for xi in latency])\n",
    "training = Data.train.reshape((Data.train[0].shape[0], data.train[0].shape[1], 1))\n",
    "#x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "#print(f\"data train is: {training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance = {}\n",
    "performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Root relative squared error\n",
    "def tf_rse(y_true, y_pred):\n",
    "    #\n",
    "    # The formula is:\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred)))     \n",
    "    #    RSE = -----------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)))       \n",
    "    #\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred))/(N-1))\n",
    "    #        = ----------------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)/(N-1)))\n",
    "    #\n",
    "    #\n",
    "    #           K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    #        = ------------------------------------------\n",
    "    #           K.std(y_true)\n",
    "    #\n",
    "    num = K.sqrt(K.mean(K.square(y_true - y_pred), axis=None))\n",
    "    den = K.std(y_true, axis=None)\n",
    "    \n",
    "    return num / den\n",
    "\n",
    "def rse_test1(y_true, y_pred):\n",
    "    return K.square(y_true - y_pred)\n",
    "\n",
    "def rse_test2(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred), axis=None))\n",
    "\n",
    "def rse_test3(y_true, y_pred):\n",
    "    return K.std(y_true, axis=None)\n",
    "\n",
    "def rse(y_true, y_pred):\n",
    "    #\n",
    "    # The formula is:\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred)))     \n",
    "    #    RSE = -----------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)))       \n",
    "    #\n",
    "    #           K.sqrt(K.sum(K.square( y_true - y_pred))/(N-1))\n",
    "    #        = ----------------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)/(N-1)))\n",
    "    #\n",
    "    #\n",
    "    #           K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    #        = ------------------------------------------\n",
    "    #           K.std(y_true)\n",
    "    #\n",
    "    num = np.sqrt(np.mean(np.square(y_true - y_pred), axis=None))\n",
    "    den = np.std(y_true, axis=None)\n",
    "    \n",
    "    return num / den\n",
    "\n",
    "def tf_corr(y_true, y_pred):\n",
    "    #\n",
    "    # This function calculates the correlation between the true and the predicted outputs\n",
    "    #\n",
    "    num1 = y_true - K.mean(y_true, axis=0)\n",
    "    num2 = y_pred - K.mean(y_pred, axis=0)\n",
    "    \n",
    "    num  = K.mean(num1 * num2, axis=0)\n",
    "    den  = K.std(y_true, axis=0) * K.std(y_pred, axis=0)\n",
    "    \n",
    "    return K.mean(num / den)\n",
    "\n",
    "def corr(y_true, y_pred):\n",
    "    #\n",
    "    # This function calculates the correlation between the true and the predicted outputs\n",
    "    #\n",
    "    num1 = y_true - np.mean(y_true, axis=0)\n",
    "    num2 = y_pred - np.mean(y_pred, axis=0)\n",
    "    \n",
    "    num  = np.mean(num1 * num2, axis=0)\n",
    "    den  = np.std(y_true, axis=0) * np.std(y_pred, axis=0)\n",
    "    \n",
    "    return np.mean(num / den)\n",
    "\n",
    "def single_rse(y_true, y_pred):\n",
    "    #\n",
    "    # The formula is:\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred)))     \n",
    "    #    RSE = -----------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)))       \n",
    "    #\n",
    "    #           K.sqrt(K.sum(K.square(y_true - y_pred))/(N-1))\n",
    "    #        = ----------------------------------------------------\n",
    "    #           K.sqrt(K.sum(K.square(y_true_mean - y_true)/(N-1)))\n",
    "    #\n",
    "    #\n",
    "    #           K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "    #        = ------------------------------------------\n",
    "    #           K.std(y_true)\n",
    "    #\n",
    "    num = K.sqrt(K.mean(K.square(y_true[:,0] - y_pred[:,0]), axis=None))\n",
    "    den = K.std(y_true, axis=None)\n",
    "    \n",
    "    return num / den\n",
    "\n",
    "\n",
    "def single_corr(y_true, y_pred):\n",
    "    #\n",
    "    # This function calculates the correlation between the true and the predicted outputs\n",
    "    #\n",
    "    num1 = y_true[:,0] - K.mean(y_true[:,0], axis=0)\n",
    "    num2 = y_pred[:,0] - K.mean(y_pred[:,0], axis=0)\n",
    "    \n",
    "    num  = K.mean(num1 * num2, axis=0)\n",
    "    den  = K.std(y_true[:,0], axis=0) * K.std(y_pred[:,0], axis=0)\n",
    "    \n",
    "    return K.mean(num / den)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=10,\n",
    "                                                mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.train[0][:,:,0:3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.train[1][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = {}\n",
    "accuracy_stats['rmse'] = {}\n",
    "accuracy_stats['rse'] = {}\n",
    "accuracy_stats['corr'] = {}\n",
    "accuracy_stats['accuracy'] = {}\n",
    "accuracy_stats['mae'] = {}\n",
    "accuracy_stats['predicted'] = {}\n",
    "accuracy_stats['mse'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MLP\n",
    "\n",
    "Here we are testing the effectiveness of a simple ANN (MLP) on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(10,3)),\n",
    "    tf.keras.layers.Dense(units=15),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=15),\n",
    "    tf.keras.layers.Dense(units=1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.train[1][:,0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.fit(Data.train[0][:,:,:], Data.train[1][:,0].reshape(Data.train[1][:,0].shape[0],1), epochs=100, validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0].reshape(Data.valid[1][:,0].shape[0],1)), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_stats = linear.evaluate(Data.test[0], Data.test[1][:,0].reshape(2933,1))\n",
    "linear_stats = linear.evaluate(Data.test[0], Data.test[1][:,0].reshape(25230,1))\n",
    "\n",
    "linear_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predicted = linear.predict(Data.test[0][:,:,:])\n",
    "\n",
    "np.save('predicted_results/mlp_predicted.npy', linear_predicted)\n",
    "np.savetxt('predicted_results/mlp_predicted.txt', linear_predicted)\n",
    "linear.save_weights('./checkpoints/linear_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import iqr\n",
    "import matplotlib.cm as cm\n",
    "Data.test[1][0:25230,0]\n",
    "linear_predicted[0:25230]\n",
    "inquartileRange = iqr(Data.test[1][0:25230,0],interpolation = 'midpoint')\n",
    "print(inquartileRange)\n",
    "higherRange = inquartileRange * 1.5\n",
    "\n",
    "import numpy as np\n",
    "# First quartile (Q1)\n",
    "#print(Data.test[])\n",
    "Q1 = np.median(Data.test[1][:12615,0])\n",
    "  \n",
    "# Third quartile (Q3)\n",
    "Q3 = np.median(Data.test[1][12615:,0])\n",
    "  \n",
    "# Interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "print(f\"IQR: {IQR}\")\n",
    "# Quartile Deviation\n",
    "qd = IQR / 2\n",
    "  \n",
    "print(f\"Quartile Deviation: {qd}\")\n",
    "highRange = IQR + qd\n",
    "lowRange = IQR - qd\n",
    "print(f\"High Range: {highRange}\")\n",
    "print(f\"Low Range: {lowRange}\")\n",
    "# plt.plot(Data.test[1][0:25230,0])\n",
    "# print(linear_predicted[0:25230])\n",
    "# anomolyList =[]\n",
    "# anomolyListXCoords =[]\n",
    "# count = 0\n",
    "# for x in Data.test[1][0:25230,0]:\n",
    "#     if x > 2 or x <-1:\n",
    "#         anomolyList.append([x])\n",
    "#         anomolyListXCoords.append(count)\n",
    "#     count = count + 1\n",
    "# colors = cm.rainbow(np.linspace(1, 1, 2119))\n",
    "# #print(anomolyList)\n",
    "# #plt.scatter(linear_predicted[0:25230])\n",
    "# plt.scatter(anomolyListXCoords, anomolyList, c=colors)\n",
    "# plt.legend([\"Actual\", \"Anomoly Points\"])\n",
    "# plt.show()\n",
    "print(Data.test[0][1,:])\n",
    "#Data.test[x] shows data in the format [throughput, latency, bufferSize] . Focus Anomoly detection on both Throughput and Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import matplotlib.cm as cm\n",
    "dataRange = 500\n",
    "Data.test[1][0:25230,0]\n",
    "linear_predicted[0:25230]\n",
    "plt.plot(Data.test[1][0:dataRange,0])\n",
    "#print(linear_predicted[0:25230])\n",
    "anomalyList =[]\n",
    "anomalyListXCoords =[]\n",
    "count = 0\n",
    "total=0\n",
    "for x in range(dataRange):\n",
    "    difference = abs(Data.test[1][x,0]-linear_predicted[x])\n",
    "    total = difference + total\n",
    "    count += 1\n",
    "total = total / count\n",
    "print(f\"The Average is: {total}\")\n",
    "count = 0\n",
    "for x in range(dataRange):\n",
    "    difference = abs(Data.test[1][x,0]-linear_predicted[x])\n",
    "    if difference > 3*total:\n",
    "        anomalyList.append(Data.test[1][x,0])\n",
    "        anomalyListXCoords.append(count)\n",
    "    count += 1\n",
    "percentageAnomalous =  round(len(anomalyList)/dataRange *100)\n",
    "print(f\"The percentage of total anomalous points was: {percentageAnomalous}%\")\n",
    "colors = cm.rainbow(np.linspace(1, 1, len(anomalyList)))\n",
    "print(f\"The len of anomalyList: {len(anomalyList)}\")\n",
    "#print(anomolyList)\n",
    "#plt.scatter(linear_predicted[0:25230])\n",
    "#print(f\"The anomalyList: {anomalyList}\\nThe anomalyListXCoords: {anomalyListXCoords}\")\n",
    "\n",
    "plt.scatter(anomalyListXCoords, anomalyList, c=colors)\n",
    "#plt.scatter([1762, 4443, 19902, 23501, 25112], [3.7193446, 4.0872087, 4.4067316, 3.9032767, 4.3992643])#, c=colors)\n",
    "\n",
    "plt.legend([\"Actual\", \"Anomoly Points\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Data.test[1][0:25230,0])\n",
    "plt.plot(linear_predicted[0:25230])\n",
    "plt.legend([\"Actual\", \"Predicted\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(Data.test[1][:,0], linear_predicted.flatten())\n",
    "rmse = sqrt(mean_squared_error(Data.test[1][:,0], linear_predicted.flatten()))\n",
    "mae = mean_absolute_error(Data.test[1][:,0], linear_predicted.flatten())\n",
    "rse_val = rse(Data.test[1][:,0], linear_predicted.flatten())\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "\n",
    "accuracy_stats['rmse']['mlp'] = rmse\n",
    "accuracy_stats['rse']['mlp'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['mlp'] = mae\n",
    "accuracy_stats['predicted']['mlp'] = linear_predicted\n",
    "accuracy_stats['mse']['mlp'] = mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMPLE LSTM\n",
    "\n",
    "Here we run our data through a simple lstm for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.train[0][:,:,0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.train[0][:,:,0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lstm network\n",
    "\n",
    "# lstm_model = tf.keras.models.Sequential([\n",
    "#     # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "#     tf.keras.layers.GRU(32, input_shape=(10), return_sequences=False),\n",
    "#     # Shape => [batch, time, features]\n",
    "#     tf.keras.layers.Dense(units=1)\n",
    "# ])\n",
    "\n",
    "ts_inputs = tf.keras.Input(shape=(10,3))\n",
    "x = tf.keras.layers.LSTM(units=250, dropout=0.1, recurrent_dropout=0.1)(ts_inputs)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(1,activation='linear')(x)\n",
    "lstm_model = tf.keras.Model(inputs=ts_inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lstm_model.fit(Data.train[0][:,:,:], Data.train[1][:,0], \n",
    "               epochs=100, \n",
    "               validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]), \n",
    "               callbacks=[early_stopping],\n",
    "               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_stats = lstm_model.evaluate(Data.test[0][:,:,:], Data.test[1][:,0])\n",
    "lstm_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted = lstm_model.predict(Data.test[0][:,:,:]).flatten()\n",
    "\n",
    "np.save('predicted_results/lstm_predicted.npy', lstm_predicted)\n",
    "np.savetxt('predicted_results/lstm_predicted.txt', lstm_predicted)\n",
    "lstm_model.save_weights('./checkpoints/lstm_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted = np.load('predicted_results/lstm_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "data_true = Data.test[1][:,0]*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100\n",
    "lstm_mape = mean_absolute_percentage_error(data_true, lstm_predicted)\n",
    "lstm_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Data.test[1][0:50,0])\n",
    "plt.plot(lstm_predicted[0:50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 10))\n",
    "plt.plot(Data.test[1][:,0],label=\"actual\")\n",
    "plt.plot(lstm_predicted, color='r',label=\"predicted\")\n",
    "plt.legend(loc='best', fontsize='xx-large')\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(Data.test[1][:,0], lstm_predicted)\n",
    "rmse = sqrt(mean_squared_error(Data.test[1][:,0], lstm_predicted))\n",
    "mae = mean_absolute_error(Data.test[1][:,0], lstm_predicted)\n",
    "rse_val = rse(Data.test[1][:,0], lstm_predicted)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "\n",
    "accuracy_stats['rmse']['lstm'] = rmse\n",
    "accuracy_stats['rse']['lstm'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['lstm'] = mae\n",
    "accuracy_stats['predicted']['lstm'] = lstm_predicted\n",
    "accuracy_stats['mse']['lstm'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.test[1][:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GRU\n",
    "\n",
    "Do the same thing but with a GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_inputs = tf.keras.Input(shape=(10,3))\n",
    "x = tf.keras.layers.GRU(units=250, dropout=0.1)(ts_inputs)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(1,activation='linear')(x)\n",
    "gru_model = tf.keras.Model(inputs=ts_inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                  optimizer=tf.optimizers.Adam(),\n",
    "                  metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.fit(Data.train[0][:,:,:], Data.train[1][:,0], \n",
    "               epochs=100, \n",
    "               validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]), \n",
    "               callbacks=[early_stopping],\n",
    "               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.evaluate(Data.test[0][:,:,:], Data.test[1][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_predicted = gru_model.predict(Data.test[0][:,:,:]).flatten()\n",
    "\n",
    "np.save('predicted_results/gru_predicted.npy', gru_predicted)\n",
    "np.savetxt('predicted_results/gru_predicted.txt', gru_predicted)\n",
    "gru_model.save_weights('./checkpoints/gru_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_predicted = np.load('predicted_results/gru_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "data_true = Data.test[1][:,0]*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100\n",
    "gru_mape = mean_absolute_percentage_error(data_true, gru_predicted)\n",
    "gru_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Data.test[1][0:100,0], label='actual')\n",
    "plt.plot(gru_predicted[0:100], label=\"predicted\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(Data.test[1][:,0], gru_predicted)\n",
    "rmse = sqrt(mean_squared_error(Data.test[1][:,0], gru_predicted))\n",
    "mae = mean_absolute_error(Data.test[1][:,0], gru_predicted)\n",
    "rse_val = rse(Data.test[1][:,0], gru_predicted)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "\n",
    "accuracy_stats['rmse']['gru'] = rmse\n",
    "accuracy_stats['rse']['gru'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['gru'] = mae\n",
    "accuracy_stats['predicted']['gru'] = gru_predicted\n",
    "accuracy_stats['mse']['gru'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "\n",
    "\n",
    "# cnn_model = Sequential()\n",
    "# cnn_model.add(Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=(10, 3)))\n",
    "# cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "# cnn_model.add(Flatten())\n",
    "# cnn_model.add(Dense(50, activation='relu'))\n",
    "# cnn_model.add(Dense(1))\n",
    "# cnn_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=30, kernel_size=5, activation='relu', padding='SAME', strides=1, input_shape=(10, 3)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "cnn_model.add(Conv1D(filters=45, kernel_size=5, activation='relu', padding='SAME', strides=1))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "cnn_model.add(Conv1D(filters=60, kernel_size=5, activation='relu', padding='SAME', strides=1))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(120, activation='relu'))\n",
    "cnn_model.add(Dense(1))\n",
    "# cnn_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "              optimizer=tf.optimizers.Adam(),\n",
    "              metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.fit(Data.train[0][:,:,:], Data.train[1][:,0], \n",
    "               epochs=100, \n",
    "               validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]), \n",
    "               callbacks=[early_stopping],\n",
    "               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_stats = cnn_model.evaluate(Data.test[0][:,:,:], Data.test[1][:,0])\n",
    "cnn_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_predicted = cnn_model.predict(Data.test[0][:,:,:]).flatten()\n",
    "\n",
    "np.save('predicted_results/cnn_predicted.npy', cnn_predicted)\n",
    "np.savetxt('predicted_results/cnn_predicted.txt', cnn_predicted)\n",
    "cnn_model.save_weights('./checkpoints/cnn_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Data.test[1][0:100,0], label='actual')\n",
    "plt.plot(cnn_predicted[0:100], label=\"predicted\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(Data.test[1][:,0], cnn_predicted)\n",
    "rmse = sqrt(mean_squared_error(Data.test[1][:,0], cnn_predicted))\n",
    "mae = mean_absolute_error(Data.test[1][:,0], cnn_predicted)\n",
    "rse_val = rse(Data.test[1][:,0], cnn_predicted)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "\n",
    "accuracy_stats['rmse']['cnn'] = rmse\n",
    "accuracy_stats['rse']['cnn'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['cnn'] = mae\n",
    "accuracy_stats['predicted']['cnn'] = cnn_predicted\n",
    "accuracy_stats['mse']['cnn'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_predicted = np.load('predicted_results/cnn_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "data_true = Data.test[1][:,0]*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "\n",
    "cnn_mape = mean_absolute_percentage_error(data_true, cnn_predicted)\n",
    "cnn_mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-LSTM HYBRID MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, Conv2D, LSTM, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model = Sequential()\n",
    "cnn_lstm_model.add(Conv1D(filters=64, kernel_size=5, activation='relu', padding='SAME', strides=1, input_shape=(10, 3)))\n",
    "cnn_lstm_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "cnn_lstm_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='SAME', strides=1))\n",
    "cnn_lstm_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "# cnn_lstm_model.add(Conv1D(filters=10, kernel_size=3, activation='relu', padding='SAME', strides=1))\n",
    "# cnn_lstm_model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "# cnn_model.add(Flatten())\n",
    "cnn_lstm_model.add(LSTM(32, dropout=0.1, recurrent_dropout=0.1, return_sequences=False))\n",
    "cnn_lstm_model.add(Dense(100, activation='relu'))\n",
    "cnn_lstm_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                       optimizer=tf.optimizers.Adam(),\n",
    "                       metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model.fit(Data.train[0][:,:,:], Data.train[1][:,0], \n",
    "                   epochs=100, \n",
    "                   validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]), \n",
    "                   callbacks=[early_stopping],\n",
    "                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm1_stats = cnn_lstm_model.evaluate(Data.test[0][:,:,:], Data.test[1][:,0])\n",
    "cnn_lstm1_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_predicted = cnn_lstm_model.predict(Data.test[0][:,:,:]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Data.test[1][0:100,0], label='actual')\n",
    "plt.plot(cnn_lstm_predicted[0:100], label=\"predicted\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(Data.test[1][:,0], cnn_lstm_predicted)\n",
    "rmse = sqrt(mean_squared_error(Data.test[1][:,0], cnn_lstm_predicted))\n",
    "mae = mean_absolute_error(Data.test[1][:,0], cnn_lstm_predicted)\n",
    "rse_val = rse(Data.test[1][:,0], cnn_lstm_predicted)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "\n",
    "accuracy_stats['rmse']['cnn_lstm'] = rmse\n",
    "accuracy_stats['rse']['cnn_lstm'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['cnn_lstm'] = mae\n",
    "accuracy_stats['predicted']['cnn_lstm'] = cnn_lstm_predicted\n",
    "accuracy_stats['mse']['cnn_lstm'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=10,\n",
    "                                                mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, LSTM, MaxPooling2D, Reshape, TimeDistributed, Input, Dropout, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Input(shape = (10,3))\n",
    "\n",
    "\n",
    "#CNN\n",
    "C = Reshape((10, 3, 1))(X)\n",
    "\n",
    "# Apply a Conv2D that will transform it into data of dimensions (batchsize, time, 1, NumofFilters)\n",
    "C = Conv2D(filters=200, kernel_size=(1, 3), kernel_initializer='glorot_uniform')(C)\n",
    "C = Dropout(0.2)(C)\n",
    "\n",
    "# Adjust data dimensions by removing axis=2 which is always equal to 1\n",
    "c_shape = K.int_shape(C)\n",
    "C = Reshape((c_shape[1], c_shape[3]))(C)\n",
    "\n",
    "# Apply a GRU layer (with activation set to 'relu' as per the paper) and take the returned states as result\n",
    "_, R = GRU(200, activation=\"relu\", return_sequences = False, return_state = True)(C)\n",
    "R    = Dropout(0.2)(R)\n",
    "Y = Flatten()(R)\n",
    "Y = Dense(3)(Y)\n",
    "cnn_lstm_model2 = Model(inputs = X, outputs = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model2.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                       optimizer=tf.optimizers.Adam(),\n",
    "                       metrics=[tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.set_seed(123456)\n",
    "cnn_lstm_model2.fit(Data.train[0][:,:,:], Data.train[1][:,0], \n",
    "                   epochs=10, \n",
    "                   validation_data=(Data.valid[0][:,:,:], Data.valid[1]), \n",
    "                   callbacks=[early_stopping],\n",
    "                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model2.evaluate(Data.test[0][:,:,:], Data.test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model2_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_model2_predicted = cnn_lstm_model2.predict(Data.test[0][:,:,:])\n",
    "\n",
    "np.save('predicted_results/cnn_lstm_predicted.npy', cnn_lstm_model2_predicted)\n",
    "np.savetxt('predicted_results/cnn_lstm_predicted.txt', cnn_lstm_model2_predicted)\n",
    "cnn_lstm_model.save_weights('./checkpoints/cnn_lstm_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Data.test[1][0:100,0], label='actual')\n",
    "plt.plot(cnn_lstm_model2_predicted[0:100,0], label=\"predicted\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(Data.test[1][:,0], cnn_lstm_model2_predicted.flatten())\n",
    "rmse = sqrt(mean_squared_error(Data.test[1][:,0], cnn_lstm_model2_predicted.flatten()))\n",
    "mae = mean_absolute_error(Data.test[1][:,0], cnn_lstm_model2_predicted.flatten())\n",
    "rse_val = rse(Data.test[1][:,0], cnn_lstm_model2_predicted[:,0].flatten())\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RSE: {rse_val}')\n",
    "\n",
    "accuracy_stats['rmse']['cnn_lstm2'] = rmse\n",
    "accuracy_stats['rse']['cnn_lstm2'] = rse_val\n",
    "# accuracy_stats['corr']['mlp'] = corr\n",
    "# accuracy_stats['accuracy']['mlp'] = acc\n",
    "accuracy_stats['mae']['cnn_lstm2'] = mae\n",
    "accuracy_stats['predicted']['cnn_lstm2'] = cnn_lstm_model2_predicted\n",
    "accuracy_stats['mse']['cnn_lstm2'] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTNET MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, model_from_json\n",
    "\n",
    "custom_objects = {\n",
    "        'PreSkipTrans': PreSkipTrans,\n",
    "        'PostSkipTrans': PostSkipTrans,\n",
    "        'PreARTrans': PreARTrans,\n",
    "        'PostARTrans': PostARTrans\n",
    "        }\n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # print(\"CUSTOM LOSS BABBBY\")\n",
    "    # print(type(y_true))\n",
    "    # print(type(y_pred))\n",
    "    # print(y_true)\n",
    "    # print(y_true.shape)\n",
    "    # tf.print(y_true[:,0, sys.stdout)\n",
    "    return tf.keras.losses.mean_absolute_error(y_true[:,0], y_pred[:,0])\n",
    "\n",
    "file = 'models/model2.json'\n",
    "lstnet_model = None\n",
    "with open(file, \"r\") as json_file:\n",
    "  lstnet_model = model_from_json(json_file.read(), custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_model.compile(loss=custom_loss,\n",
    "                       optimizer=tf.optimizers.Adam(),\n",
    "                       metrics=[single_rse, single_corr, tf_rse, tf_corr, tf.metrics.MeanAbsoluteError(), tf.metrics.MeanSquaredError(), tf.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_model.fit(Data.train[0][:,:,:], Data.train[1][:,0], \n",
    "                   epochs=20, \n",
    "                   validation_data=(Data.valid[0][:,:,:], Data.valid[1][:,0]), \n",
    "                   callbacks=[early_stopping],\n",
    "                   shuffle=True,\n",
    "                   batch_size=91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_model.evaluate(Data.test[0], Data.test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_predicted = lstnet_model.predict(Data.test[0])\n",
    "\n",
    "np.save('predicted_results/lstnet_predicted.npy', lstnet_predicted)\n",
    "np.savetxt('predicted_results/lstnet_predicted.txt', lstnet_predicted)\n",
    "lstnet_model.save_weights('./checkpoints/lstnet_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Data.test[1][0:100,0], label='actual')\n",
    "plt.plot(lstnet_predicted[0:100, 0], label=\"predicted\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "print(f'MSE: {mean_squared_error(Data.test[1][:,0], lstnet_predicted[:,0])}')\n",
    "print(f'RMSE: {sqrt(mean_squared_error(Data.test[1][:,0], lstnet_predicted[:,0]))}')\n",
    "print(f'MAE: {mean_absolute_error(Data.test[1][:,0], lstnet_predicted[:,0])}')\n",
    "print(f'RSE: {rse(Data.test[1][:,0], lstnet_predicted[:,0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.test[1][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_predicted[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(Data.test[1][:,0]*Data.normalize_std[0] + Data.normalize_mean[0], lstnet_predicted[:,0]*Data.normalize_std[0] + Data.normalize_mean[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between Different Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_predicted = np.load('predicted_results/mlp_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "lstm_predicted = np.load('predicted_results/lstm_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "gru_predicted = np.load('predicted_results/gru_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "cnn_predicted = np.load('predicted_results/cnn_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "cnn_lstm_predicted = np.load('predicted_results/cnn_lstm_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "lstnet_predicted = np.load('predicted_results/lstnet_predicted.npy')*Data.normalize_std[0] + Data.normalize_mean[0]\n",
    "\n",
    "data_true = Data.test[1][:,0]*Data.normalize_std[0] + Data.normalize_mean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "\n",
    "# Create cycler object. Use any styling from above you please\n",
    "monochrome = (cycler('color', ['k']) * cycler('linestyle', ['-', '--', ':']) * cycler('marker', ['^',',', '.']))\n",
    "\n",
    "# Print examples of output from cycler object. \n",
    "# A cycler object, when called, returns a `iter.cycle` object that iterates over items indefinitely\n",
    "\n",
    "default_cycler = (cycler(color=['black', 'r', 'b', 'y', 'teal', 'green', 'purple']) +\n",
    "                  cycler(linestyle=['-', '--', ':', '-.', '-.', '-', '--']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "cmap_1 = ListedColormap([\"darkorange\", \"gold\", \"lawngreen\", \"lightseagreen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 150\n",
    "end_time = 200\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "# plt.rc('axes', prop_cycle=default_cycler)\n",
    "# plt.style.use('grayscale')\n",
    "plt.plot(data_true[start_time:end_time], label='actual')\n",
    "plt.plot(mlp_predicted[start_time:end_time, 0], label=\"mlp\")\n",
    "plt.plot(lstm_predicted[start_time:end_time], label=\"lstm\")\n",
    "plt.plot(gru_predicted[start_time:end_time], label=\"gru\")\n",
    "plt.plot(cnn_predicted[start_time:end_time], label=\"cnn\")\n",
    "plt.plot(cnn_lstm_predicted[start_time:end_time, 0], label=\"cnn+gru\")\n",
    "plt.plot(lstnet_predicted[start_time:end_time, 0], label=\"lstnet\")\n",
    "plt.ylabel('Throughput (Mbits/sec)')\n",
    "plt.xlabel('Day')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_rmse = sqrt(mean_squared_error(data_true, mlp_predicted[:, 0]))\n",
    "mlp_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_rmse = sqrt(mean_squared_error(data_true, lstm_predicted))\n",
    "lstm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_rmse = sqrt(mean_squared_error(data_true, gru_predicted))\n",
    "gru_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_rmse = sqrt(mean_squared_error(data_true, cnn_predicted))\n",
    "cnn_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_rmse = sqrt(mean_squared_error(data_true, cnn_lstm_predicted[:, 0]))\n",
    "cnn_lstm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_rmse = sqrt(mean_squared_error(data_true, lstnet_predicted[:, 0]))\n",
    "lstnet_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[0.45, mlp_rmse, lstm_rmse, gru_rmse, cnn_rmse, cnn_lstm_rmse, lstnet_rmse])\n",
    "ax.set_xlabel('Model')\n",
    "\n",
    "ax.set_ylabel('Root Mean Squared Error (RMSE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mape = mean_absolute_percentage_error(data_true, mlp_predicted[:, 0])\n",
    "mlp_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mape = mean_absolute_percentage_error(data_true, lstm_predicted)\n",
    "lstm_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_mape = mean_absolute_percentage_error(data_true, gru_predicted)\n",
    "gru_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mape = mean_absolute_percentage_error(data_true, cnn_predicted)\n",
    "cnn_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_mape = mean_absolute_percentage_error(data_true, cnn_lstm_predicted[:, 0])\n",
    "cnn_lstm_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_mape = mean_absolute_percentage_error(data_true, lstnet_predicted[:, 0])\n",
    "lstnet_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[79, mlp_mape, lstm_mape, gru_mape, cnn_mape, cnn_lstm_mape, lstnet_mape])\n",
    "ax.set_xlabel('Model')\n",
    "# ax.set_ylim(0.0, 0.9)\n",
    "ax.set_ylabel('Mean Absolute Percentage Error (MAPE) %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_corr = corr(data_true, mlp_predicted[:, 0])\n",
    "mlp_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_corr = corr(data_true, lstm_predicted)\n",
    "lstm_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_corr = corr(data_true, gru_predicted)\n",
    "gru_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_corr = corr(data_true, cnn_predicted)\n",
    "cnn_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_corr = corr(data_true, cnn_lstm_predicted[:, 0])\n",
    "cnn_lstm_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_corr = corr(data_true, lstnet_predicted[:, 0])\n",
    "lstnet_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "scipy.stats.pearsonr(data_true, lstnet_predicted[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[0.88, mlp_corr, lstm_corr, gru_corr, cnn_corr, cnn_lstm_corr, lstnet_corr])\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylim(0.85, 0.95)\n",
    "ax.set_ylabel('Mean Absolute Percentage Error (MAPE) %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_r2 = r2_score(data_true, mlp_predicted[:, 0])\n",
    "lstm_r2 = r2_score(data_true, lstm_predicted)\n",
    "gru_r2 = r2_score(data_true, gru_predicted)\n",
    "cnn_r2 = r2_score(data_true, cnn_predicted)\n",
    "cnn_lstm_r2 = r2_score(data_true, cnn_lstm_predicted[:, 0])\n",
    "lstnet_r2 = r2_score(data_true, lstnet_predicted[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'mlp r2:     {mlp_r2}')\n",
    "print(f'lstm r2:    {lstm_r2}')\n",
    "print(f'gru r2:     {gru_r2}')\n",
    "print(f'cnn r2:     {cnn_r2}')\n",
    "print(f'cnn+gru r2: {cnn_lstm_r2}')\n",
    "print(f'lstnet r2:  {lstnet_r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RRSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_rrse = rse(data_true, mlp_predicted[:, 0])\n",
    "mlp_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_rrse = rse(data_true, lstm_predicted)\n",
    "lstm_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_rrse = rse(data_true, gru_predicted)\n",
    "gru_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_rrse = rse(data_true, cnn_predicted)\n",
    "cnn_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_rrse = rse(data_true, cnn_lstm_predicted[:, 0].flatten())\n",
    "cnn_lstm_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_rrse = rse(data_true, lstnet_predicted[:, 0].flatten())\n",
    "lstnet_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[0.79, mlp_rrse,lstm_rrse,gru_rrse,cnn_rrse,cnn_lstm_rrse,lstnet_rrse])\n",
    "ax.set_xlabel('Model')\n",
    "# ax.set_ylim(0.0, 0.9)\n",
    "ax.set_ylabel('Root Relative Squared Error (RRSE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mae = mean_absolute_error(data_true, mlp_predicted[:, 0])\n",
    "mlp_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mae = mean_absolute_error(data_true, lstm_predicted)\n",
    "lstm_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_mae = mean_absolute_error(data_true, gru_predicted)\n",
    "gru_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mae = mean_absolute_error(data_true, cnn_predicted)\n",
    "cnn_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_mae = mean_absolute_error(data_true, cnn_lstm_predicted[:, 0])\n",
    "cnn_lstm_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_mae = mean_absolute_error(data_true, lstnet_predicted[:, 0])\n",
    "lstnet_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[79, mlp_mae, lstm_mae, gru_mae, cnn_mae, cnn_lstm_mae, lstnet_mae])\n",
    "ax.set_xlabel('Model')\n",
    "# ax.set_ylim(0.0, 0.9)\n",
    "ax.set_ylabel('Mean Absolute Percentage Error (MAPE) %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSRE (root mean square relative error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mae = mean_absolute_error(data_true, mlp_predicted[:, 0])\n",
    "mlp_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mae = mean_absolute_error(data_true, lstm_predicted)\n",
    "lstm_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_mae = mean_absolute_error(data_true, gru_predicted)\n",
    "gru_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mae = mean_absolute_error(data_true, cnn_predicted)\n",
    "cnn_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm_mae = mean_absolute_error(data_true, cnn_lstm_predicted[:, 0])\n",
    "cnn_lstm_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstnet_mae = mean_absolute_error(data_true, lstnet_predicted[:, 0])\n",
    "lstnet_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "ax.bar(x=['ARIMA', 'MLP', 'LSTM', 'GRU', 'CNN', 'CNN+LSTM', 'LSTNet'], \n",
    "        height=[79, mlp_mae, lstm_mae, gru_mae, cnn_mae, cnn_lstm_mae, lstnet_mae])\n",
    "ax.set_xlabel('Model')\n",
    "# ax.set_ylim(0.0, 0.9)\n",
    "ax.set_ylabel('Mean Absolute Percentage Error (MAPE) %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDF of Relative Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_relative_error = (data_true - mlp_predicted[:, 0]) / data_true\n",
    "lstm_relative_error = (data_true - lstm_predicted) / data_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_residual_error = (data_true - mlp_predicted[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_relative_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mlp_relative_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 40\n",
    "counts, bin_edges = np.histogram (abs(mlp_relative_error), bins=num_bins, normed=True)\n",
    "cdf = np.cumsum (counts)\n",
    "plt.plot (bin_edges[1:], cdf/cdf[-1])\n",
    "counts, bin_edges = np.histogram (abs(lstm_relative_error), bins=num_bins, normed=True)\n",
    "cdf = np.cumsum (counts)\n",
    "plt.plot (bin_edges[1:], cdf/cdf[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_actual = np.load('predicted_results/arima_data_actual_multivar_1.npy')\n",
    "arima_predicted = np.load('predicted_results/arima_data_predictions_multivar_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(arima_actual[0:300])\n",
    "plt.plot(arima_predicted[0:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rrse = rse(arima_actual, arima_predicted)\n",
    "arima_rrse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "arima_mae = mean_absolute_error(arima_actual, arima_predicted)\n",
    "arima_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "  return np.mean(np.abs(y_true - y_pred) / np.abs(y_true)) * 100\n",
    "\n",
    "arima_mape = mean_absolute_percentage_error(arima_actual, arima_predicted)\n",
    "arima_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "arima_rmse = sqrt(mean_squared_error(arima_actual, arima_predicted))\n",
    "arima_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_corr = corr(arima_actual, arima_predicted)\n",
    "arima_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for all models on a single route (from test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = np.load('numpy_group_test_data/1_stream_test_sample_group_95.npy')\n",
    "test_target = np.load('numpy_group_test_data/1_stream_test_target_group_95.npy')\n",
    "\n",
    "normalize_mean = 9726.925995055048\n",
    "normalize_std  = 6670.752950995383\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm \n",
    "\n",
    "arma_mod = sm.tsa.ARIMA(test_target[:,0], order=(8,0,8))\n",
    "arma_res = arma_mod.fit(trend='nc', disp=-1)\n",
    "arma_predictions = arma_res.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model instance\n",
    "\n",
    "# Restore the weights\n",
    "linear.load_weights('./checkpoints/linear_weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_test_predict = linear.predict(test_sample)\n",
    "lstm_test_predict = lstm_model.predict(test_sample)\n",
    "gru_test_predict = gru_model.predict(test_sample)\n",
    "cnn_test_predict = cnn_model.predict(test_sample)\n",
    "cnn_lstm_test_predict = cnn_lstm_model.predict(test_sample)\n",
    "lstnet_test_predict = lstnet_model.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "plt.plot(test_target[1:,0] * normalize_std + normalize_mean, label='actual')\n",
    "plt.plot(arma_predictions[1:] * normalize_std + normalize_mean, label='arima')\n",
    "plt.plot(linear_test_predict[1:] * normalize_std + normalize_mean, label='mlp')\n",
    "plt.plot(lstm_test_predict[1:] * normalize_std + normalize_mean, label='lstm')\n",
    "plt.plot(gru_test_predict[1:] * normalize_std + normalize_mean, label='gru')\n",
    "plt.plot(cnn_test_predict[1:] * normalize_std + normalize_mean, label='cnn')\n",
    "plt.plot(cnn_lstm_test_predict[1:,0] * normalize_std + normalize_mean, label='cnn+gru')\n",
    "plt.plot(lstnet_test_predict[1:,0] * normalize_std + normalize_mean, label='lstnet')\n",
    "plt.ylabel('Throughput (Mbits/sec)')\n",
    "plt.xlabel('Day')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(test_target[1:,0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
